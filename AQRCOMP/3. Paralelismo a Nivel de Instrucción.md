# 3.1 Emisión Múltiple
La **segmentación** permite ejecutar varias instrucciones a la vez. El objetivo de explotar el **ILP** (Instruction Level Paralelism) es **optimizar el CPI**:
$$CPI = CPI_{ideal} + \text{Paradas por riesgos estructurales}+ \text{Paradas por riesgos de control} + \text{Paradas por riesgos de datos}$$
La predicción de saltos realizada por el compilador, el unrolling,etc. ayudan a exponer más el paralelismo.

Hay dos alternativas para **mejorar el ILP**:
- Hacer más **profundo el pipeline** (tema2)->menos trabajo por etapa -> $T_{clock}$ más corto -> mayor $f_{clock}$
- **Emisión múltiple** (tema3) -> se replican las etapas del pipeline en **multiples pipelines** en los que se comenzarán **varias instrucciones en cada ciclo**. Entonces $CPI \lt 1$, por lo que en su lugar se usa el **IPC** (numero de instrucciones por ciclo) como medida de rapidez. 

## 3.1.2 Dependencias de Nombre
**Dependencia de nombre**, suceden cuando dos instrucciones usan el **mismo nombre de registro**, pero entre ellas **no hay flujo real de información**.

Aunque no sean dependencias reales de datos suponen un problema al reordenar código, ya que **el orden** de las instrucciones en las dependencias de nombre **se debe conservar**. Son las dependencias **WAR y WAW**.

En el MIPS segmentado estudiado estas dependencias no producen riesgos, pero en otras arquitecturas sí. Se resuelven mediante **renombrado de registros**.

![[Pasted image 20250428221424.png]]

## 3.1.2 Emisión múltiple estática vs dinámica
- **Emisión múltiple estática:** el **compilador** agrupa instrucciones en **paquetes de emisión** para emitirlas juntas. El compilador **detecta** y **evita riesgos** con lo cual reduce o elimina **paradas**.

- **Emisión múltiple dinámica:** la **cpu** examina el flujo de instrucciones y selecciona las que se deben emitir en cada ciclo. Las CPU **evita riesgos** utilizando técnicas avanzadas en **tiempo de ejecución**. El **compilador** puede ayudar **reordenando** las instrucciones. Se usa sobre todo en servidores y procesadores de escritorio.

# 3.2 Emisión Múltiple Estática
La **emisión múltiple estática:** el **compilador** agrupa instrucciones en **paquetes de emisión** para emitirlas juntas. Un **paquete de emisión** es un grupo instrucciones que pueden ser **emitidas** en un solo **ciclo**, y viene determinado por los **recursos del pip**.

## 3.2.1 Planificación Estática
En la **planificación estática** el **compilador** debe **eliminar algunos/todos los riesgos:**
- En un paquete de emisión sólo puede haber instrucciones **sin dependencias entre ellas** (si no, no se podrían ejecutar simultáneamente).
- Posiblemente haya **dependencias entre paquetes** -> su tratamiento varía entre ISAs. **El compilador debe saberlo**.
- Se rellenará el resto del paquete con **NOP** si no se encuentran las instrucciones adecuadas.

## 3.2.2 MIPS con emisión dual estática
Se forman paquetes de emisión con una instrucción **ALU** o un **salto** seguida de una instrucción de **load** o **store**. Las instrucciones no utilizadas se rellenan con **NOP**.

![[Pasted image 20250428222829.png]]

![[Pasted image 20250428222902.png]]

Se ejecutan más instrucciones en paralelo, pero surgen **nuevos casos de riesgos de datos en EX:**
- El **forwarding** evita paradas que se producirán con la **emisión simple**. 
- Pero ahora **no se puede adelantar** el resultado de una instrucción ALU en una load/store **en el mismo paquete** de dos instrucciones, por lo que hay que dividirlo en **dos paquetes** o se producirá una **parada**.

```
add $t0, $s0, $s1
load $s2, 0($t0)
```

Se puede producir **riesgo de carga y uno entre paquetes** de emisión dual -> sigue habiendo un ciclo de parada, pero ahora se ejutan dos instrucciones en cada paquete.

Se requiere una **planificación más agresiva** que para la emisión tradicional de una sola instrucción.

![[Pasted image 20250428225350.png]]
$$IPC = \frac{5}{4}=1.25 \text{(el máximo sería IPC = 0)}$$

## 3.2.3 Unrolling
El **unrolling** consiste en replicar el cuerpo de un lazo para exponer más paralelismo:
- Reduce la sobrecarga por **control del lazo**.
- Reúsa datos almacenados en las memoria **caché**.
Conviene usar **diferentes registros** para la replicación (renombrado de registros)

![[Pasted image 20250428225802.png]]

## 3.2.4 Procesadores VLIW
Las arquitecturas **VLIW** (Very Long Instruction Word) ven los paquetes como una **instrucción muy larga** que especifica **múltiples operaciones concurrentes**. Debe haber **suficiente paralelismo** en el código como para **llenar todos los slots** disponibles. 

Esto implica **hardware** de la CPU más **simplificado**, menor **consumo de potencia**, es necesario **encontrar paralelismo estáticamente** ya que no hay hardware de detección de riesgos. Gran **tamaño** del código.

![[Pasted image 20250428230237.png]]
![[Pasted image 20250428230253.png]]

# 3.3 Emisión Múltiple Dinámica
La **emisión múltiple estática** la **cpu** examina el flujo de instrucciones y selecciona las que se deben emitir en cada ciclo. Los procesadores que la realizan denominan **procesadores superescalares**.

Evita la necesidad de **planificación** del **compilador**, ya que se realiza por hardware. La CPU asegura la semántica del código, pero da lugar a CPUs más complicadas en cuanto a hardware.
![[Pasted image 20250429113500.png]]

Permite a la CPU emitir varias instrucciones que:
- Se **ejecutan fuera de orden** (para evitar paradas).
- **Terminan fuera de orden** en muchos casos.
- Pero el WB respeta la semántica del programa


## 3.3.1 Planificación dinámica
La **planificación dinámica** consiste en **reordenar** las instrucciones para reducir las paradas a la vez que se mantiene el flujo de datos del programa. 

El **compilador** no necesita conocer el **hardware** y puede gestionar casos en los que las **dependencias no** se conocen en **tiempo de compilación**. Sim embargo, hay un incremento de **complejidad hardware**.

**Motivos para hacer planificación dinámica:**
- No todas las paradas son **predecible** (por ejemplo, los fallos de caché).
- No siempre se pueden planificar estáticamente, por ejemplo, si hay instrucciones de **salto**, ya que el **resultado** del salto se determina **dinámicamente**.
- **Diferentes implementaciones de un ISA** pueden tener diferentes **latencias** y dar lugar a diferentes **riesgos**.

![[Pasted image 20250429114623.png]]
- **Instruction commit:** proceso que se produce cuando una instrucción actualiza su resultado en el **archivo de registros**.

Hay dos técnicas básicas de planificación dinámica:
- **Marcador:** **retener** las instrucciones emitidas hasta que haya **recursos suficientes y no haya riesgos de datos**.
- **Tomasulo:** eliminar dependencias de datos WAR y WAW realizando **renombrado de registros**.

![[Pasted image 20250429114518.png]]

## 3.3.2 Renombrado de registros
El **renombrado de registros** resuelve las dependencias WAR y WAW usando las **estaciones de reserva** y **buffers de reordenamiento**.

![[Pasted image 20250429114828.png]]
![[Pasted image 20250429114844.png]]

### Estaciones de reserva
El renombrado de registros se realiza mediante **estaciones de reserva** (RS), que tienen una **entrada** por cada **instrucción** en **ejecución**. Las instrucciones **entran** a las RS en **orden**, pero pueden **ejecutarse desordenadas** dependiendo de la disponibilidad de los operandos que necesitan.

Cuando una instrucción se emite a una estación de reserva:
- Si el **operando** está **disponible** en el almacén de registros o en un buffer de reordenamiento, se copia a la estación de reserva. Si no se necesita en el registro para más adelante se puede **sobreescribir**.

- Si el **operando no** está **disponible**, se copia a la estación de reserva cuando esté disponible. Podría no ser necesario **actualizar** el registro
![[Pasted image 20250429115334.png]]

Campos de una entrada en la RS:
- $B$: indica si la entrada está ocupada por una instrucción o libre
- $INST$: campo de código de instrucción.
- $OP1$ y $OP2$: operandos de entrada de la instrucción: proceden de registros o de caminos de adelantamiento de las unidades de ejecución. Pueden ser un identificador de registro o de renombrado, es decir, que su valor está siendo calculado.
- $V1$ y $V2$: indica si los operandos $OP1$ y $OP2$ son válidos.
- $R$: indica si la instrucción está lista para la emisión.

## 3.3.3 Algoritmo de Tomasulo
**Tomasulo** rastrea cuando los operandos están disponibles e introduce renombrado de registros. Cada instrucción pasa por tres pasos:
- **Emitir:**
	- Obtener la siguiente instrucción de la cola FIFO
	- Si la RS está disponible:
		- Si los valores del operando están disponibles, emite la instrucción a la RS
		- Si los valores de los operandos no están disponibles, detiene la instrucción

- **Ejecutar:**
	- Cuando un operando está disponible, lo almacena en cualquier estación de reserva que lo esté esperando
	- Cuando todos los operandos están listos, emite la instrucción
		- Las **cargas** y el **almacenamiento** se mantienen en **orden** a través de la **dirección efectiva**.
		- No se permite iniciar la ejecución de ninguna instrucción hasta que se completen todas las ramas que la preceden en el orden del programa.

- **Escribir el resultado:** 
	- Escribir en las estaciones de reserva y en los buffers de almacenamiento el resultado que está en el bus CDB (bus común de datos). Los **almacenamientos** deben **esperar** hasta que la dirección y los valores estén disponibles.

![[Pasted image 20250429121045.png]]


# 3.4 Especulación Basada en Hardware
La **especulación** consiste en hacer conjeturas sobre de lo que hará una instrucción.
- Comenzar la operación tan pronto como sea posible
- Chequear si se acertó:
	- Si se acertó: completar la operación
	- Si no se acertó: retroceder y corregir

Se realiza tanto en la emisión **multiple** como en dinámica.

Tipos de especulación:
- Especulación realizada por el **compilador:** reordena instrucciones (ej, mover la carga antes de un salto). Si la especulación es incorrecta, puede incluir **instrucciones de arreglo** para recuperarse.

- Especulación realizada por **hardware:** busca por adelantado instrucciones para ejecutar. Mete los resultados de ejecutar la instrucción en un buffer hasta que se determine si se necesitan realmente, si la especulación es incorrecta se **vacían los buffers**.

### Especulación acerca del Salto
Consiste en especular acerca del resultado de un salto y continuar emitiendo instrucciones asumiendo que son las correctas. No se actualizan los registros (Instruction Commit) hasta que se determine el resultado de salto.

### Especulación acerca de la Carga
Trata de evitar el retardo por carga y fallo caché.
- Predecir la dirección efectiva
- Predecir el valor cargado
- Pasar los valores almacenado a la unidad de carga
No se actualizan los registros hasta que se resuelve la especulación.

## 3.4.1 Buffers de Reordenamiento (ROB)
Posibles estados para una instrucción:
- **En ejecución**: la instrucción no acabó de ejecutarse
- **Finalizada**: la ejecución acabó y se escribe el resultado en un **registro renombrado** o en un **buffer** previo a escribir memoria (si es un store)
- **Completada**: modifica los registros del núcleo.
- **Retirada**: 
	- Si el destino es un registro: coincide con **comletada**
	- Si el destino es la memoria: se escribe en la caché de datos
![[Pasted image 20250429123014.png]]

# 3.5 Arquitectura de alto nivel de un Núcleo
![[Pasted image 20250429123104.png]]

# 3.6 Dificultades de la emisión múltiple
- Los programas tienen **dependencias** que limitan el ILP, y algunas son difíciles de eliminar (ejemplo, las asociadas a los punteros).
- Algún **paralelismo** es **difícil de encontrar** en el código, ya que se usa una ventana de emisión (rango de instrucciones analizadas) de tamaño limitado.
- Hay **retardos de memoria** y el **ancho de banda** está **limitado**, es difícil mantener los pipelines llenos. 
- La **especulación puede ayudar si se hace bien**.

# 3.7 Tipos de Arquitecturas
Las microarquitecruas modernas usan **emisión múltiple, planificación dinámica** y **especulación**. Hay dos grandes enfoques:
- Asignar **lógica de diseño** para manejar cualquier posible dependencia entre las instrucciones. Sólo permite 2 IPC
- Añadir **lógica de diseño** para manejar cualquier posible dependencia entre las instrucciones. La lógica de emisión es el **cuello de botella** en los superescalares planificados dinámicamente.

![[Pasted image 20250429124042.png]]

# 3.8 Eficiencia Energética
La complejidad de la **planificación dinámica** y las **especulaciones** requieren **energía**. Podría resultar más eficiente tener **muchos núcleos más simples.**
![[Pasted image 20250429125615.png]]

# 3.9 Ejemplo: ARM A8 e INTEL I7
![[Pasted image 20250429125830.png]]

## ARM8
### Pipeline
![[Pasted image 20250429125912.png]]
### Rendimiento expresado mediante el CPI
![[Pasted image 20250429125932.png]]

## I7
### Pipeline
![[Pasted image 20250429130017.png]]
### Rendimiento expresado mediante el CPI
![[Pasted image 20250429130033.png]]
![[Pasted image 20250429130041.png]]

# 3.10 Falacias
Creer que procesadores con **CPIs** más bajos o **frecuencias** de reloj más **altas** son **más rápidas**.
![[Pasted image 20250429130137.png]]
Creer que hay grandes cantidades de **ILP disponibles** y que se podrían explotar si tuviéramos las **técnicas adecuadas**.
![[Pasted image 20250429130228.png]]

# 3.11 Conclusiones
- El **ISA** influencia el **diseño** del camino de datos y control
- En las máquinas que realizan emisión múltiple, la **segmentación mejora** la **productividad**, pero no la **latencia** por instrucción no **cambia**.
- Los **riesgos** estructurales, de datos y de control pueden producir **paradas**.
- En las arquitecturas de **emisión múltiple** y **planificación dinámica**:
	- Las **dependencias de datos** limitan la cantidad de paralelismo explotable.
	- La **complejidad del hardware** requerido lleva la potencia requerida al límite de lo permisible.

