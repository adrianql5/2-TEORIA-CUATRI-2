# 1.1 Introducción a la Arquitectura de Computadores y Procesadores Multinúcleo
La arquitectura de computadores es el área de la informática que estudia el diseño y la organización de los procesadores, la memoria y los sistemas de interconexión para optimizar el rendimiento de los sistemas de cómputo. En esta asignatura abordaremos:
- **Modelos de computación y Taxonomía de Flynn**
- **Paralelismo y rendimiento** (ILP, TLP, RLP, GPUs)
- **Estructuras de microprocesadores y memoria caché**
- **Segmentación de procesadores y ejecución fuera de orden**

Dado el crecimiento de la demanda de procesamiento y las limitaciones físicas del modelo tradicional basado en el aumento de frecuencia, los procesadores actuales han evolucionado hacia arquitecturas multinúcleo que explotan el paralelismo.


# 1.2 Parámetros de Diseño de un Sistema
- **Rendimiento** (velocidad)
- **Coste**
- **Potencia** (*estática + dinámica*):
	- Potencia **pico** (*máxima*)
	- Potencia media 
- **Robustez**: 
	- Tolerancia al ruido
	- Resistencia a la readiación
- **Testeabilidad**
- **Reconfigurabilidad**
- **Tiempo de salida el mercado**

# 1.3 Clasificación de los Computadores

- **Personal MObile Device** (*PMD*) -> Énfasis en eficiencia energética y tiempo real.
- **Computación de escritorio** -> Énfasis en coste-rendimiento
- **Servidores** -> Énfasis en disponibilidad, escalabilidad y producividad.
- **Clústers** / *Warehouse Scale Computers* -> Énfasis en disponibilidad y coste-rendimiento.
	- Usados para *Software como servicio*
	- **Supercomputadores** -> Énfasis en rendimiento en punto flotante y redes internas rápidas
- **Internet of Things** / *Embedded Computers* -> Énfasis en precio.

![[Pasted image 20250406161504.png]]

# 1.4 Arquitectura de un Computador
Visión **simplificada** del diseño de la arquitectura de un computador: 
- Se centra en el diseño del **ISA** (*Instruction Set Architecure*)
- Toma decisiones: **registros, direccionamiento de memeoria, operandos de las instrucciones, tipos de instrucciones, etc.**

Visión **realista** del diseño de la arquitectura de un computador: 
- Se diseña para satisfacer los **requisitos específicos de la máquina objetivo**, maximizando el rendimiento con ciertas restricciones (*coste, potencia y disponibilidiad*).
- Toma de decisiones: **ISA pero también microarquitecturas hardware**.

# 1.5 Concepto y Tipos de Paralelismo
La **explotación del paralelismo** está relacionada con la **mejora de rendimiento** del sistema. Para poder explotar el paralelismo es necesario modificar las aplicaciones: **el código debe exponer el paralelismo de manera explícita**.

Paralelismo en **arquitecturas:**
- **Instruction-Level Parallelism (ILP):** se ejecutan a la vez varias instrucciones en distintas fases. Se dice que está **agotado**, a nivel tecnológico ya que no hay muchas mejoras posibles y se deben buscar otros métodos para mejorar el rendimiento.

- **Thread-Level Parallelism (TLP):** Múltiples hilos ejecutados en paralelo en distintos núcleos.

- **Request-Level Parallelism (RLP):** Procesamiento de múltiples solicitudes en paralelo.

- **Vector Architectures / GPUs (SIMD):** Se aplican instrucciones a multiples datos en paralelo. Para ello agrupan las variables en vectores, realizando muchos cálculos en pocas instrucciones.

# 1.6 Clasificación de Arquitecturas Paralelas
Existen diferentes criterios que permiten clasificar arquitecturas paralelas: **taxonomía de Flynn**, según las organización del sistema de memoria, según la escalabilidad, disponibilidad de sus comonentes, cociente rendimiento/coste, etc.

## 1.6.1 Taxonomía de Flynn 
Es una clasificación de los procesadores basada en el número de flujos de **instrucciones** y **datos** que manejan simultáneamente.

- **SISD:** computador secuencial que puede explotar el **paralelismo a nivel de instrucción**
- **SIMD:** arquitecturas vectoriales, GPUs o extensiones multimedia
- **MISD:** no hay implementaciones comerciales
- **MIMD:** cada procesador tiene sus propias instrucciones y opera sobre sus propios datos.

| Categoría                                      | Flujo de Instrucciones | Flujo de Datos | Descripción                                                                |
| ---------------------------------------------- | ---------------------- | -------------- | -------------------------------------------------------------------------- |
| **SISD** (Single Instruction, Single Data)     | 1                      | 1              | Computación secuencial tradicional (Ej: procesadores mononúcleo antiguos). |
| **SIMD** (Single Instruction, Multiple Data)   | 1                      | Múltiples      | Ideal para procesamiento de gráficos y cálculos vectoriales (Ej: GPUs).    |
| **MISD** (Multiple Instruction, Single Data)   | Múltiples              | 1              | Poco común, usado en sistemas tolerantes a fallos.                         |
| **MIMD** (Multiple Instruction, Multiple Data) | Múltiples              | Múltiples      | Base de los procesadores multinúcleo modernos.                             |
![[Pasted image 20250403153030.png]]

## 1.6.2 Arquitecturas MIMD - Multiprocesadores
Son las de **uso más extendido:**

- **Procesadores con memoria compartida (*UMA, Uniform Memory Access)*:**
	- Todos los procesadores comparten el **mismo espacio de direcciones** (*como si tuvieran una única memoria compartida entre todos*).
	- El programador **no necesita** conocer la ubicación de los datos.

- **Procesadores con memoria distribuida (*NUMA, Non-Uniform Memory Access)*:** 
	- Cada procesador tiene su **propio espacio de direcciones**.
	- El programador **necesita** conocer la ubicación de los datos

- **Multicores (*Multiprocesadores en un único chip)*:**
	- Tienen **más de un procesador por chip**
	- Requieren **programación paralela explícita**, el hardware tienen la capacidad de ejecutar varias instrucciones a la vez, pero esta característica suele estar oculta al programador.
	- Es difícil programar para conseguir un buen rendimiento, conseguir balanceo de carga entre los núcleos y optimizar la comunicación y sincronización

- Otros tipos como **clusters, MPPs, etc.**

![[Pasted image 20250406165122.png]]

![[Pasted image 20250406165208.png]]


# 1.7 Conceptos de Procesadores Multinúcleo
## 1.7.1 Segmentación (pipeline)
La **segmentación** es la ejecución de instrucciones en **etapas,** de manera que cada etapa tiene un **retardo adicional** (para almacenar los resultados de la etapa en registros).

La **profundidad de segmentación** es el número de **etapas de segmentación**.

$F04$ (*Fan_out of 4*) es una unidad de tiempo equivalente al retardo que tiene una señal al atrevesar un único inversor con 4 inversores conectados a la salida. Su valor exacto depende de la tecnología de fabricación, es decir, del **nodo tecnológico**.

>[!Nota]
>Un **nodo tecnológico** se refiere al **tamaño mínimo de los transistores y las interconexiones** en un proceso de fabricación. Este tamaño se mide en nanómetros (nm) y define la generación de un microprocesador.

El **retardo de cada instrucción** en un procesador con segmentación es más alto que sin ella debido a la lógica adicional añadida, pero pasa **menos tiempo entre instrucciones**.

En cada ciclo de reloj se emite una instrucción para ser ejecutada, pero alguna puede quedarse **bloqueada** en alguna etapa (por ejemplo, para buscar un dato en memoria), provocando que las instrucciones posteriores no puedan avanzar, lo cual se conoce como la **burbuja** (parada de emisión), lo que reduce la productividad.

Con segmentación se usa una **frecuencia de reloj más alta** pues el periodo será de la longitud aproximada de una etapa (se intenta que todas tarden aproximadamente lo mismo).

![[Pasted image 20250406171108.png]]
## 1.7.2 Arquitectura de un Núcleo
![[Pasted image 20250406170828.png]]


## 1.7.3 Arquitectura de un Microprocesador Multinúcleo
![[Pasted image 20250406170916.png]]

# 1.8 Escalamiento de Prestaciones en Microprocesadores

## 1.8.1 Tecnologías de Fabricación CMOS
Los chips tienen **varias capas de transistores** apiladas para ahorrar superficie. El valor numérico que identifica al **nodo tecnológico** es el ancho **mínimo** de una **conexión de** cobre de **nivel 1**, que esta relacionado directamente con la superficie que ocupa el transistor.

![[Pasted image 20250406172201.png]]

### Evolución del Área Lógica de un Circuito General con la Tecnología
![[Pasted image 20250406172253.png]]

La **ley de Moore** predice que la unidad de transistores por unidad de área se duplica cada 2 años aproximadamente.

Cada nodo tecnológico supone una **reducción del 0.7x de las conexiones** entre transistores y del **0.5x del aŕea** de un 
chip.

En el caso **ideal**, esto supondría que el procesador tiene el **doble de superficie** disponible, pero en **realidad no todas sus partes escalan igual** (especialmente, la memoria DRAM escala mal).

### Evolución del Área Lógica de Microprocesadores con la Tecnología
![[Pasted image 20250406172550.png]]
**Al principio** el área ocupada por la misma cantidad de transistores se **reducía a la mitad** entre nodos tecnológicos, pero **cada vez se reduce menos** (en torno al 0.4x).


## 1.8.2 Tendencias en Potencia, Ancho de Banda y Latencia
### Potencia Dinámica
La **potencia dinámica** es la energía consumida cuando los transistores cambian de estado (**de 0 a 1 o de 1 a 0**). Esto ocurre cada vez que el procesador ejecuta instrucciones.
$$P_{dinámica} = \frac{1}{2} C V^2 f$$
Donde:
- **C** = Carga capacitiva
- **V** = Voltaje de alimentación
- **f** = Frecuencia de reloj

La **carga capacitiva** depende del número de **transistores activos** y de la **tecnología** (que determina la capacitancia de cables y transistores). En CMOS escala ineficientemente, 0.8x de una generación a otra (mientras que transistores x2)

A mayor frecuencia, **más conmutaciones** por segundo → **mayor consumo energético**.

La potencia es **proporcional al cuadrado del voltaje**, lo que significa que **reducir V** ayuda significativamente a disminuir el consumo energético.

### Potencia Estática (o de fuga)
La **potencia estática** es la energía consumida **incluso cuando el procesador está inactivo**. Se debe a **corrientes de fuga** que atraviesan los transistores aunque no estén cambiando de estado.

$$P_{estática} = I_{fuga} \times V$$
Donde:
- **$I_\text{fuga}$** = Corriente de fuga
- **$V$** = Voltaje de alimentación

Para reducirla: 
- **Power gating:** desconectar las partes que no se estén usando.
- Diseños **domain-specific** -> diseños optimizados para una operación muy frecuente.
- Escala con el **número de transistores**, aunque estén sin funcionar. Si se usan cachés SRAM grandes, puede llegar al 50%


### Eficiencia Energética en Microprocesadores de Altas Prestaciones
![[Pasted image 20250406173739.png]]

### Eficiencia Energética en Microprocesadores de Propósito General
![[Pasted image 20250406173908.png]]

### Potencia Consumida: Variación de la Frecuencia de Reloj
![[Pasted image 20250406174018.png]]

### Thermal Desing Power (*TDP*)
El **TDP** caracteriza el consumo de potencia sostenido. Se usa como objetivo en cuanto a **potencia suministrada** y **sistema de refrigeración**. Su valor está entre la potencia pico y la media

La **frecuencia de reloj** se puede **reducir dinámicamente**, es decir, tomar valores distintos en distintas partes del sistema, para limitar el consumo de energía.

Hay un **límite** en las condiciones de **temperatura** en las que puede funcionar un circuito. Se ha llegado a un **límite de disipación** de potencia (100-200W) debido a cuestiones técnicas y económicas. Mantener el límite en cada nueva generación de microprocesadores requiere **optimizar el consumo de potencia**.

![[Pasted image 20250406174517.png]]

### **Técnicas para Aumentar la Eficiencia Energética**
- **No hacer nada:** Cuando una unidad no está en uso, se **detiene su reloj** para evitar consumo innecesario de energía estática o dinámica.
 
- **Escalado Dinámico de Voltaje-Frecuencia (DVFS):** Cuando el procesador está inactivo, **reduce su frecuencia y voltaje** para ahorrar energía.
 
- **Estados de baja potencia en memorias DRAM y discos almacenamiento:** tratando de que las partes inactivas funcionen con frecuencia menor. 

- **Overclocking:** trabajar a frecuencia más alta durante breves periodos de tiempo.
	- Puede implicar apagar los núcleos para los que no se sube la frecuencia
	- Limitado por la subida de la temperatura
	- Transparente a la usuario

### Efecto de la Evolución Tecnológica en Prestaciones y Potencia
![[Pasted image 20250406175953.png]]




### Escalamiento del Retardo en Circuitos CMOS
Se ha determinado **experimentalmente** que el **retardo típico de una tecnología**, el $FO4$, es:
$$FO4 = 0.2 \times T \text{ (nm)} \quad (\text{en picosegundos})$$
Donde $T$ es el caracterizador del nodo tecnológico (en nm). El $FO4$ puede aumentar hasta un 1.4x en condiciones de operación extremas.

- **Ejemplo en tecnología de 45 nm:**
$$FO4 = 0.2 \times 45 = 9 ps$$
- **Ejemplo en tecnología de 65 nm:**
$$FO4 = 0.2 \times 65 = 13 ps$$

**Ejemplo de Cálculo de Frecuencia de Reloj:**  
Si un microprocesador tiene un **ciclo de reloj de 13 FO4**, su **frecuencia** en diferentes tecnologías es:

$$ Frecuencia= \frac{1}{\text{Periodo}}$$

- **45 nm:** 
$$f = \frac{1}{13 \times 9 \text{ ps}} = 8.5 \text{ GHz}$$

- **65 nm:**
$$f = \frac{1}{13 \times 13 \text{ ps}} = 5.9 \text{ GHz}$$

**A menor nodo tecnológico, menor retardo y mayor frecuencia de reloj.**


### Efectos del Escalar Voltaje y Frecuencia sobre la Potencia Dinámica
Para las tecnologías actuales hay una relación obtenida **experimental** entre el **escalado del voltaje**, en un factor $K_v$, y el escalada como consecuencia tendrá la **frecuencia**, en un factor $K_f$: 

$$K_f = 1.45 K_v - 0.40$$

Sobre el **escalamiento del consumo de potencia dinámica** en un factor $K_d$:
$$K_d= K_v ^2 * K_f$$

Los procesadores actuales explotan esta propiedad masivamente:
- Para rebajar el consumo de potencia en los circuitos que no están en los caminos críticos.
- Mediante el escalado dinámico de voltaje en cada núcleo de procesamiento cuando no se demanda computación intensiva.

### Evolución de la frecuencia de reloj en los microprocesadores de Intel
![[Pasted image 20250406181837.png]]

### Ancho de Banda y Latencia
**Ancho de Banda:** mide la transferencia de información por unidad de tiempo
**El ancho de banda máximo sostenido (*BWM*)** se diseña para satisfacer cargas de trabajo representativas para el procesador.

$$BWM = \frac{N \times F}{IP \times CPI_{\text{corei}}} \quad (\text{bytes/s})$$
Donde:
- **N** = Número de núcleos.
- **F** = Frecuencia del procesador.
- **IP** = Intensidad operacional (instrucciones/byte).
- **CPI** = Ciclos por instrucción.

En la práctica, el $BWM$ **no siempre escala entre generaciones**: se suele **duplicar entre nodos tecnológicos** y mantener el mismo diseño de memoria dentro del mismo nodo.

El **ancho de banda** y la **latencia** evolucionan de manera muy distinta en diferentes unidades:

| Intervalo de mejora | En procesadores | En memoria y discos |
| ------------------- | --------------- | ------------------- |
| Ancho de banda      | 32000× – 40000× | 300× – 1200×        |
| Latencia            | 50× – 90×       | 6× – 8×             |

![[Pasted image 20250406182219.png]]


## 1.8.3 Escalamiento de Prestaciones
### Escalamiento Hardware
![[Pasted image 20250406182803.png]]

### Distribución del Área de Chip en Microprocesadores
![[Pasted image 20250406182846.png]]

### Efecto de la Ejecución Multihilo Hardware
![[Pasted image 20250406182925.png]]

Los núcleos actuales soportan **más de un hilo** hardware para enmascarar parte de la latencia de memoria, de manera que cuando alguno se detiene se comienza a ejecutar otro. La reducción de latencia depende del tipo de carga de trabajo y programa
Implica **coste de hardware** y conflictos en el **pipeline**.

### Evolución de Procesadores de un solo Núcleo en Prestaciones
![[Pasted image 20250406183105.png]]

La tendencia para los procesadores de Intel fue mantener **constante el CPI**, aunque en las últimas generaciones **aumentó** debido a la **profundidad de segmentación**.

### Final de los Procesadores de un Solo Núcleo
Hasta 2003 se usó un modelo **mononúcleo** de procesamiento **superescalar**, es decir, ejecución de varias instrucciones a la vez en cada ciclo:
- La **latencia** escalaba 0.5x de una generación de microprocesadores a la siguiente.
- La **frecuencia** escalaba 2x de una generación de microprocesadores a la siguiente, manteniendo el CPI constante. Para ello se aumentaba la **profundidad del pipeline** y el **tamaño de la caché** (y por tanto el área del procesador).

El modelo basado en un solo núcleo se ha **agotado** debido a que no se puede reducir más el CPI sin disparar el consumo:
- De una generación a otra, el **área** de los componentes escala 0.5x, lo que en principio reduciría el CPI, pero, debido a usar (por ejemplo) cachés más grandes, aparecen **conexiones que no reducen su longitud**, lo que provoca problemas:
	- Se necesitan más ciclos de reloj para transmitir una señal por esas conexiones largas
	- Las conexiones largas se segmentan mediante registros, aumentando la profundidad del pipeline y por tanto el CPI. Esto, a su vez, implica tener conexiones más largas, creando una paradoja.
- Además, el **modelo de programación** limita el **CPI mínimo** que se puede alcanzar. Por tanto, llega un momento en que la precarga de datos o instrucciones, la ejecución multihilo, ... no son suficiente.
![[Pasted image 20250406184140.png]]


# 1.9 Métricas de Rendimiento de un Sistema
Se basan en media tiempos de ejecución:
- **Tiempo de Respuesta**, latencia o tiempo real: tiempo entre el inicio y final de una tarea. Incluye todos los sobrecostes del sistema (E/S, acceso a memoria RAM, etc.)
- **Tiempo de CPU:** tiempo de computación en CPU para una tarea concreta.
$$Tiempo_{CPU} = \text{Ciclos de CPU} \times \text{Tiempo de ciclo}$$
$$Tiempo_{CPU} = \frac{\text{Ciclos de CPU}}{\text{Frecuencia de reloj}}$$
$$\text{Ciclos de CPU} = \text{Número de instrucciones} \times \text{CPI}$$

- **Troughput** o productividad: cantidad de trabajo realizado por unidad de tiempo
- **Speedup:** aceleración de una version X relativa a una versión Y para un programa en particular
$$ SpeedUp = \frac{T_{Ejecucion_X}}{T_{Ejecucion_Y}}$$

- **CPI (Ciclos por Instrucción):** **número medio de ciclos** que una instrucción necesita para ejecutarse. Diferentes instrucciones **pueden requerir distinto número de ciclos**.
$$CPI = \frac{\sum (NI_i \times CPI_i)}{N}$$ 
donde `NI_i` es el número total de instrucciones tipo `i`, `CPI_i` es el número de ciclos por instrucción y `N` es el número total de instrucciones.

- **MIPS (Millones de Instrucciones por Segundo)**
$$MIPS = \frac{N}{Tcpu \times 10^6}$$
	- **No es válido** para comparar procesadores con diferentes conjuntos de instrucciones.
	- **Depende del programa** ejecutado.

- **GFLOPS (GigaFLOPS)**
$$GFLOPS = \frac{FLOPS}{Tcpu \times 10^9}$$

	**Problema:** Dependiente del programa, como MIPS.

- **Ecuación Básica de Rendimiento:**
$$Tcpu = \frac{N \times CPI}{F}$$
- **N** = Número total de instrucciones.
- **CPI** = Ciclos por instrucción.
- **F** = Frecuencia del procesador (Hz).
- Permite **comparar arquitecturas** y evaluar cambios en los tres factores.

- **BenchMarks:** medida de prestaciones en comparación con un sistema de referencia y para un conjunto de programas de prueba.
	- Kernels (matrix multiply): programas tipicos
	- Programas de juguete (sorting): codigo simple
	- Benchmarks sintéticos (dhrystone): no ejecutan código con funcionalidad real.
	- Conjuntos de programas reales que simulan cargas de computación estándar.

- **LEY DE AMDAHL:**
**La posible mejroa de rendimiento está limitada por la proporcion en que se use la prestación mejorada**.

$$t_{\text{mejor}} = \frac{t_{\text{parte mejor}}}{\%_{\text{de mejora}}} + t_{\text{parte no mejor}} \Rightarrow t_{\text{mejor}} \geq t_{\text{parte no mejor}}$$

A un código que se ejecutaba en `t` se le aplica una mejora a un porcentaje de su ejecución `F`, que lo reduce en un factor `M`.
 $$t' = \frac{F \cdot t}{M} + (1 - F) \cdot t$$


## 1.9.1 Técnicas de Medida de Rendimiento
### Utilización de información mantenida por el SO
Los SOs actuales mantienen información sobre las diferentes tareas que se están ejecutando (*uso de memoria y de la CPU, número de tareas del sistema, tiempo de inicio y finalización de cada tarea, etc.*)

No hace falta desarollar **código específico** para realizar las medidas. 
Se añade **sobrecarga** al acceder a esta información. **Formato poco amigable** que impone bastantes restricciones. No mantiene información de **todos los elementos**.

### Monitores Software
Se ejecuta una **aplicación específicamente programada** para recoger y tratar la información necesaria. Tipos de monitores software:
- Detección de eventos
- Muestreo, cuenta eventos, almacena una traza.

Se adecúan a las necesidades de los usuarios recogiendo la **información necesaria**.
Se añade **sobrecarga** al acceder a esta información si se hace a menudo.

### Monitores Hardware
Los **fabricantes incluyen en el hardware** monitores que permiten contar con gran precisión una multitud de eventos (*utilización de memoria, utilización de CPU, alertas, etc.*).

No se consumen **recursos** (ni tiempo de CPU ni almacenamiento) y se pueden monitorizar **eventos de muy bajo nivel** que son transparentes para el software y el SO. Además son muy precisos.

Se miden **magnitudes físicas** (como la temperatura) y no lógicas. Requieren **librerías específicas**.

### Análisis de Programas - Profiling
Se utilizan medidas de tiempo y recursos **incluidas por el programador en su código**. Son útiles cuando la evaluación del rendimiento es a **alto nivel** y en términos de **optimización de código o de un sistema**.

No está sujeta a **errores aleaorios** como el muestreo. Sin embargo **sobrecargar la aplicación**.

### BenchMarks
Para evaluar el rendimiento de un sistema se puede usar un conjunto específico de programas de prueba conocidos como **BENCHMARKS**.
- La práctica estándar es usar conjuntos de programas de **aplicación real**.
- Los programas de prueba forman una carga con la que el usuario espera **predecir el rendimiento de la carga real del sistema**.

Para indicar las medidas se debe hacer un **informe** de forma que otra persona pueda reproducir los resultados (versión del SO, compilador, entradas, ...).
El rendimiento de la máquina medido con un benchmark se suele dar como un **único número**.

El grupo de programas de prueba más popular y completo es el **SPEC** (_Standard Performance Evaluation Corporation_).
- Se usan para medir **tiempo de CPU y productividad**. 
- Los 43 programas que se incluyen en la última versión de SPEC para procesador se agrupan en:
    - Carga computacional intensa en **punto flotante** (SPECfp2017).
    - Carga computacional intensa en **enteros** (SPECint2017).
- El **procesador**, la **memoria** y la **E/S** del sistema influyen en el valor medido, junto con el **programa utilizado**.
- Los tiempos de ejecución del sistema deben ser normalizados, para lo que se usa otro sistema como **referencia** (normalmente uno muy antiguo):
    - Ratio SPEC para un programa →
    $$SPEC = \frac{T_{CPU \ referencia}}{T_{CPU \ test}}$$
    - El test se repite para todos los programas del conjunto SPEC y se computa la **media geométrica** de los resultados:
	Ratio SPEC para un conjunto de $n$ programas
$$\text{velocidad SPEC} = \sqrt[n]{\prod_{i=1}^{n}(SPEC_i)}$$


### Conclusiones
- La **medida más importante** del rendimiento de un computador es el **tiempo de ejecución**. La **segunda más importante** es la **productividad**.
- El **tiempo de ejecución** en un procesador depende de:
    - La organización de su hardware (**CPI**).
    - Su ciclo de reloj (**T_ciclo**).
    - El número de instrucciones máquina ejecutadas (**NI**, **CPI**).
    - El compilador usado (**NI**).
- Existen otras métricas del rendimiento como los **MIPS** o **GFLOPS**.
- Los **benchmarks** nos permiten comparar tiempos de ejecución entre máquinas diferentes y obtener una **media normalizada del rendimiento**.
- La **ley de Amdahl** permite calcular la aceleración que se obtendrá al mejorar alguno de los subsistemas del conjunto.


# 1.10 Paralelismo de Datos
Existen aplicaciones estructuradas en tareas simples denominadas **Kernels** (conjuntos de instrucciones) que operan sobre muchos datos, con potencial de ejecución paralela:
- Por ejemplo, aplicaciones gráficas, multimedia y de realidad virtual
- En ellas es **fácil** disponer de hilos que puedan **operar en paralelo**, lo **difícil** es **proporcionar datos a la velocidad necesaria**.

![[Pasted image 20250406233458.png]]

## 1.10.1 Procesadores Vectoriales
Una posible solución es incluir en los procesadores **núcleos especializados** en el **procesamiento gráfico** para aprovechar el paralelismo de datos. AMD llama a este tipo de arquitectura APU, Intel no le da un nombre específico.

![[Pasted image 20250406233656.png]]

## 1.10.2 Extensiones Vectoriales
Otra posible solución es incluir en los **núcleos de propósito general** la posibilidad de **procesamiento vectorial**. Intel fue incorporando **instrucciones para procesamiento vectorial** en todos sus procesadores mediante las **extensiones MMX, SSE y AVX**.

Actualmente se pueden realizar operaciones en paralelo sobre **vectores de 256 bits** (es decir 8 operandos en float o 4 en double).

![[Pasted image 20250406234018.png]]

Las instrucciones vectoriales aumenta la **complejidad de la programación**. El aumento en velocidad suele compensar. Para tamaños de problema grandes se puede llegar a ganar hasta 8x en tiempo de ejecución si se usan operaciones AVX.

![[Pasted image 20250406234050.png]]

## 1.10.3 Microprocesadores Basados en Streaming
Los microprocesadores basados en streaming extienden el concepto del procesador vectorial (son usados en las tarjetas gráficas de Nvidia).

En lugar de organizar la información en vectores, usan **streams**, que son vectores de estructuras. EN lugar de instrucciones vectoriales simples, usan **kernels**, que actúan sobre cada uno de los elementos del stream.

![[Pasted image 20250406234452.png]]

EL **modelo de programación** basado en streams ofrece **más oportunidades de paralelismo** que el de programación paralela. 

![[Pasted image 20250406234519.png]]
![[Pasted image 20250406234536.png]]

La **programación** para estas unidades, (se suele realizar CUDA o OpenCL) es en general **más compleja** que en entornos habituales de programa. La **carga y escritura** de streams de datos a memoria son **responsabilidad del programador**. Ha habido un desarrollo reciente de muchas librerías  facilitan la programación para cualquier tipo de tarea.

![[Pasted image 20250406234600.png]]