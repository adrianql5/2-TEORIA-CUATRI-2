
# 1.1 Introducci√≥n a la Arquitectura de Computadores y Procesadores Multin√∫cleo
La arquitectura de computadores es el √°rea de la inform√°tica que estudia el dise√±o y la organizaci√≥n de los procesadores, la memoria y los sistemas de interconexi√≥n para optimizar el rendimiento de los sistemas de c√≥mputo. En esta asignatura abordaremos:

- **Modelos de computaci√≥n y Taxonom√≠a de Flynn**
- **Paralelismo y rendimiento** (ILP, TLP, RLP, GPUs)
- **Estructuras de microprocesadores y memoria cach√©**
- **Segmentaci√≥n de procesadores y ejecuci√≥n fuera de orden**

Dado el crecimiento de la demanda de procesamiento y las limitaciones f√≠sicas del modelo tradicional basado en el aumento de frecuencia, los procesadores actuales han evolucionado hacia arquitecturas multin√∫cleo que explotan el paralelismo.


## 1.1.1 Taxonom√≠a de Flynn y Modelos de Computaci√≥n
Michael J. Flynn propuso una clasificaci√≥n de los procesadores basada en el n√∫mero de flujos de **instrucciones** y **datos** que manejan simult√°neamente.

| Categor√≠a                                      | Flujo de Instrucciones | Flujo de Datos | Descripci√≥n                                                                |
| ---------------------------------------------- | ---------------------- | -------------- | -------------------------------------------------------------------------- |
| **SISD** (Single Instruction, Single Data)     | 1                      | 1              | Computaci√≥n secuencial tradicional (Ej: procesadores monon√∫cleo antiguos). |
| **SIMD** (Single Instruction, Multiple Data)   | 1                      | M√∫ltiples      | Ideal para procesamiento de gr√°ficos y c√°lculos vectoriales (Ej: GPUs).    |
| **MISD** (Multiple Instruction, Single Data)   | M√∫ltiples              | 1              | Poco com√∫n, usado en sistemas tolerantes a fallos.                         |
| **MIMD** (Multiple Instruction, Multiple Data) | M√∫ltiples              | M√∫ltiples      | Base de los procesadores multin√∫cleo modernos.                             |
![[Pasted image 20250403153030.png]]

Las arquitecturas **MIMD** han permitido el desarrollo de procesadores multin√∫cleo, lo que ha cambiado dr√°sticamente la forma en la que se ejecutan las aplicaciones.

## 1.1.2 Arquitecturas Multin√∫cleo y Paralelismo

### Arquitecturas MIMD y Procesadores Multin√∫cleo

Los procesadores actuales utilizan arquitecturas **MIMD**, donde m√∫ltiples n√∫cleos ejecutan instrucciones diferentes sobre distintos conjuntos de datos.

Existen dos tipos principales de sistemas multin√∫cleo:

- **Memoria compartida:** Todos los n√∫cleos acceden a la misma memoria RAM.
- **Memoria distribuida:** Cada n√∫cleo tiene su propia memoria y se comunica con otros mediante redes de interconexi√≥n.

### Tipos de Paralelismo
Para mejorar el rendimiento, los procesadores explotan distintos tipos de **paralelismo**:

1. **Instruction-Level Parallelism (ILP):**
    - Se logra mediante t√©cnicas como ejecuci√≥n fuera de orden y segmentaci√≥n.
    - Se ha alcanzado un l√≠mite en la cantidad de ILP explotable.

2. **Vector Architectures / GPUs (SIMD):**
    - Se aplican instrucciones a m√∫ltiples datos en paralelo.
    - Clave en gr√°ficos, inteligencia artificial y simulaciones cient√≠ficas.

3. **Thread-Level Parallelism (TLP):**
    - M√∫ltiples hilos ejecutados en paralelo en distintos n√∫cleos.
    - Programaci√≥n con **OpenMP, pthreads, CUDA**.

4. **Request-Level Parallelism (RLP):**
    - Procesamiento de m√∫ltiples solicitudes en paralelo.
    - Importante en servidores y bases de datos.


Para aprovechar el paralelismo, las aplicaciones deben reestructurarse para exponer tareas paralelizables.

## 1.1.3 Arquitectura Interna de un N√∫cleo y Memoria Cach√©
Los procesadores modernos utilizan una arquitectura jer√°rquica de **memoria cach√©** para minimizar los tiempos de acceso a la memoria principal.


| Nivel de Cach√©                    | Capacidad T√≠pica                      | Latencia      | Caracter√≠stica                         |
| --------------------------------- | ------------------------------------- | ------------- | -------------------------------------- |
| **L1 (Privada por n√∫cleo)**       | 32 KB (Datos) + 32 KB (Instrucciones) | ~4 ciclos     | Mayor velocidad, menor tama√±o.         |
| **L2 (Privada por n√∫cleo)**       | 256 KB                                | ~12 ciclos    | Equilibrio entre latencia y capacidad. |
| **L3 (Compartida entre n√∫cleos)** | 12MB - 32MB                           | ~26-31 ciclos | Gran capacidad, mayor latencia.        |

Los accesos a memoria principal tardan **centenas de ciclos**, por lo que si un dato no est√° en la cach√©, el procesador debe esperar, reduciendo el rendimiento.

**Imagen de un core:**
![[Pasted image 20250403154035.png]]

**Imagen de un microprocesador multin√∫cleo (LLC->las level cach√©):**
![[Pasted image 20250403154222.png]]

**Funcionamiento:**
- Al realizar una operaci√≥n **Load/Store**, el procesador verifica primero en cach√©.
- Si el dato no est√°, se carga desde el siguiente nivel de cach√© o desde memoria RAM.
- La organizaci√≥n en **l√≠neas de cach√©** (64B por l√≠nea) optimiza la transferencia de datos.


Los procesadores utilizan memoria virtual, lo que significa que deben traducir direcciones l√≥gicas en direcciones f√≠sicas. Para acelerar este proceso, incorporan **buffers de traducci√≥n de direcciones (TLBs)**:

| TLB                         | Funci√≥n                               |
| --------------------------- | ------------------------------------- |
| **DTLB (Data TLB)**         | Traduce direcciones de datos.         |
| **ITLB (Instruction TLB)**  | Traduce direcciones de instrucciones. |
| **STLB (Second-Level TLB)** | Cache unificada de traducci√≥n.        |

Los TLBs almacenan direcciones recientemente traducidas para evitar accesos frecuentes a la tabla de p√°ginas, reduciendo la latencia en la gesti√≥n de memoria.

## 1.1.4 Segmentaci√≥n de Procesadores y Ejecuci√≥n Fuera de Orden**

### **5.1. Segmentaci√≥n del Pipeline**
Un procesador moderno **divide** la ejecuci√≥n de instrucciones en etapas. Esto permite procesar varias instrucciones simult√°neamente.

| Etapa             | Funci√≥n                                            |
| ----------------- | -------------------------------------------------- |
| **Fetch**         | Se obtienen las instrucciones de la memoria cach√©. |
| **Decode**        | Se decodifican las instrucciones.                  |
| **Execute**       | Se ejecutan en unidades funcionales.               |
| **Memory Access** | Se accede a la memoria si es necesario.            |
| **Write Back**    | Se escriben los resultados en los registros.       |

Cuanto m√°s profundo es el pipeline (m√°s etapas), m√°s instrucciones pueden ejecutarse simult√°neamente, pero **mayores son las penalizaciones en caso de fallos de predicci√≥n de saltos**.

### **5.2. Ejecuci√≥n Fuera de Orden y Predicci√≥n de Saltos**

Los procesadores modernos son capaces de **reordenar instrucciones** para ejecutar primero las que no dependan de resultados previos. Sin embargo:

- Si una instrucci√≥n depende de un dato a√∫n no calculado, el procesador **debe esperar**.
- Para mitigar esto, se usa la **predicci√≥n de saltos**, que intenta anticipar el flujo del programa.
- Si la predicci√≥n falla, el procesador debe **descartar** instrucciones y volver a empezar, lo que afecta al rendimiento.

# 1.2 Tecnolog√≠as de Fabricaci√≥n y Escalamiento
## 1.2.1 Tecnolog√≠a de fabricaci√≥n de microprocesadores
Los microprocesadores est√°n formados por **millones o incluso miles de millones de transistores**, que funcionan como interruptores electr√≥nicos para procesar datos. Estos transistores est√°n fabricados con **tecnolog√≠a CMOS** (_Complementary Metal-Oxide-Semiconductor_), que permite alta eficiencia energ√©tica y escalabilidad.


## 1.2.2 ¬øQu√© es un nodo tecnol√≥gico?
Un **nodo tecnol√≥gico** se refiere al **tama√±o m√≠nimo de los transistores y las interconexiones** en un proceso de fabricaci√≥n. Este tama√±o se mide en nan√≥metros (nm) y define la generaci√≥n de un microprocesador. Ejemplo de nodos tecnol√≥gicos utilizados en la industria:
- **45 nm** (2008)
- **32 nm** (2010)
- **22 nm** (2012)
- **14 nm** (2014)
- **7 nm** (2018)
- **5 nm** (2020)
- **3 nm** (2023)

A menor tama√±o del nodo, **mayor cantidad de transistores** se pueden colocar en el mismo espacio, lo que mejora la potencia de c√≥mputo y la eficiencia energ√©tica.

## 1.2.3 Escalamiento de las dimensiones
Cada nuevo nodo tecnol√≥gico sigue un patr√≥n de **reducci√≥n del tama√±o de los transistores**.
- Cuando se pasa de un nodo a otro, las dimensiones de los transistores y conexiones se reducen en un **factor de 0.7**.
- Como el √°rea de un transistor es proporcional al cuadrado de sus dimensiones lineales, el √°rea total se reduce en un **factor de 0.5**.

Ejemplo pr√°ctico:
- Un procesador fabricado en **65 nm** con un √°rea de **2 cm¬≤** pasar√≠a a ocupar solo **1 cm¬≤** en una tecnolog√≠a de **45 nm**.

- Si el √°rea del procesador **se mantiene**, esto significa que se pueden incluir **m√°s transistores** en la nueva generaci√≥n, lo que permite a√±adir m√°s unidades funcionales, m√°s memoria cach√©, etc.    

Sin embargo, **no todas las partes del procesador escalan igual**.
- **Memorias cach√©** escalan casi perfectamente (x0.5).
- **N√∫cleos de procesamiento** pueden escalar menos eficientemente (x0.6 o x0.7), debido a la complejidad de sus circuitos.

Esta tendencia de duplicar el n√∫mero de transistores con cada nueva generaci√≥n se conoce como **Ley de Moore**.


## 1.2.4 Potencia Din√°mica
La **potencia din√°mica** es la energ√≠a consumida cuando los transistores cambian de estado (**de 0 a 1 o de 1 a 0**). Esto ocurre cada vez que el procesador ejecuta instrucciones.

### **F√≥rmula de la potencia din√°mica en CMOS:**
$$P_{din√°mica} = \frac{1}{2} C V^2 f$$

Donde:
- **C** = Carga capacitiva
- **V** = Voltaje de alimentaci√≥n
- **f** = Frecuencia de reloj
### **Factores que afectan la potencia din√°mica:**
**Carga capacitiva (C):**
- Depende del **n√∫mero de transistores activos** y de la **capacitancia de cables y transistores**.
- En cada nueva generaci√≥n, la carga capacitiva **no escala eficientemente** (se reduce solo un **factor de 0.8**), mientras que el n√∫mero de transistores **se duplica (x2)**.

**Frecuencia de reloj (f):**
- A mayor frecuencia, **m√°s conmutaciones** por segundo ‚Üí **mayor consumo energ√©tico**.
- La industria ha limitado el aumento de la frecuencia por problemas de consumo y calor.

**Voltaje de alimentaci√≥n (V):**
- La potencia es **proporcional al cuadrado del voltaje**, lo que significa que **reducir V** ayuda significativamente a disminuir el consumo energ√©tico.
- Sin embargo, reducir demasiado el voltaje afecta la estabilidad del procesador.

## 1.2.5 Potencia Est√°tica (o de fuga)
La **potencia est√°tica** es la energ√≠a consumida **incluso cuando el procesador est√° inactivo**. Se debe a **corrientes de fuga** que atraviesan los transistores aunque no est√©n cambiando de estado.
### **F√≥rmula de la potencia est√°tica en CMOS:**
$$P_{est√°tica} = I_{fuga} \times V$$

Donde:
- **I_fuga** = Corriente de fuga
- **V** = Voltaje de alimentaci√≥n

### **Factores que afectan la potencia est√°tica:**
**Corriente de fuga (I_fuga):**
- Crece **exponencialmente** con cada nueva generaci√≥n. 
- Puede representar hasta **40% de la potencia total** en algunos chips modernos.

**N√∫mero de transistores:**
- Como los transistores **se duplican** con cada generaci√≥n, el consumo est√°tico tambi√©n **aumenta**.
- Especialmente problem√°tico en **memorias cach√© grandes**, donde puede llegar al **50% del consumo total**.


## 1.2.6 Escalamiento de la potencia y consumo energ√©tico
Uno de los principales problemas del escalamiento es el **aumento del consumo de potencia** y la disipaci√≥n de calor.
### **Factores que afectan el consumo de potencia en CMOS:**

- **N√∫mero de transistores activos** ‚Üí Aumenta con cada nueva generaci√≥n.
- **Frecuencia de reloj** ‚Üí Cuanto m√°s alta es la frecuencia, m√°s r√°pido se ejecutan las instrucciones, pero tambi√©n mayor consumo energ√©tico.
- **Voltaje de alimentaci√≥n** ‚Üí La potencia consumida es proporcional al **cuadrado** del voltaje.


Aunque el consumo de **cada transistor** se reduce en un **factor de 0.8** con cada nueva generaci√≥n, el **doble de transistores** significa que el consumo total sigue aumentando.

Adem√°s, hay otro problema: **las corrientes de fuga**.

- Estas corrientes son p√©rdidas de energ√≠a que no realizan trabajo √∫til.
- **Aumentan exponencialmente** con cada generaci√≥n tecnol√≥gica.
- Actualmente pueden representar hasta **30% del consumo total de un chip**.

### **Hot Spots y limitaciones t√©rmicas**
- En algunas √°reas del chip, la **densidad de potencia** (W/cm¬≤) es mucho m√°s alta, lo que genera **hot spots** o puntos calientes.
- Estos hot spots aparecen en partes del procesador que realizan c√°lculos intensivos, como las **unidades de ejecuci√≥n de direcciones**.
- Para evitar sobrecalentamiento, se deben usar **sistemas de refrigeraci√≥n avanzados**.

Un l√≠mite razonable de densidad de potencia para un sistema multiprocesador es **10 kW/m¬≤**. Si se supera, se requieren **m√©todos de enfriamiento avanzados y costosos**, como refrigeraci√≥n l√≠quida o sistemas criog√©nicos.

## 1.2.7 M√©tricas de eficiencia en microprocesadores
Para evaluar el rendimiento de los microprocesadores, se utilizan m√©tricas como:

1. **GFLOPS/Watt** ‚Üí Mide la eficiencia energ√©tica del procesador en **operaciones de punto flotante por segundo por cada watt consumido**.

2. **GFLOPS/mm¬≤** ‚Üí Mide la eficiencia de c√≥mputo por unidad de √°rea del chip.

3. **GFLOPS/m¬≤** ‚Üí Indica la **densidad de c√≥mputo** en un centro de datos, tomando en cuenta la refrigeraci√≥n por ventilaci√≥n.
  ![[Pasted image 20250403161418.png]]
### **Impacto de peque√±os aumentos de consumo**
- Si un procesador tiene **muy bajo consumo (0.5 W)**, un incremento fijo de **0.1 W** puede reducir dr√°sticamente su eficiencia energ√©tica en t√©rminos de **GFLOPS/Watt**.
- Un ejemplo es el **ARM Mote**, que pierde rendimiento al aumentar ligeramente el consumo fijo.

![[Pasted image 20250403161442.png]]

## 1.2.8 Consumo de Potencia (TDP) y Evoluci√≥n Energ√©tica en Microprocesadores
### **1. Evoluci√≥n del Consumo de Potencia (TDP)**
üîπ **L√≠mite de disipaci√≥n de 100-200 W**
- M√°s all√° de este l√≠mite, los **ventiladores tradicionales no pueden disipar el calor de manera eficiente**.
- Ser√≠a necesario usar **refrigeraci√≥n l√≠quida o t√©cnicas avanzadas** de disipaci√≥n t√©rmica, lo que aumenta los costos.
### **2. Potencia Consumida a lo Largo del Tiempo**
- **Intel 80386 (1985):** **2 W**
- **Intel Core i7 (3.3 GHz, 2020):** **130 W** 
- **Supera el l√≠mite de refrigeraci√≥n por aire** (los chips modernos de 1.5 cm¬≤ no pueden disipar m√°s calor sin m√©todos avanzados).

**L√≠mite t√©rmico:** Un **procesador m√°s potente no siempre es mejor si genera demasiado calor**.

### **3. T√©cnicas para Aumentar la Eficiencia Energ√©tica**
**1. Apagado de reloj en m√≥dulos inactivos**
- Cuando una unidad no est√° en uso, se **detiene su reloj** para evitar consumo innecesario.
 
**2. Escalado Din√°mico de Voltaje-Frecuencia (DVFS)**
- Cuando el procesador est√° inactivo, **reduce su frecuencia y voltaje** para ahorrar energ√≠a.
 
**3. Estados de baja potencia para memoria y almacenamiento**
- **Memorias DRAM y discos duros** pueden entrar en modo de bajo consumo cuando no se usan.

**4. Overclocking y Turbo Boost**
- **Intel Turbo Boost (desde 2008)** permite que la CPU **aumente su frecuencia hasta un 10% m√°s** por cortos per√≠odos.
- Para compensar el aumento de temperatura, **se apagan algunos n√∫cleos** y se **sube la frecuencia de los n√∫cleos activos**.
- **L√≠mite:** No puede mantenerse por mucho tiempo debido a la temperatura.

**Conclusi√≥n:** La eficiencia energ√©tica es clave para el dise√±o moderno de procesadores.



## 1.2.9 Escalamiento del Retardo en Circuitos CMOS
El **retardo** en los circuitos CMOS es un factor clave en la velocidad de los microprocesadores. A medida que la **tecnolog√≠a avanza** (reducci√≥n de nodo tecnol√≥gico), los transistores se hacen m√°s peque√±os, lo que **reduce el retardo** de los circuitos de manera **aproximadamente lineal**.

### **¬øC√≥mo Escala el Retardo de los Circuitos?**

**Regla general:**
- El **retardo se reduce en un factor de 0.7** con cada nueva generaci√≥n de tecnolog√≠a.
- Es decir, si en una tecnolog√≠a de **65 nm** un circuito tiene un retardo de **10 ps**, en **45 nm** ser√≠a aproximadamente **7 ps**.

**Expresi√≥n en t√©rminos de FO4 (Fanout-of-Four):**
- No se expresa en unidades absolutas (ps) sino en t√©rminos de **FO4**, que representa el **retardo de un inversor cargado con 4 inversores**.
- Se ha comprobado que los retardos en unidades de **FO4** **son independientes del nodo tecnol√≥gico**, lo que permite comparar circuitos de distintas generaciones.

**Ejemplo:**
- Un sumador r√°pido tiene un **retardo de 10 FO4**.  
- Esto significa que **su retardo es 10 veces el retardo de un inversor con carga de 4 inversores**.

### **Conversi√≥n de FO4 a Retardos Absolutos**
**F√≥rmula Experimental:**

$$1 FO4 = 0.2 \times T \text{ (nm)} \quad (\text{en picosegundos})$$

- **Ejemplo en tecnolog√≠a de 45 nm:**
$$1 FO4 = 0.2 \times 45 = 9 ps$$
- **Ejemplo en tecnolog√≠a de 65 nm:**
$$1 FO4 = 0.2 \times 65 = 13 ps$$

**Ejemplo de C√°lculo de Frecuencia de Reloj:**  
Si un microprocesador tiene un **ciclo de reloj de 13 FO4**, su **frecuencia** en diferentes tecnolog√≠as es:

- **45 nm:** 
$$f = \frac{1}{13 \times 9 \text{ ps}} = 8.5 \text{ GHz}$$

- **65 nm:**
$$f = \frac{1}{13 \times 13 \text{ ps}} = 5.9 \text{ GHz}$$

üîπ **Conclusi√≥n:**  
**A menor nodo tecnol√≥gico, menor retardo y mayor frecuencia de reloj.**

---

## **3. Evoluci√≥n del Reloj en Microprocesadores Intel**

üìå **Ejemplos Hist√≥ricos:**

1. **Pentium II (1997):**
    
    - **Frecuencia:** **300 MHz**
        
    - **Tecnolog√≠a:** **350 nm**
        
    - **Ciclo de reloj:** **47 FO4**
        
2. **Pentium 4 HyperThreading (2002):**
    
    - **Frecuencia:** **3 GHz**
        
    - **Tecnolog√≠a:** **130 nm**
        
    - **Ciclo de reloj:** **12.5 FO4**
        

üí° **Observaci√≥n:**

- **El Pentium 4 ten√≠a un pipeline mucho m√°s profundo**, lo que permit√≠a alcanzar **mayores frecuencias**.
    
- Sin embargo, **m√°s etapas en el pipeline pueden aumentar la latencia en ciertos tipos de instrucciones**.
    

---

## **4. Relaci√≥n entre Latencia, Potencia y √Årea**

üìå **Regla emp√≠rica:**

Latencia3√óPotencia=cte(L)\text{Latencia}^3 \times \text{Potencia} = \text{cte} (L)

- Si reducimos la **latencia a la mitad (x0.5)**, la **potencia aumenta x8**.
    
- **La constante disminuye con el avance tecnol√≥gico**, lo que significa que los chips m√°s modernos pueden operar con menor potencia relativa.
    

üìå **Efecto de la Reducci√≥n del Voltaje en la Frecuencia y Potencia**

üîπ **Relaci√≥n Voltaje-Frecuencia:**

Kf=1.45Kv‚àí0.40K_f = 1.45 K_v - 0.40

- Si bajamos el voltaje en **x0.6**, la frecuencia **se reduce en x0.5**.
    

üîπ **Impacto en la Potencia:**

P‚àùKf√óKv2P \propto K_f \times K_v^2

- **Ejemplo:** Si **K_v = 0.6** y **K_f = 0.5**, la **potencia cae en x0.2**.
    

üí° **Conclusi√≥n:**

- **Escalar el voltaje es clave para reducir el consumo energ√©tico.**
    
- **Se usa en t√©cnicas como el escalado din√°mico de voltaje para ahorrar energ√≠a en momentos de baja demanda.**
    

---

## **5. Relaci√≥n entre √Årea y Latencia**

üìå **Regla emp√≠rica:**

AÀärea√óLatencian=cte(L)\text{√Årea} \times \text{Latencia}^n = \text{cte} (L)

- **Si n = 2**, reducir la latencia a **x0.5** aumenta el √°rea en **x4**.
    

üîπ **Conclusi√≥n:**

- **Reducir la latencia exige m√°s √°rea**, lo que puede afectar los costos de fabricaci√≥n y consumo energ√©tico.
    

---

## **6. Evoluci√≥n de la Tecnolog√≠a y su Impacto en el Consumo de Potencia**

üìå **Figura 12 (Procesadores Intel Xeon):**

- Cada nueva generaci√≥n de tecnolog√≠a **reduce el consumo de energ√≠a a igual nivel de rendimiento**.
    
- Tambi√©n permite **mayor rendimiento sin aumentar la potencia consumida**.
    

üìå **Figura 13 (Relaci√≥n Potencia-√Årea-Rendimiento en 45 nm):**

- **Gr√°fica izquierda:** Relaci√≥n **potencia vs rendimiento**.
    
    - La curva sigue una **tendencia c√∫bica**, indicando que aumentar el rendimiento **exige mucho m√°s consumo de energ√≠a**.
        
- **Gr√°fica derecha:** Relaci√≥n **√°rea vs rendimiento**.
    
    - Sigue una **tendencia cuadr√°tica**, indicando que aumentar el rendimiento **requiere chips m√°s grandes**.
        

üí° **Conclusi√≥n:**

- **Las mejoras tecnol√≥gicas permiten hacer m√°s eficientes los procesadores en consumo de energ√≠a.**
    
- **A mayor rendimiento, se paga un costo alto en consumo de potencia y √°rea.**
    

---

## **7. Conclusi√≥n General**

üìå **Escalamiento del Retardo:**

- El **retardo de los circuitos se reduce en x0.7 por cada nodo tecnol√≥gico**.
    
- Se usa el **FO4** como referencia para medir retardos de circuitos.
    
- **Ejemplo:** **45 nm ‚Üí 9 ps por FO4** | **65 nm ‚Üí 13 ps por FO4**.
    

üìå **Frecuencia de Reloj:**

- **Ejemplo:** **Pentium II (1997) ‚Üí 300 MHz | Pentium 4 (2002) ‚Üí 3 GHz**.
    
- **Procesadores m√°s modernos tienen pipelines m√°s profundos para alcanzar mayores frecuencias.**
    

üìå **Relaciones Clave:**

1. **Latencia¬≥ √ó Potencia = constante** (Reducir latencia aumenta consumo).
    
2. **Voltaje y frecuencia est√°n relacionados** (Reducir voltaje disminuye la frecuencia).
    
3. **√Årea y latencia tienen relaci√≥n cuadr√°tica** (Reducir latencia aumenta √°rea).
    

üìå **Evoluci√≥n de Tecnolog√≠as:**

- **Los procesadores modernos usan t√©cnicas de escalado de voltaje para ahorrar energ√≠a.**
    
- **Los nuevos nodos tecnol√≥gicos permiten m√°s rendimiento con menor consumo.**
    
- **Cada nueva generaci√≥n mejora eficiencia energ√©tica y potencia de c√≥mputo.**
    

üöÄ **Futuro:**

- Uso masivo del **escalado din√°mico de voltaje**.
    
- Dise√±o de **arquitecturas m√°s eficientes en consumo de energ√≠a**.
    
- **Chips 3D y transistores avanzados** para seguir mejorando la computaci√≥n sin aumentar la energ√≠a consumida.




## **4. Ancho de Banda y Latencia**

üìå **Ancho de Banda:**

- **Definici√≥n:** Cantidad de trabajo que puede hacerse en un tiempo dado.
    
- **Mejoras:**
    
    - **Procesadores:** Se ha mejorado **32,000-40,000X**.
        
    - **Memoria y discos:** Se ha mejorado **300-1,200X**.
        

üìå **Latencia:**

- **Definici√≥n:** Tiempo entre que se inicia y se finaliza una operaci√≥n.
    
- **Mejoras:**
    
    - **Procesadores:** Se ha reducido **50-90X**.
        
    - **Memoria y discos:** Se ha reducido **6-8X**.
        

üîπ **Problema clave:**

- **Los procesadores piden datos m√°s r√°pido de lo que la memoria puede entregarlos**.
    
- **La latencia de memoria es mucho mayor que la velocidad de procesamiento**.
    

---

## **5. Ancho de Banda de Memoria y su Escalabilidad**

üìå **Tendencia hist√≥rica:**

- No siempre aumenta con cada nueva generaci√≥n.
    
- Generalmente **se duplica con cada nodo tecnol√≥gico**.
    

üìå **F√≥rmula del Ancho de Banda M√°ximo (BWM):**

BWM=N√óFIP√óCPIcorei(bytes/s)BWM = \frac{N \times F}{IP \times CPI_{\text{corei}}} \quad (\text{bytes/s})

Donde:

- **N** = N√∫mero de n√∫cleos.
    
- **F** = Frecuencia del procesador.
    
- **IP** = Intensidad operacional (instrucciones/byte).
    
- **CPI** = Ciclos por instrucci√≥n.
    

üí° **Conclusi√≥n:**

- **El ancho de banda debe escalar con el n√∫mero de n√∫cleos, frecuencia y eficiencia de ejecuci√≥n**.
- **La latencia y la potencia est√°n ligadas**: si una mejora en latencia aumenta la potencia consumida, puede haber un **compromiso entre rendimiento y consumo**.
