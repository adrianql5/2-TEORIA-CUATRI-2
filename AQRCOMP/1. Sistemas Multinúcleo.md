# 1.1 Introducci√≥n a la Arquitectura de Computadores y Procesadores Multin√∫cleo
La arquitectura de computadores es el √°rea de la inform√°tica que estudia el dise√±o y la organizaci√≥n de los procesadores, la memoria y los sistemas de interconexi√≥n para optimizar el rendimiento de los sistemas de c√≥mputo. En esta asignatura abordaremos:

- **Modelos de computaci√≥n y Taxonom√≠a de Flynn**
- **Paralelismo y rendimiento** (ILP, TLP, RLP, GPUs)
- **Estructuras de microprocesadores y memoria cach√©**
- **Segmentaci√≥n de procesadores y ejecuci√≥n fuera de orden**

Dado el crecimiento de la demanda de procesamiento y las limitaciones f√≠sicas del modelo tradicional basado en el aumento de frecuencia, los procesadores actuales han evolucionado hacia arquitecturas multin√∫cleo que explotan el paralelismo.


## 1.1.1 Taxonom√≠a de Flynn y Modelos de Computaci√≥n
Michael J. Flynn propuso una clasificaci√≥n de los procesadores basada en el n√∫mero de flujos de **instrucciones** y **datos** que manejan simult√°neamente.

| Categor√≠a                                      | Flujo de Instrucciones | Flujo de Datos | Descripci√≥n                                                                |
| ---------------------------------------------- | ---------------------- | -------------- | -------------------------------------------------------------------------- |
| **SISD** (Single Instruction, Single Data)     | 1                      | 1              | Computaci√≥n secuencial tradicional (Ej: procesadores monon√∫cleo antiguos). |
| **SIMD** (Single Instruction, Multiple Data)   | 1                      | M√∫ltiples      | Ideal para procesamiento de gr√°ficos y c√°lculos vectoriales (Ej: GPUs).    |
| **MISD** (Multiple Instruction, Single Data)   | M√∫ltiples              | 1              | Poco com√∫n, usado en sistemas tolerantes a fallos.                         |
| **MIMD** (Multiple Instruction, Multiple Data) | M√∫ltiples              | M√∫ltiples      | Base de los procesadores multin√∫cleo modernos.                             |
![[Pasted image 20250403153030.png]]

Las arquitecturas **MIMD** han permitido el desarrollo de procesadores multin√∫cleo, lo que ha cambiado dr√°sticamente la forma en la que se ejecutan las aplicaciones.

## 1.1.2 Arquitecturas Multin√∫cleo y Paralelismo

### Arquitecturas MIMD y Procesadores Multin√∫cleo

Los procesadores actuales utilizan arquitecturas **MIMD**, donde m√∫ltiples n√∫cleos ejecutan instrucciones diferentes sobre distintos conjuntos de datos.

Existen dos tipos principales de sistemas multin√∫cleo:

- **Memoria compartida:** Todos los n√∫cleos acceden a la misma memoria RAM.
- **Memoria distribuida:** Cada n√∫cleo tiene su propia memoria y se comunica con otros mediante redes de interconexi√≥n.

### Tipos de Paralelismo
Para mejorar el rendimiento, los procesadores explotan distintos tipos de **paralelismo**:

1. **Instruction-Level Parallelism (ILP):**
    - Se logra mediante t√©cnicas como ejecuci√≥n fuera de orden y segmentaci√≥n.
    - Se ha alcanzado un l√≠mite en la cantidad de ILP explotable.

2. **Vector Architectures / GPUs (SIMD):**
    - Se aplican instrucciones a m√∫ltiples datos en paralelo.
    - Clave en gr√°ficos, inteligencia artificial y simulaciones cient√≠ficas.

3. **Thread-Level Parallelism (TLP):**
    - M√∫ltiples hilos ejecutados en paralelo en distintos n√∫cleos.
    - Programaci√≥n con **OpenMP, pthreads, CUDA**.

4. **Request-Level Parallelism (RLP):**
    - Procesamiento de m√∫ltiples solicitudes en paralelo.
    - Importante en servidores y bases de datos.


Para aprovechar el paralelismo, las aplicaciones deben reestructurarse para exponer tareas paralelizables.

## 1.1.3 Arquitectura Interna de un N√∫cleo y Memoria Cach√©
Los procesadores modernos utilizan una arquitectura jer√°rquica de **memoria cach√©** para minimizar los tiempos de acceso a la memoria principal.


| Nivel de Cach√©                    | Capacidad T√≠pica                      | Latencia      | Caracter√≠stica                         |
| --------------------------------- | ------------------------------------- | ------------- | -------------------------------------- |
| **L1 (Privada por n√∫cleo)**       | 32 KB (Datos) + 32 KB (Instrucciones) | ~4 ciclos     | Mayor velocidad, menor tama√±o.         |
| **L2 (Privada por n√∫cleo)**       | 256 KB                                | ~12 ciclos    | Equilibrio entre latencia y capacidad. |
| **L3 (Compartida entre n√∫cleos)** | 12MB - 32MB                           | ~26-31 ciclos | Gran capacidad, mayor latencia.        |

Los accesos a memoria principal tardan **centenas de ciclos**, por lo que si un dato no est√° en la cach√©, el procesador debe esperar, reduciendo el rendimiento.

**Imagen de un core:**
![[Pasted image 20250403154035.png]]

**Imagen de un microprocesador multin√∫cleo (LLC->las level cach√©):**
![[Pasted image 20250403154222.png]]

**Funcionamiento:**
- Al realizar una operaci√≥n **Load/Store**, el procesador verifica primero en cach√©.
- Si el dato no est√°, se carga desde el siguiente nivel de cach√© o desde memoria RAM.
- La organizaci√≥n en **l√≠neas de cach√©** (64B por l√≠nea) optimiza la transferencia de datos.


Los procesadores utilizan memoria virtual, lo que significa que deben traducir direcciones l√≥gicas en direcciones f√≠sicas. Para acelerar este proceso, incorporan **buffers de traducci√≥n de direcciones (TLBs)**:

| TLB                         | Funci√≥n                               |
| --------------------------- | ------------------------------------- |
| **DTLB (Data TLB)**         | Traduce direcciones de datos.         |
| **ITLB (Instruction TLB)**  | Traduce direcciones de instrucciones. |
| **STLB (Second-Level TLB)** | Cache unificada de traducci√≥n.        |

Los TLBs almacenan direcciones recientemente traducidas para evitar accesos frecuentes a la tabla de p√°ginas, reduciendo la latencia en la gesti√≥n de memoria.

## 1.1.4 Segmentaci√≥n de Procesadores y Ejecuci√≥n Fuera de Orden**

### **5.1. Segmentaci√≥n del Pipeline**
Un procesador moderno **divide** la ejecuci√≥n de instrucciones en etapas. Esto permite procesar varias instrucciones simult√°neamente.

| Etapa             | Funci√≥n                                            |
| ----------------- | -------------------------------------------------- |
| **Fetch**         | Se obtienen las instrucciones de la memoria cach√©. |
| **Decode**        | Se decodifican las instrucciones.                  |
| **Execute**       | Se ejecutan en unidades funcionales.               |
| **Memory Access** | Se accede a la memoria si es necesario.            |
| **Write Back**    | Se escriben los resultados en los registros.       |

Cuanto m√°s profundo es el pipeline (m√°s etapas), m√°s instrucciones pueden ejecutarse simult√°neamente, pero **mayores son las penalizaciones en caso de fallos de predicci√≥n de saltos**.

### **5.2. Ejecuci√≥n Fuera de Orden y Predicci√≥n de Saltos**

Los procesadores modernos son capaces de **reordenar instrucciones** para ejecutar primero las que no dependan de resultados previos. Sin embargo:

- Si una instrucci√≥n depende de un dato a√∫n no calculado, el procesador **debe esperar**.
- Para mitigar esto, se usa la **predicci√≥n de saltos**, que intenta anticipar el flujo del programa.
- Si la predicci√≥n falla, el procesador debe **descartar** instrucciones y volver a empezar, lo que afecta al rendimiento.

# 1.2 Tecnolog√≠as de Fabricaci√≥n y Escalamiento
## 1.2.1 Tecnolog√≠a de fabricaci√≥n de microprocesadores
Los microprocesadores est√°n formados por **millones o incluso miles de millones de transistores**, que funcionan como interruptores electr√≥nicos para procesar datos. Estos transistores est√°n fabricados con **tecnolog√≠a CMOS** (_Complementary Metal-Oxide-Semiconductor_), que permite alta eficiencia energ√©tica y escalabilidad.


## 1.2.2 ¬øQu√© es un nodo tecnol√≥gico?
Un **nodo tecnol√≥gico** se refiere al **tama√±o m√≠nimo de los transistores y las interconexiones** en un proceso de fabricaci√≥n. Este tama√±o se mide en nan√≥metros (nm) y define la generaci√≥n de un microprocesador. Ejemplo de nodos tecnol√≥gicos utilizados en la industria:
- **45 nm** (2008)
- **32 nm** (2010)
- **22 nm** (2012)
- **14 nm** (2014)
- **7 nm** (2018)
- **5 nm** (2020)
- **3 nm** (2023)

A menor tama√±o del nodo, **mayor cantidad de transistores** se pueden colocar en el mismo espacio, lo que mejora la potencia de c√≥mputo y la eficiencia energ√©tica.

## 1.2.3 Escalamiento de las dimensiones
Cada nuevo nodo tecnol√≥gico sigue un patr√≥n de **reducci√≥n del tama√±o de los transistores**.
- Cuando se pasa de un nodo a otro, las dimensiones de los transistores y conexiones se reducen en un **factor de 0.7**.
- Como el √°rea de un transistor es proporcional al cuadrado de sus dimensiones lineales, el √°rea total se reduce en un **factor de 0.5**.

Ejemplo pr√°ctico:
- Un procesador fabricado en **65 nm** con un √°rea de **2 cm¬≤** pasar√≠a a ocupar solo **1 cm¬≤** en una tecnolog√≠a de **45 nm**.

- Si el √°rea del procesador **se mantiene**, esto significa que se pueden incluir **m√°s transistores** en la nueva generaci√≥n, lo que permite a√±adir m√°s unidades funcionales, m√°s memoria cach√©, etc.    

Sin embargo, **no todas las partes del procesador escalan igual**.
- **Memorias cach√©** escalan casi perfectamente (x0.5).
- **N√∫cleos de procesamiento** pueden escalar menos eficientemente (x0.6 o x0.7), debido a la complejidad de sus circuitos.

Esta tendencia de duplicar el n√∫mero de transistores con cada nueva generaci√≥n se conoce como **Ley de Moore**.


## 1.2.4 Potencia Din√°mica
La **potencia din√°mica** es la energ√≠a consumida cuando los transistores cambian de estado (**de 0 a 1 o de 1 a 0**). Esto ocurre cada vez que el procesador ejecuta instrucciones.

### **F√≥rmula de la potencia din√°mica en CMOS:**
$$P_{din√°mica} = \frac{1}{2} C V^2 f$$

Donde:
- **C** = Carga capacitiva
- **V** = Voltaje de alimentaci√≥n
- **f** = Frecuencia de reloj
### **Factores que afectan la potencia din√°mica:**
**Carga capacitiva (C):**
- Depende del **n√∫mero de transistores activos** y de la **capacitancia de cables y transistores**.
- En cada nueva generaci√≥n, la carga capacitiva **no escala eficientemente** (se reduce solo un **factor de 0.8**), mientras que el n√∫mero de transistores **se duplica (x2)**.

**Frecuencia de reloj (f):**
- A mayor frecuencia, **m√°s conmutaciones** por segundo ‚Üí **mayor consumo energ√©tico**.
- La industria ha limitado el aumento de la frecuencia por problemas de consumo y calor.

**Voltaje de alimentaci√≥n (V):**
- La potencia es **proporcional al cuadrado del voltaje**, lo que significa que **reducir V** ayuda significativamente a disminuir el consumo energ√©tico.
- Sin embargo, reducir demasiado el voltaje afecta la estabilidad del procesador.

## 1.2.5 Potencia Est√°tica (o de fuga)
La **potencia est√°tica** es la energ√≠a consumida **incluso cuando el procesador est√° inactivo**. Se debe a **corrientes de fuga** que atraviesan los transistores aunque no est√©n cambiando de estado.
### **F√≥rmula de la potencia est√°tica en CMOS:**
$$P_{est√°tica} = I_{fuga} \times V$$

Donde:
- **I_fuga** = Corriente de fuga
- **V** = Voltaje de alimentaci√≥n

### **Factores que afectan la potencia est√°tica:**
**Corriente de fuga (I_fuga):**
- Crece **exponencialmente** con cada nueva generaci√≥n. 
- Puede representar hasta **40% de la potencia total** en algunos chips modernos.

**N√∫mero de transistores:**
- Como los transistores **se duplican** con cada generaci√≥n, el consumo est√°tico tambi√©n **aumenta**.
- Especialmente problem√°tico en **memorias cach√© grandes**, donde puede llegar al **50% del consumo total**.


## 1.2.6 Escalamiento de la potencia y consumo energ√©tico
Uno de los principales problemas del escalamiento es el **aumento del consumo de potencia** y la disipaci√≥n de calor.
### **Factores que afectan el consumo de potencia en CMOS:**

- **N√∫mero de transistores activos** ‚Üí Aumenta con cada nueva generaci√≥n.
- **Frecuencia de reloj** ‚Üí Cuanto m√°s alta es la frecuencia, m√°s r√°pido se ejecutan las instrucciones, pero tambi√©n mayor consumo energ√©tico.
- **Voltaje de alimentaci√≥n** ‚Üí La potencia consumida es proporcional al **cuadrado** del voltaje.


Aunque el consumo de **cada transistor** se reduce en un **factor de 0.8** con cada nueva generaci√≥n, el **doble de transistores** significa que el consumo total sigue aumentando.

Adem√°s, hay otro problema: **las corrientes de fuga**.

- Estas corrientes son p√©rdidas de energ√≠a que no realizan trabajo √∫til.
- **Aumentan exponencialmente** con cada generaci√≥n tecnol√≥gica.
- Actualmente pueden representar hasta **30% del consumo total de un chip**.

### **Hot Spots y limitaciones t√©rmicas**
- En algunas √°reas del chip, la **densidad de potencia** (W/cm¬≤) es mucho m√°s alta, lo que genera **hot spots** o puntos calientes.
- Estos hot spots aparecen en partes del procesador que realizan c√°lculos intensivos, como las **unidades de ejecuci√≥n de direcciones**.
- Para evitar sobrecalentamiento, se deben usar **sistemas de refrigeraci√≥n avanzados**.

Un l√≠mite razonable de densidad de potencia para un sistema multiprocesador es **10 kW/m¬≤**. Si se supera, se requieren **m√©todos de enfriamiento avanzados y costosos**, como refrigeraci√≥n l√≠quida o sistemas criog√©nicos.

## 1.2.7 M√©tricas de eficiencia en microprocesadores
Para evaluar el rendimiento de los microprocesadores, se utilizan m√©tricas como:

1. **GFLOPS/Watt** ‚Üí Mide la eficiencia energ√©tica del procesador en **operaciones de punto flotante por segundo por cada watt consumido**.

2. **GFLOPS/mm¬≤** ‚Üí Mide la eficiencia de c√≥mputo por unidad de √°rea del chip.

3. **GFLOPS/m¬≤** ‚Üí Indica la **densidad de c√≥mputo** en un centro de datos, tomando en cuenta la refrigeraci√≥n por ventilaci√≥n.
  ![[Pasted image 20250403161418.png]]
### **Impacto de peque√±os aumentos de consumo**
- Si un procesador tiene **muy bajo consumo (0.5 W)**, un incremento fijo de **0.1 W** puede reducir dr√°sticamente su eficiencia energ√©tica en t√©rminos de **GFLOPS/Watt**.
- Un ejemplo es el **ARM Mote**, que pierde rendimiento al aumentar ligeramente el consumo fijo.

![[Pasted image 20250403161442.png]]

## 1.2.8 Consumo de Potencia (TDP) y Evoluci√≥n Energ√©tica en Microprocesadores
### **1. Evoluci√≥n del Consumo de Potencia (TDP)**
üîπ **L√≠mite de disipaci√≥n de 100-200 W**
- M√°s all√° de este l√≠mite, los **ventiladores tradicionales no pueden disipar el calor de manera eficiente**.
- Ser√≠a necesario usar **refrigeraci√≥n l√≠quida o t√©cnicas avanzadas** de disipaci√≥n t√©rmica, lo que aumenta los costos.
### **2. Potencia Consumida a lo Largo del Tiempo**
- **Intel 80386 (1985):** **2 W**
- **Intel Core i7 (3.3 GHz, 2020):** **130 W** 
- **Supera el l√≠mite de refrigeraci√≥n por aire** (los chips modernos de 1.5 cm¬≤ no pueden disipar m√°s calor sin m√©todos avanzados).

**L√≠mite t√©rmico:** Un **procesador m√°s potente no siempre es mejor si genera demasiado calor**.

### **3. T√©cnicas para Aumentar la Eficiencia Energ√©tica**
**1. Apagado de reloj en m√≥dulos inactivos**
- Cuando una unidad no est√° en uso, se **detiene su reloj** para evitar consumo innecesario.
 
**2. Escalado Din√°mico de Voltaje-Frecuencia (DVFS)**
- Cuando el procesador est√° inactivo, **reduce su frecuencia y voltaje** para ahorrar energ√≠a.
 
**3. Estados de baja potencia para memoria y almacenamiento**
- **Memorias DRAM y discos duros** pueden entrar en modo de bajo consumo cuando no se usan.

**4. Overclocking y Turbo Boost**
- **Intel Turbo Boost (desde 2008)** permite que la CPU **aumente su frecuencia hasta un 10% m√°s** por cortos per√≠odos.
- Para compensar el aumento de temperatura, **se apagan algunos n√∫cleos** y se **sube la frecuencia de los n√∫cleos activos**.
- **L√≠mite:** No puede mantenerse por mucho tiempo debido a la temperatura.

**Conclusi√≥n:** La eficiencia energ√©tica es clave para el dise√±o moderno de procesadores.



## 1.2.9 Escalamiento del Retardo en Circuitos CMOS
El **retardo** en los circuitos CMOS es un factor clave en la velocidad de los microprocesadores. A medida que la **tecnolog√≠a avanza** (reducci√≥n de nodo tecnol√≥gico), los transistores se hacen m√°s peque√±os, lo que **reduce el retardo** de los circuitos de manera **aproximadamente lineal**.

### **¬øC√≥mo Escala el Retardo de los Circuitos?**

**Regla general:**
- El **retardo se reduce en un factor de 0.7** con cada nueva generaci√≥n de tecnolog√≠a.
- Es decir, si en una tecnolog√≠a de **65 nm** un circuito tiene un retardo de **10 ps**, en **45 nm** ser√≠a aproximadamente **7 ps**.

**Expresi√≥n en t√©rminos de FO4 (Fanout-of-Four):**
- No se expresa en unidades absolutas (ps) sino en t√©rminos de **FO4**, que representa el **retardo de un inversor cargado con 4 inversores**.
- Se ha comprobado que los retardos en unidades de **FO4** **son independientes del nodo tecnol√≥gico**, lo que permite comparar circuitos de distintas generaciones.

**Ejemplo:**
- Un sumador r√°pido tiene un **retardo de 10 FO4**.  
- Esto significa que **su retardo es 10 veces el retardo de un inversor con carga de 4 inversores**.

### **Conversi√≥n de FO4 a Retardos Absolutos**
**F√≥rmula Experimental:**

$$1 FO4 = 0.2 \times T \text{ (nm)} \quad (\text{en picosegundos})$$

- **Ejemplo en tecnolog√≠a de 45 nm:**
$$1 FO4 = 0.2 \times 45 = 9 ps$$
- **Ejemplo en tecnolog√≠a de 65 nm:**
$$1 FO4 = 0.2 \times 65 = 13 ps$$

**Ejemplo de C√°lculo de Frecuencia de Reloj:**  
Si un microprocesador tiene un **ciclo de reloj de 13 FO4**, su **frecuencia** en diferentes tecnolog√≠as es:

- **45 nm:** 
$$f = \frac{1}{13 \times 9 \text{ ps}} = 8.5 \text{ GHz}$$

- **65 nm:**
$$f = \frac{1}{13 \times 13 \text{ ps}} = 5.9 \text{ GHz}$$

üîπ **Conclusi√≥n:**  
**A menor nodo tecnol√≥gico, menor retardo y mayor frecuencia de reloj.**



### **4. Relaci√≥n entre Latencia, Potencia y √Årea**
**Regla emp√≠rica:**
$$\text{Latencia}^3 \times \text{Potencia} = \text{cte} (L)$$

- Si reducimos la **latencia a la mitad (x0.5)**, la **potencia aumenta x8**.
- **La constante disminuye con el avance tecnol√≥gico**, lo que significa que los chips m√°s modernos pueden operar con menor potencia relativa.

**Efecto de la Reducci√≥n del Voltaje en la Frecuencia y Potencia**

**Relaci√≥n Voltaje-Frecuencia:**
$$K_f = 1.45 K_v - 0.40$$

- Si bajamos el voltaje en **x0.6**, la frecuencia **se reduce en x0.5**.

**Impacto en la Potencia:**
$$P \propto K_f \times K_v^2$$

- **Ejemplo:** Si **K_v = 0.6** y **K_f = 0.5**, la **potencia cae en x0.2**.

**Conclusi√≥n:**
- **Escalar el voltaje es clave para reducir el consumo energ√©tico.**
- **Se usa en t√©cnicas como el escalado din√°mico de voltaje para ahorrar energ√≠a en momentos de baja demanda.**


### **5. Relaci√≥n entre √Årea y Latencia**
**Regla emp√≠rica:**
$$\text{√Årea} \times \text{Latencia}^n = \text{cte} (L)$$

- **Si n = 2**, reducir la latencia a **x0.5** aumenta el √°rea en **x4**.

**Conclusi√≥n:**
- **Reducir la latencia exige m√°s √°rea**, lo que puede afectar los costos de fabricaci√≥n y consumo energ√©tico.



## 1.2.10 Ancho de Banda y Latencia

**Latencia:**
- **Definici√≥n:** Tiempo entre que se inicia y se finaliza una operaci√≥n.
- **Mejoras:**
    - **Procesadores:** Se ha reducido **50-90X**.
    - **Memoria y discos:** Se ha reducido **6-8X**.

**Problema clave:**
- **Los procesadores piden datos m√°s r√°pido de lo que la memoria puede entregarlos**.
- **La latencia de memoria es mucho mayor que la velocidad de procesamiento**.

**Ancho de Banda:**
- **Definici√≥n:** Cantidad de trabajo que puede hacerse en un tiempo dado.
- **Mejoras:**
    - **Procesadores:** Se ha mejorado **32,000-40,000X**.
    - **Memoria y discos:** Se ha mejorado **300-1,200X**.

**Tendencia hist√≥rica:**
- No siempre aumenta con cada nueva generaci√≥n.
- Generalmente **se duplica con cada nodo tecnol√≥gico**. 

**F√≥rmula del Ancho de Banda M√°ximo (BWM):**
$$BWM = \frac{N \times F}{IP \times CPI_{\text{corei}}} \quad (\text{bytes/s})$$

Donde:
- **N** = N√∫mero de n√∫cleos.
- **F** = Frecuencia del procesador.
- **IP** = Intensidad operacional (instrucciones/byte).
- **CPI** = Ciclos por instrucci√≥n.

**Conclusi√≥n:**
- **El ancho de banda debe escalar con el n√∫mero de n√∫cleos, frecuencia y eficiencia de ejecuci√≥n**.
- **La latencia y la potencia est√°n ligadas**: si una mejora en latencia aumenta la potencia consumida, puede haber un **compromiso entre rendimiento y consumo**.


# 1.3 Escalamiento Hardware
En la siguiente tabla (Figura 14 en el texto), se comparan **cuatro versiones** del procesador en distintos nodos tecnol√≥gicos:

|**Nodo Tecnol√≥gico**|**√Årea (mm¬≤)**|**Transistores (millones)**|**Frecuencia (GHz)**|**Cach√© L3 (MB)**|**Ancho de Banda (GB/s)**|**N√∫cleos (N)**|**TDP (W)**|
|---|---|---|---|---|---|---|---|
|**180 nm (2001)**|420 mm¬≤|220 M|1 GHz|3 MB|6.4 GB/s|1|100 W|
|**130 nm (2003)**|430 mm¬≤|590 M|1.66 GHz|9 MB|6.4 GB/s|1|122 W|
|**90 nm (2005)**|600 mm¬≤|1700 M|1.66 GHz|24 MB|10.67 GB/s|2|104 W|
|**65 nm (2008)**|700 mm¬≤|2000 M|1.73 GHz|24 MB|34.0 GB/s|4|185 W|


Comparando generaci√≥n a generaci√≥n, observamos los siguientes factores de crecimiento:

| **Par√°metro**                 | **Factor de Cambio**                           |
| ----------------------------- | ---------------------------------------------- |
| **Frecuencia de reloj**       | x1.04                                          |
| **Tama√±o de cach√© L3**        | x3.0                                           |
| **N√∫mero de transistores**    | x2.7                                           |
| **N√∫mero de n√∫cleos**         | x1.0 (hasta 2005), luego x1.7 y x3.2           |
| **Ancho de banda de memoria** | x1.0 ‚Üí x1.7 ‚Üí x3.2                             |
| **√Årea del chip**             | Aumenta moderadamente                          |
| **TDP (Consumo energ√©tico)**  | Var√≠a, pero en general aumenta con m√°s n√∫cleos |

**Conclusiones:**
- **El n√∫mero de transistores creci√≥ de 220M a 2000M (casi x10) en 7 a√±os.**
- **El tama√±o de la cach√© aument√≥ de 3MB a 24MB (x8), mejorando la eficiencia de la CPU.**
- **El n√∫mero de n√∫cleos aument√≥ de 1 a 4, permitiendo mayor paralelismo.**
- **El ancho de banda de memoria aument√≥ significativamente, permitiendo transferencias m√°s r√°pidas.**

## 1.3.1 Ejecuci√≥n Multihilo en Hardware
Para **reducir el efecto de la latencia de memoria**, los n√∫cleos modernos permiten la ejecuci√≥n de m√∫ltiples hilos en hardware.
**Beneficios y efectos del multihilo en hardware:**
- **Un solo hilo**: 3.79 ciclos de parada por instrucci√≥n (**CPI = 4.79**) y **0.21 instrucciones por ciclo**.
- **Con ejecuci√≥n de 4 hilos**: Cuando un hilo se detiene por latencia, otro entra en ejecuci√≥n.
- **Resultado con 4 hilos**:
    - Tiempo de espera baja a **1.56 ciclos**.
    - **CPI = 1.39**, es decir, **0.72 instrucciones por ciclo**.

üîπ **Desventajas:**
- El hardware multihilo **tiene un coste** adicional.
- Se generan **conflictos en el pipeline**, afectando el rendimiento si no se gestiona bien.

![[Pasted image 20250403173413.png]]

## 1.3.2 Evoluci√≥n de los Procesadores de Un Solo N√∫cleo

### **Medici√≥n del rendimiento con SpecInt**
- **SpecInt** compara el rendimiento de un procesador con un sistema de referencia usando pruebas de benchmarking.
- Intel intent√≥ **mantener el CPI constante** en sus procesadores, pero en las √∫ltimas generaciones **el CPI aument√≥** debido a la mayor profundidad del pipeline.
- **Ratio SpecInt/MHz** (proporcional al inverso del CPI) evolucion√≥ a lo largo del tiempo, reflejando cambios en la eficiencia del procesador.

Hasta 2003, los procesadores usaban un **modelo de n√∫cleo √∫nico superescalar** con ejecuci√≥n de m√∫ltiples instrucciones por ciclo.

**Factores clave del escalamiento:**
- **Latencia** se reduc√≠a a la mitad en cada nueva generaci√≥n.
- **Frecuencia** se duplicaba manteniendo CPI constante.
- Para lograrlo, se **aumentaba la profundidad del pipeline y el tama√±o de la cach√©**, incrementando el √°rea del procesador.

## 1.3.3 Agotamiento del Modelo de Escalamiento de un Solo N√∫cleo**
El modelo de n√∫cleo √∫nico **lleg√≥ a su l√≠mite** porque no se pod√≠a reducir m√°s el CPI.

**Problemas al escalar un solo n√∫cleo:**
1. **Reducci√≥n del √°rea no implica menor CPI**
    - A medida que se **reduce el nodo tecnol√≥gico**, las cach√©s crecen. 
    - Las **conexiones largas** dentro del chip no reducen su longitud proporcionalmente.

2. **Impacto en la transmisi√≥n de se√±ales**
    - **M√°s ciclos de reloj son necesarios** para enviar datos a trav√©s de conexiones largas.
    - **Se aumenta la profundidad del pipeline** para segmentar estas conexiones. 
    - Esto provoca un **aumento del CPI**, en lugar de reducirlo.

3. **Mayor complejidad del hardware**
    - Se requieren **mejores predicciones de saltos y estructuras m√°s avanzadas**.  
    - Esto **incrementa la complejidad**, lo que lleva a conexiones a√∫n m√°s largas y m√°s registros intermedios.

4. **L√≠mites de la programaci√≥n**
    - Existen **restricciones en la ejecuci√≥n de instrucciones** que impiden bajar el CPI indefinidamente.
    - **Multihilo y precarga de datos** ayudan, pero no solucionan completamente el problema.
 

**Conclusi√≥n:**
- **El modelo de n√∫cleo √∫nico dej√≥ de ser viable despu√©s de 2003**. 
- La soluci√≥n fue **migrar a procesadores multin√∫cleo**, permitiendo m√°s rendimiento sin depender √∫nicamente del aumento de frecuencia y pipeline.

# 1.4 M√©tricas de rendimiento de un sistema
**Tiempo de CPU**

$$Tiempo_{CPU} = \text{Ciclos de CPU} \times \text{Tiempo de ciclo}$$ 
$$Tiempo_{CPU} = \frac{\text{Ciclos de CPU}}{\text{Frecuencia de reloj}}$$

**Ciclos de CPU**
$$\text{Ciclos de CPU} = \text{N√∫mero de instrucciones} \times \text{CPI}$$

**CPI (Ciclos por Instrucci√≥n)**
- **N√∫mero medio de ciclos** que una instrucci√≥n necesita para ejecutarse.
- Diferentes instrucciones **pueden requerir distinto n√∫mero de ciclos**.
- Se calcula como:
$$CPI = \frac{\sum (NI_i \times CPI_i)}{N}$$ 
donde `NI_i` es el n√∫mero total de instrucciones tipo `i`, `CPI_i` es el n√∫mero de ciclos por instrucci√≥n y `N` es el n√∫mero total de instrucciones.


**Ecuaci√≥n b√°sica de rendimiento**
$$Tcpu = \frac{N \times CPI}{F}$$

- **N** = N√∫mero total de instrucciones.
- **CPI** = Ciclos por instrucci√≥n.
- **F** = Frecuencia del procesador (Hz).
- Permite **comparar arquitecturas** y evaluar cambios en los tres factores.

**MIPS (Millones de Instrucciones por Segundo)**
$$MIPS = \frac{N}{Tcpu \times 10^6}$$

**Problemas de MIPS:**
- **No es v√°lido** para comparar procesadores con diferentes conjuntos de instrucciones.
- **Depende del programa** ejecutado.

**GFLOPS (GigaFLOPS)**
$$GFLOPS = \frac{FLOPS}{Tcpu \times 10^9}$$

**Problema:** Dependiente del programa, como MIPS.
