# 1.1 Parámetros de Diseño de un Sistema

- **Rendimiento** (*Velocidad*)
- **Coste**
- **Potencia** (*Estática + Dinámica*)
	- Potencia pico
	- Potencia media
- **Robustez**
	- Tolerancia al ruido
	- Resistencia a la radiación
- **Testabilidad**
- **Reconfigurabilidad:** Si uno nodo del sistema se estropea este debe ser capaz de adaptarse a la nueva situación.
- **Tiempo de salida del mercado, etc.**


# 1.2 Clases de Computadores
- **Personal Mobile Device**
- **Computación de Escritorio**
- **Servidores**
- **Clusters**
- **Internet of Things**

![[Pasted image 20250206173816.png]]

# 1.3 Definiendo la Arquitectura de un Ordenador.
Tenemos la visión **simplificada** del diseño de la arquitectura de un ordenador, donde nos centramos en el diseño del **INSTRUCTION SET ARCHITECTURE** (*ISA*), es decir, decisiones relacionados con los registros, modos de direccionamiento, operandos de las instrucciones, tipos de instrucciones, forma de codificar instrucciones, ...

Y por otro lado tenemos la visión **realista** de la arquitectura de un computador, donde se recoge requerimiento específicos de la máquina objetivo; el diseño para maximizar el rendimiento con restricciones de coste, potencia y disponibilidad; y también incluye ISA, microarquitectura y el hardware.

# 1.4 Tipos de Paralelismo
El **paralelismo** es la capacidad que tiene un ordenador para realizar varias tareas al mismo tiempo. Las **instrucciones vectoriales** consisten en agrupar las variables en vectores cuando tenemos una gran cantidad de datos y de esta forma hacemos grandes cálculos con un número reducido de instrucciones. **Explotar el paralelismo está relacionado con la mejora del rendimiento**.

- **Tipos de paralelismo en las aplicaciones**:
	- Paralelismo a nivel de datos (*DLP*).
	- Paralelismo a nivel de tareas (*TLP*).
- **Tipos de paralelismo en las arquitecturas**:
	- **Paralelismo de nivel instrucción** (*ILP*): Varias instrucciones en la CPU se ejecutan al mismo tiempo en distintos puntos de ejecución, por ejemplo una instrucción decodificándose mientras otra realiza cálculos. Se dice que se está agotando porque a nivel tecnológico no hay muchas mejora posibles y se debe experimentar con nuevos métodos para mejorar el rendimiento
	- **Arquitectura de Vectores / Unidades de procesamiento gráfico** (*GPUs*): Explota el paralelismo a nivel de datos.
	- **Paralelismo de nivel de subprocesos (TLP)**: Usado por software como OpenMP, puede explotar tanto el paralelismo a nivel de datos o tareas.
	- **Paralelismo de nivel de petición:** Se trata de tareas de gran tamaño que se encuentran desacopladas.
**El paralelismo requiere reestructuras las aplicaciones. Por lo que, el código debe exponerlo de forma explícita**.

# 1.5 Taxonomía de Flynn
Es una clasificación de arquitecturas paralelas basadas en flujos de datos e instrucciones denominadas **flujos**:
- **Instrucción simple, flujo de datos simple (SISD):**
	Ordenador secuencial que puede explotar paralelismo a nivel de instrucción. Son ordenadores mononúcleos.
![[Pasted image 20250206180244.png]]
- **Instrucción simple, flujo de datos múltiple (SIMD):**
	- Arquitecturas vectoriales.
	- Extensiones multimedia como las instrucciones SSE  AVX.
	- Unidades de procesamiento gráfico (*GPUs*).
![[Pasted image 20250206180508.png]]
- **Múltiples instrucciones, flujo de datos simple (MSID):**
	No tiene implementaciones comerciales.
![[Pasted image 20250206180638.png]]
- **Múltiples instrucciones, múltiples datos (MIMD):**
	Cada procesador tiene sus propias instrucciones y opera sobre sus propios datos. Los clusters están dentro de esta categoría. Son más flexibles que los SIMD pero más caros. Se usan en sistemas multicore.
![[Pasted image 20250206180943.png]]
	El ejemplo más claro puede ser el uso de un cluster por parte de dos usuarios, donde cada uno envía un programa para su ejecución. Dichos programas serán atendidos por su correspondiente procesador propio y enviados a una red de interconexión.

# 1.6 Arquitecturas MIMD
Son las de uso más extendido. 
- **Procesadores de memoria compartida**:
	Todos los procesadores comparten el mismo espacio de direcciones y el programador no necesita conocer la ubicación de los datos.
- **Multiprocesadores de memoria distribuída (multicomputadores)**:
	Cada procesador tiene su propio espacio de direcciones y el programador necesita saber donde están los datos.
- **Multicores: multiprocesadores en un único chip**.
- **Otros subtipos como clústers, MPP's**.

# 1.7 Multiprocesadores
![[Pasted image 20250206181938.png]]
Los procesadores y la memoria se encuentran separados por una red de interconexión. Cada procesador puede tener niveles propios de caché pero comparte la misma memoria RAM. La entrada/salida está centralizada.

La red de interconexión puede ser: barras cruzadas, multietapa. Las comunicaciones se realizan a través de escrituras/lecturas en memoria. Las memorias se encuentran en una zona amarilla para recalcar que se gestionan conjuntamente. 

Un sistema es escalable si al añadirle nuevos recursos su rendimiento mejora de manera proporcional. Los procesadores tienen una baja escalabilidad. Como posibles soluciones tenemos:
- Añadir caché a los procesadores.
- Usar redes de baja latencia y alto ancho de banda.

# 1.8 Multicomputadores
![[Pasted image 20250206182647.png]]