# 2.1 Arquitectura MIPS
**MIPS** es una arquitectura tipo **RISC** (instrucciones de tamaño y formatos uniformes) desarrollada para **aprovechar al máximo las técnicas de segmentación**. El ISA tiene **versiones de 32 y 64 bits**, además de **extensiones para aplicaciones específicas** (compresión de datos, instrucciones SIMD para coma flotante, etc.) Estos 32 o 64 bits representa el ancho de la **palabra**, **todas las instrucciones tienen esa longitud**.

## 2.1.1 Ciclo de Instrucción
El **Ciclo de Instrucción** son las etapas necesarias en un caso general para ejecutar cada instrucción. Etapas de ejecución:
- Búsqueda de instrucciones (IF)
- Decodificación y lectura de registros (ID)
- Ejecución o cálculo de direcciones (EX)
- Memoria de datos (MEM)
- Escritura de registros (WB)

## 2.1.2 Camino de Datos
El **camino de datos** es el hardware que procesa datos y direcciones en la CPU.

![[Pasted image 20250419140530.png]]

## 2.1.3 Instrucciones MIPS
### Tipos de Instrucciones
- **Tipo I:** transferencia de datos, instrucciones con operandos inmediatos y saltos condicionales
- **Tipo R:** operaciones aritméticas y lógicas
- **Tipo J:** saltos incondicionales

![[Pasted image 20250419141018.png]]

- `code` indica la codificación de la operacion
- `rs` registro fuente/origen/source
- `rd` registro destino
- `shamt` desplazamiento
- `funct` código de función
- `dirección` dirección

### Modos de Direccionamiento
- Direccionamiento **directo:** el operando es una constante que aparece en un campo de la instrucción.
- Direccionamiento **registro:** el operando está en un registro
- Direccionamiento **base con desplazamiento:** el operando está en una dirección de memoria obtenida como la suma de una constante (que está en la instrucción) y el contenido de un registro
- Direccionamiento **relativo al PC:** el operando está en una dirección de memoria obtenida como la suma de una constante (que está en la instrucción) y el PC.
- Direccionamiento **pseudodirecto:** el operando está en una dirección de memoria obtenida como la concatenación de una constante (que está en la instrucción) y los MSB del PC

![[Pasted image 20250419141808.png]]
![[Pasted image 20250419141816.png]]
![[Pasted image 20250419141828.png]]
![[Pasted image 20250419141838.png]]

## 2.1.4 Implementación Monociclo
En MIPS, **cada instrucción se ejecuta en un ciclo de reloj** (CPI=1). Entonces, es muy importante decidir una longitud de ciclo de reloj adecuada. Como hay instrucciones con **más etapas** de ejecución que otras, se tendrá que escoger una **longitud de ciclo** que permita que se ejecute la **más lenta**. Como consecuencia, el resto de instrucciones tendrán tiempos muerto durante su ciclo de ejecución. 
![[Pasted image 20250419155505.png]]
**Opciones para reducir el ciclo de reloj:** 
- Mejoras **tecnológicas de los circuitos** que permitan reducir el tiempo de ejecución de **cada etapa**.
- Mejoras de la **organización del hardware** que pueda ejecutar más de una instrucción **al mismo tiempo**.

## 2.1.5 Implementación Multiciclo y Segmentación
La implementación multiciclo y la segmentación son dos métodos de **mejora de la organización** del **hardware**. 

En las **implementaciones multiciclo** cada etapa de ejecución se ejecuta en un ciclo, de manera que en cada instante hay sólo una instrucción en ejecución. Para conseguirla hay que **subdividir** la unidad de ejecución y colocar **registros entre etapas**. Aprovechar mejor la **duración variable de las etapas** de ejecución.

La **segmentación** se consigue a partir de una implementación multiciclo si se permite comenzar a ejecutar una instrucción mientras se ejecutan otras. Sin embargo, no todas las instrucciones **terminan al mismo tiempo**. Cuando dos instrucciones necesitas usar la **misma unidad funcional** se pueden producir **conflictos**. Los **saltos** pueden provocar **paradas**.

# 2.2 Sementación del Cauce
La **ejecución multiciclo con número de ciclos variable** acelera la ejecución de instrucciones permitiendo que unas acaben antes que otras. La **segmentación** permite lanzar a ejecución un instrucción antes de que acabe la anterior.

El objetivo es aprovechar todas las etapas a la vez para ir progresando en la ejecución de diferentes instrucciones simultáneamente. 
- En cada instante habrá como **máximo una instrucción en cada etapa**.
- **Idealmente** se inicia **una instrucción cada ciclo** de reloj. 

![[Pasted image 20250419161405.png]]
![[Pasted image 20250419161430.png]]

## 2.2.1 Etapas de Segmentación de Cauce
**La complejidad del conjunto de instrucciones afecta directamente a la complejidad del pipeline**. Una unidad convencional de ejecución de $N$ etapas tardará en ejecutar una instrucción la suma del tiempo que tarda cada una de las etapas.
$$T_{comb} = T_1 + ... + T_N$$
![[Pasted image 20250419162602.png]]
Una unidad **segmentada** con $N$ etapas tardará más ene ejecutar cada instrucción por separado, pues tiene que cargar los registros entre cada etapa. El ciclo de reloj debe ser lo suficientemente largo para ejecutar la etapa más lenta y realizar su carga de registros. Por tanto, conviene que **todas las etapas** del pipeline tengan una **duración similar**.

En cada ciclo de reloj se solapa la ejecución de diferentes instrucciones, de manera que, tras una **latencia inicial** igual al tiempo de ejecución de la primera instrucción, se obtiene **una instrucción por ciclo (*idealmente*)**.

$$ T_{clk} = max(T_1+T_R, ..., T_N+T_R)$$
![[Pasted image 20250419163333.png]]
![[Pasted image 20250419163404.png]]

## 2.2.2 Aceleración en la Segmentación del Cauce
Si todas las $N$ etapas tiene la misma duración: $t_{entreInstSegmentadas}=t_{entreInstNoSegmetnadas}/N$
Si las etapas no están balanceadas la aceleración es menor.

**Aceleración** que se obtiene con la segmentación_
$$SpeedUp= \frac{t_{original}}{t_{segmentación}}$$
Esta aceleración se debe al **aumento de productividad**, pues aumenta el número de instrucciones finalizadas por unidad de tiempo. La **la latencia no disminuye**, pues aumenta ligeramente el tiempo que tarda en ejecutarse cada instrucción por separado. 

![[Pasted image 20250419163941.png]]

## 2.2.3 Camino de Datos Segmentado
![[Pasted image 20250419164134.png]]

**Ejemplo para instrucciones tipo load y store:**
![[Pasted image 20250419164259.png]]
![[Pasted image 20250419164330.png]]
![[Pasted image 20250419164358.png]]
![[Pasted image 20250419164415.png]]
![[Pasted image 20250419164445.png]]

Para evitar esto, se añade **hardware adicional** además del necesario para permitir la ejecución multiciclo. 
![[Pasted image 20250419164540.png]]

# 2.3 Riesgos en la Ejecución
El **CPI ideal** de un procesador segmentado es 1, pero existen situaciones que **impiden que se inicie una instrucción en cada ciclo**. Los ciclos del pipeline en los que no se computa se denominan **burbujas del pipeline** y en ellos se introduce en el pipeline un **código de no operación** (NOP). 

Los **riesgos** son situaciones que limitan la posibilidad de que dos instrucciones se ejecuten simultáneamente.
- De **estructura:** el hardware no permite la ejecución de determinadas instrucciones a la vez
- De **datos:** se tiene que esperar a que una instrucción anterior lea o escriba un dato
- De **control:** no se sabe determinar la instrucción correcta que se tiene que ejecutar después de un salto.

## 2.3.1 Riesgos Estructurales
Los **riesgos estructurales** se producen cuando los recursos hardware no son capaces de satisfacer la demanda de uso. Por ejemplo, que sólo exista una unidad de división en punto flotante o una única memoria compartida para datos e instrucciones. 

![[Pasted image 20250419165125.png]]
![[Pasted image 20250419165140.png]]

## 2.3.2 Riesgos de Datos: Bloqueo y Forwarding
Los **riesgos de datos** se producen cuando la ejecución de una instrucción depende de un dato que aún no está disponible. **Tipos** de riesgos de datos: 

- **RAW** (Read After Write) o **Dependencia verdadera:** una instrucción intenta leer un dato justo antes de que otra anterior lo escriba. Las instrucciones no pueden ejecutarse en paralelo ni solaparse completamente, provoca una **parada**. Se pueden detectas por **hardware** o por **compilador**
![[Pasted image 20250419170225.png]]

- **WAR** (Write After Read) o **Antidependencia:** una instrucción intenta modificar un dato antes de que otra anterior lo lea. No puede ocurrir en un MIPS con pipeline de 5 etapas ya que ID es la etapa 2 y WB es la 5, **no provoca una parada**. 
![[Pasted image 20250419170406.png]]

- **WAW** (Write After Write) o **Falsa dependencia o Dependencia de salida:** una instrucción intenta escribir un dato antes de que otra anterior lo escriba. No puede ocurrir en un MIPS con pipeline de 5 etapas, pues estas siempre se ejecutan en el mismo orden, **no** provoca una **parada**.
![[Pasted image 20250419170554.png]]

### Soluciones
**WAR o WAW:** renombrado de registros.
- Renombrado **estático:** por el compilador
- Renombrado **dinámico:** por el hardware

**RAW:** 
- **Bloquear** la instrucción hasta que se realice la escritura necesaria. 
- El compilador **reordena el código** para mitigar el riesgo, introduce una secuencia de instrucciones independientes entre las conflictivas. Si no hay instrucciones independientes inserta instrucciones **NOP**.
- **Envío adelantado** (fowarding, bypassing, anticipación)

![[Pasted image 20250419171057.png]]
![[Pasted image 20250419171127.png]]

### Fowarding
El **fowarding** consiste en enviar resultados de las últimas etapas del pipeline a las primeras para evitar esperas. Por tanto requiere **conexiones adicionales.**
- **Fowarding:** el hardware adelanta el dato que hace falta nada más se calcula, sin esperar al WB.
![[Pasted image 20250419171523.png]]

- **Bloqueo + Fowarding:** se detiene por hardware la ejecución de instrucciones hasta que el dato necesario esté disponible. Si no se de realizar fowarding, el bloqueo duraría un ciclo más.
![[Pasted image 20250419171533.png]]
![[Pasted image 20250419171547.png]]

Permite obtener las **entradas de la ALU** desde **cualquier registro de segmentación**, no solo del ID o EX, así que requiere modifica la ALU.

![[Pasted image 20250419171739.png]]
![[Pasted image 20250419171757.png]]
**Requerimientos** para relaizar el fowarding:
- **Detectar** si uno de los datos se puede traer desde otra etapa el pipeline analizando los códigos de las instrucciones que están en la etapa ID y que van a necesitar en la EX resultados de otras instrucciones.
- Generar **señales de control** en los multiplexores que controlan la entrada a la ALU para seleccionar la procedencia del operando.

**El control de interbloqueo de instrucciones** es un proceso que consiste en detectar cuándo una isntrucción **no puede avanzar por dependencia** en operandos con otra, **aunque se aplique adelantamiento**, provocando que se **pare la emisión de instrucciones** hasta que se solucione el bloqueo. La **duración** de la detección depende del **tipo** de instrucciones involucradas. Se detecta en la etapa **ID** pues en ella se averigua qué registros son operandos de entrada. Se activa una parada si: 
- En la etapa ID hay una instrucción tipo ALU, salto o de almacenamiento. 
- En la etapa EX se está ejecutando una carga
- El registro destino de la carga es operando de entrada de la instrucción que está en etapa ID

![[Pasted image 20250419172349.png]]

![[Pasted image 20250419172401.png]]
![[Pasted image 20250419172410.png]]

### Camino de Datos con detección de **InterBloqueo** y de Adelantamiento

![[Pasted image 20250419172454.png]]

## 2.3.3 Riesgos de Control: Tratamiento de Saltos
Los **riesgos de control** se producen cuando se debe tomar na decisión basada en los resultados de una instrucción mientras otras se están ejecutando. 

En el pipeline del MIPS normalmente los datos condicionales se resuelven en la etapa EX. Para **optimizar** su ejecución es necesario **comparar los registros** en una etapa anterior, normalmente la **ID**.
- Si el salto se decide en la etapa MEM y continuamos como si no se fuera a saltar, se perderían 3 ciclos si al final se saltase. Podemos evitar perder tantos ciclos añadiendo un **sumador y comparador** de registros en la etapa **ID** para resolver antes los saltos. 

![[Pasted image 20250419173334.png]]
![[Pasted image 20250419173349.png]]

Llamaremos **salto tomado** a la situación en la que se modifica el PC y **salto no tomado** a aquella en la que no se modifica. 

**Soluciones a los riesgos de control**
- **Detener** el cauce hasta que se tome la decisión.
- Aplicar una técnica de **salto retardado**
- Aplicar una técnica de **predicción de salto**

### Solución 1: Detención del Cauce
Se detiene la carga de la siguiente o siguientes instrucciones hasta que el resultado se compute. La cantidad de ciclos de bloqueo depende de qué es destino el/los registros de comparación de salto:
- Si es destino de una instrucción **ALU** que se ejecuta **2 o 3 ciclos atrás:** se pierden **0 ciclos** (se puede resolver con forwarding)
![[Pasted image 20250419174144.png]]

- Si es destino de una instrucción **ALU** que se ejecuta **1 ciclo atás** o de una de **carga** que se ejecuta **2 ciclos atrás:** se pierde **1 ciclo**
![[Pasted image 20250419174153.png]]

- Si es destino de una instrucción de **carga** que se ejecuta **1 ciclo atrás:** se pierden **2 ciclos**.
![[Pasted image 20250419174201.png]]

Si el **pipeline es profundo** el **coste** de la parada sería demasiado **alto**, por lo que predecir el resultado puede ser una mejor opción. En general, el pipeline del **MIPS** predice los saltos **no tomados** siempre, así que carga las siguientes instrucciones después del salto y las va ejecutando. Si al final la predicción resultó ser **incorrecta** se producirán **paradas**.

### Solución 2: Decisión Retardada
El compilador mueve varias instrucciones a las **ranuras** que quedan bajo el salto (en el caso del MIPS, 2 como máximo), siempre que estas instrucciones **no guarden relación con el salto.** Así **aprovecha** el tiempo necesario para decidir si se realiza el salto. Si no hay instrucciones que puedan moverse, el compilador introduce **paradas** bajo el salto (lo cual ocurre la mitad de veces).

![[Pasted image 20250419174637.png]]

Hay varias manera de implementar la decisión retardada con 1 ranura en **función de la información disponible durante la compilación:**
- Mover la **instrucción anterior al salto** a la ranura.
- Si no se puede usar la solución anterior, copiar la **instrucción de destino de salto** a la ranura
- Mover la **instrucción de después del salto** a la ranura.
> La instrucción que se coloque en la ranura de salto **no puede cambiar el estado del sistema**, es decir, no puede realizar escrituras ni en registros ni en memoria, antes de que se decida si se salta o no. 

![[Pasted image 20250419180220.png]]

### Solución 3: Predicción de Salto
- Predicción de salto **estática:** predicción fija basada en el comportamiento típico del salto. En un salto asociado a un lazo o a un `if`, si es hacia atrás se predecirá que se toma, pues seguramente será para cerrar un lazo. Si es hacia delante se predice que no se toma.
- Predicción de salto **dinámica:** mide el comportamiento real del salto mediante el hardware y va tomando una decisión adaptativa. Asume que en el futuro se seguirá la misma tendencia. Cuando falla en la predicción hay que **parar** mientras se carga la nueva instrucción y **actualizar** la historia.

#### Predicción de Salto Fija
En el MIPS de 5 etapas la predicción de **salto tomado** supone **1 ciclo de pérdida**, por lo que es **mejor** la predicción de **salto no tomado**. En otros pipelines esto puede cambiar. 

![[Pasted image 20250419180816.png]]

![[Pasted image 20250419180827.png]]
![[Pasted image 20250419180843.png]]

#### Predicción de Salto Dinámica
En pipelines más **profundos** que el MIPS y en sistemas **superescalares**, la penalización por saltos es mayor, ya que hay varios pipelines implicados en la ejecución. Por tanto se usan soluciones más complejas.

Para las predicciones de salt dinámicas se necesita:
- Un buffer de predicción de salto (una tabla de historia) en el que se almacene el resutlado del salto: tomado (T) o no tomado (NT)
- Indexado mediante las direcciones de instrucciones de salto recientes.

Para ejecutar un salto:
- Chequear el buffer de predicción, pues se espera un resultado igual
- Iniciar la búsqueda de la siguiente instrucción o la de destino de salto.
- Si la predicción es errónea hay que vaciar el pipeline y cambiar la predicción.

Incluso usando un predictor hay que **calcular la dirección de salto**. Esto tiene una **penalización de 1 ciclo** en el MIPS cuando se predice T. Una posible mejora es tener un **buffer de destino de salto** que opere como **caché** de direcciones de destino y se **indexe mediante el PC** en la etapa IF. Así se acierta y la instrucción es un salto que se predijo T, se puede buscar la instrucción de destino del salto inmediatamente.

##### Predictor de 1 BIT
Se almacena 1 bit indicando la predicción para la siguiente ocurrencia de la misma instrucción de salto:
- Si la predicción es correcta: el bit no cambia
- Si la predicción no es correcta: el bit se complementa
![[Pasted image 20250419182040.png]]

Filtra **cambios puntuales**. No es capaz de **adaptarse** al comportamiento del programa. Con un único predictor de 1 bit los saltos de lazos internos se predicen erróneamente 2 veces. Una posible mejora es hacer una **predicción separada para cada instrucción de salto** o usar un **predictor más complejo**.
![[Pasted image 20250419182219.png]]
![[Pasted image 20250419182232.png]]

##### Predictor de 2 BITS
Se almacenan 2 bits indicando la predicción para la siguiente ocurrencia de la misma instrucción de salto. Los bits solo cambian después de 2 predicciones erróneas.

Hay diferentes implementaciones, pero todas se basan en considerar **2 estados** de predicción **fuerte** y otros 2 de predicción **débil**. Usa una caché para almacenar las predicciones:
- Se indexa como una caché ordinaria: la parte menos significativa de la dirección de la instrucción de salto (la etiqueta) se usa para extraer el estado de la predicción.
- La probabilidad de que dos saltos tengan en común estos bits es muy baja, pero no imposible.
- Cuando se resuelve el salto se almacena el nuevo estado en la misma posición

Filtra **cambios esporádicos**. Evita el 50% de los fallos que se tendrían al usar un predictor d 1 bit para secuencia de saltos tipo T NT T NT T NT...

![[Pasted image 20250419183358.png]]

##### Predictor Basado en Información Local
Tiene en cuenta la historia del comportamiento **de un mismo salto** para tomar la decisión. 
- Se almacena el resultado de cada salto correspondiente a sus últimas k ocurrencias
- Con estos bits se accede a los bits de estado que informan de la predicción
- Una vez conocido el resultado real del salto, se actualiza el contenido de la memoria de historia y el filtro de decisión
- Una vez conocido el resultado real del salto, se actualiza el contenido de la memoria de historia y el filtro de decisión.

Usa **dos filtros de deicisión** y así evita el 100% de los fallos que sucederían al usar un predictor de 1 bit para secuencias tipo T NT T NT...

![[Pasted image 20250419183739.png]]

##### Predictor Basado en Información Global
Tiene en cuenta la historia del comportamiento de **las últimas $N$ instrucciones de salto** para tomar una decisión. Se usa un **registro de desplazamiento** para almacenar el **resultado de los saltos**. El contenido del registro indexa una **memoria**que guarda los **bits de estado** correspondientes al filtro de decisión. 
![[Pasted image 20250419183945.png]]

##### Predictor Combinado
Combina un predictor **local** y otro **local**. La **tasa de acierto** de los saltos en procesadores reales depende del **tipo de programa** y suele estas entre 85% y 99%

![[Pasted image 20250419184121.png]]

## 2.3.4 Extesión a Operaciones Multiciclo.
Las instrucciones en punto flotante tienen la **misma segmentación** que las entera, pero con las siguientes modificiaciones: 
- La etapa EX tiene **diferente latencia** dependiendo de la **instrucción**.
- Existen **diversas unidades** funcionales para cada **tipo de operación**.

Se añade un **banco de registros** separado para operaciones en **punto flotante**. Se añade una **unidad de multiplicación** segmentada de **7 etapas** en **enteros y punto flotante**. Se añade una **unidad de suma de 4 etapas** en punto flotante. Se añade una **unidad de división no segmentada** que requiere **varios ciclos** reutilizando la **misma etapa** (en esta unidad no se puede ejecutar una instrucción por ciclo).

![[Pasted image 20250419184659.png]]

**Chequeo de riesgos estructurales**: hay que detectarlos en la unidad de DIV  y en la etapa de WB. Para detectarlos:
- Para el paso de la instrucción a EX si es una división y hay otra división en ejecución.
- Para la emisión si se detecta que van a llegar al WB más instrucciones que puertas de acceso de escritura al banco de registros.

Chequeo de **riesgos por dependencias RAW:** similar al caso de pipeline simple con una única etapa de ejecución pero con más casos posibles.

Chequeo de **riesgos por dependencias WAW:** son **poco comunes.** Para detectarlos:
- Determinar si hay una instrucción en una etapa posterior a ID que tiene como destino el mismo registro que la etapa de ejecución, pero que haría la escritura del registro un número de ciclos posterior.
- Si sucede, para el paso a EX de la instrucción que está en una etapa posterior a ID.

# 2.4 Excepciones
Las **excepciones** se producen por diferentes **eventos en la CPU** (código de operación indefinido, overflows, syscalls,..) y requieren que el programa se ejecute de nuevo **desde el punto en que se produjo la excepción.**

Para poder restablecer el estado es necesario que se haya **guardado** el contenido de los **registros** y de la **memoria**.
- Las excepciones que permiten recuperar un estado anterior por completo se llaman **excepciones precisas**.
- Es complicado gestionarlas sin sacrificar el rendimiento, ya que reestablecer el estado del sistema significa almacenar información y perder ciclos.

Posibles soluciones:
- Incorporar un **banco de registros adicional** para ayudar a guardar los valores producidos por **cada instrucción**. 
- Utilizar una **rutina software** que permita **repetir la ejecución** de instrucciones desde la que produjo la excepción.
- **Parar la emisión de instrucciones** si en la capa EX se detecta **riesgo de excepción**.

Si suceden múltiples excepciones anidadas, se gestiona **la más antigua primera**. 
![[Pasted image 20250419185919.png]]

## 2.4.1 Caso Práctico: MIPS R4000
![[Pasted image 20250419185957.png]]
![[Pasted image 20250419190013.png]]
![[Pasted image 20250419190035.png]]

## 2.4.2 Creencias erroneas
La segmentación es **fácil:** la idea básica es simple, pero la dificultad está en los detalles.
La segmentación es **independiente de la tecnología:**
- **Más transistores** hacer que sean posibles más técnicas complejas, por ejemplo, para detectar saltos, lo cual reduce el **tiempo de ejecución**.
- El **diseño del ISA** relacionado con segmentación necesita tener en cuenta las **tendencias tecnológicas**

## 2.4.3 Dificultades
Un diseño de ISA poco cuidadoso puede hacer la segmentación más complicada. Ejemplos: 
- **Conjuntos de instrucciones complejos (VAX, IA-32):** implican un sobrecoste para hacer que la segmentación funcione.
- **Modos de direccionamiento complejos.**
- **Saltos retardados:** los pipelines avanzados tienen slots de retardo grandes.

## 2.4.4 Conclusiones
El hardware del **camino de datos** y la **lógica de control** se complican con la segmentación:
- Camino de adelantamiento.
- Lógica para detección de conflictos de datos.
- Lógica para predicción de saltos.

La segmentación **mejora la productividad**, pero **no el tiempo de ejecución de cada instrucción** (latencia).

**Incrementar la longitud del cauce** segmentado (el numero de etapas de segmentación) **no tiene por qué incrementar el rendimiento:**
- Los conflictos de datos hacen que incrementando la longitud se incremente el tiempo que se invierte en cada instrucción.
- Los conflictos de control provocan que un incremento en la longitud ralentice los saltos.
- La sobrecarga por los registros de segmentación puede limitar el aumento de la frecuenta de reloj.