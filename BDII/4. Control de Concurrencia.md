# 4.1 Bloqueos
Los bloqueos consisten en que, al acceder una transacción a un elemento de datos, no se permite que ninguna otra pueda hacerlo. Existen dos modos de bloqueo:

- **Compartido:** Permite la lectura del elemento de datos, pero no su escritura. Es compatible con más bloqueos compartidos sobre el mismo elemento de datos.

- **Exclusivo:** Permite tanto leer como escribir en el elemento de datos. No es compatible con ningún tipo de bloqueo sobre el mismo segmento de datos.    

Por tanto, existen dos instrucciones para solicitar los bloqueos (una para cada tipo) y una para desbloquear. Llamaremos a estas funciones:

- **Bloquear-c(Q):** Bloquea en modo compartido un elemento de datos Q.

- **Bloquear-x(Q):** Bloquea en modo exclusivo un elemento de datos Q.
 
- **Desbloquear(Q):** Desbloquea un elemento de datos Q.
 

Si una transacción realiza el desbloqueo de un segmento de datos inmediatamente después de acabar de trabajar con él, puede no garantizarse la secuencialidad. Como ejemplo, supongamos el caso de una transacción que resta un valor de un elemento de datos $Q$ y se lo suma a un elemento de datos $R$. Otra transacción simplemente lee $Q + R$.

De forma secuencial, el resultado obtenido por la segunda transacción siempre será $A + B = x$. Sin embargo, si se ejecutan de forma concurrente y la transacción 1 desbloquea Q justo después de la resta y, en ese momento, pasa a ejecutarse la transacción 2, esta leerá $x - y$, lo que no coincide con el resultado anterior y, por tanto, hace que la planificación no sea secuenciable.

Se produce un **interbloqueo** cuando una transacción no puede avanzar porque espera **a que otra desbloquee un segmento de datos**, m**ientras que esta segunda también está esperando a que la primera desbloquee otro segmento de datos para poder avanzar**. Por tanto, ninguna puede avanzar debido a los bloqueos activos de la otra.

Esto puede deberse a que se espera demasiado tiempo para desbloquear los elementos de datos bloqueados por una transacción. Un ejemplo es el caso de una planificación en la que:

1. Una transacción bloquea un elemento de datos $Q$ para leer su contenido y realizar una actualización (bloqueo exclusivo).
    
2. Posteriormente, otra transacción bloquea un elemento de datos $R$ para leerlo o actualizarlo y, sin desbloquearlo, solicita el bloqueo sobre el segmento de datos $Q$, que ya está bloqueado por la transacción anterior. Como resultado, debe esperar.
    
3. Al continuar la primera transacción, y sin desbloquear $Q$, solicita el bloqueo de $R$, por lo que también tiene que esperar.
    
4. En este punto, ambas transacciones están esperando por la otra, generando un interbloqueo.
    

Sin embargo, cuando se produce un interbloqueo, si el SGBD es capaz de detectarlo, la solución es tan simple como retroceder una transacción y continuar. Por el contrario, ante un estado inconsistente, no se puede hacer nada. Por tanto, es preferible un interbloqueo a las inconsistencias.

# 3.2 Protocolo de bloqueo
Se denomina **protocolo de bloqueo** al conjunto de reglas que indican el momento en el que una transacción puede bloquear y desbloquear cada segmento de datos. Esto supone una restricción en el número de planificaciones posibles.

Se dice que una transacción **Ti** precede a otra **Tj** en una planificación cuando:

- **Ti** realiza un bloqueo sobre un elemento de datos Q.

- Posteriormente, **Tj** también realiza un bloqueo sobre ese elemento de datos, pero en un modo no compatible.  

Denominamos **planificación legal bajo un protocolo de bloqueo** a aquella que es posible para un conjunto de transacciones que sigan las reglas del protocolo de bloqueo.

Se dice que un protocolo asegura la **secuencialidad en cuanto a conflictos** si, y solo si, todas las planificaciones legales son secuenciables en cuanto a conflictos.


Un bloqueo sobre un elemento de datos solicitado por una transacción se puede conceder cuando no haya activo ningún otro bloqueo conflictivo con el que se solicita sobre el mismo elemento de datos.

Sin embargo, existe un problema denominado **inanición** en la concesión de bloqueos.

- Cuando hay un bloqueo de tipo **compartido** sobre un elemento de datos solicitado por una transacción, si otra transacción distinta quiere solicitar uno de tipo **exclusivo**, tendrá que esperar a que el primero se desbloquee.
    
- No obstante, se pueden conceder más bloqueos de tipo **compartido**, ya que no son conflictivos.
    
- Debido a esto, puede llegarse a una situación en la que la transacción que solicitó el bloqueo exclusivo se encuentre en una espera interminable. A esta situación se le conoce como **inanición**.
    

Una forma de resolver este problema es no permitir que se concedan bloqueos sobre el elemento de datos (aunque sean compatibles) si ya hay otra solicitud de bloqueo esperando.


# 3.3 Protocolo de Bloqueo en 2 Fases
El **protocolo de bloqueo en 2 fases** es un tipo de protocolo que separa en dos fases las peticiones de bloqueo y desbloqueo de una transacción. Estas fases son las siguientes:

- **Fase de crecimiento:** La transacción puede solicitar bloqueos, pero no liberarlos.

- **Fase de decrecimiento:** La transacción puede liberar bloqueos, pero no solicitar nuevos.
 
Este tipo de protocolo, además, **asegura la secuencialidad en cuanto a conflictos**. Esto es fácilmente demostrable, ya que, en base a los puntos en los que finalizan las fases de crecimiento (conocidos como **puntos de bloqueo**), las transacciones se pueden ordenar asegurando que no se producirán conflictos y se obtendrá el mismo resultado que en una planificación secuencial.

No obstante, el protocolo **no asegura que no se puedan producir interbloqueos**. Aunque separemos en dos fases los bloqueos y las liberaciones de cada transacción, si intercalamos instrucciones de la primera fase de dos transacciones diferentes, todavía podemos obtener un interbloqueo.

Además, también pueden darse **planificaciones con retrocesos en cascada**, ya que en ningún momento se impide que una transacción lea los datos escritos por otra si esta ya liberó su bloqueo en la fase de decrecimiento.

Para evitar los **retrocesos en cascada**, se puede utilizar el **protocolo de bloqueo estricto en dos fases**, el cual impide que se libere un bloqueo de tipo exclusivo hasta que se complete la transacción. De esta forma, ninguna otra transacción puede leer el dato modificado hasta que se haya comprometido la transacción que lo escribió.

## Variante que aumenta el nivel de concurrencia
Simplemente con el protocolo en dos fases se pierde concurrencia debido a que algunas transacciones deben esperar hasta que otras realicen desbloqueos para poder ejecutarse. Sin embargo, existen las conversiones de bloqueo que permiten cambiar el nivel de un bloqueo existente para facilitar la compatibilidad entre instrucciones de varias transacciones.

Pongamos por ejemplo el caso en el que una transacción primero lee un segmento de datos Q y posteriormente lo escribe, por lo que realiza un bloqueo exclusivo, mientras que otra transacción simplemente necesita leer el valor inicial de Q, por lo que solicita un bloqueo compartido. Como el bloqueo de la primera transacción es exclusivo, la segunda transacción tiene que esperar hasta que esta llegue a la fase de decrecimiento y lo desbloquee.

Sin embargo, con las conversiones de bloqueo podemos hacer que la primera transacción inicialmente solo realice un bloqueo compartido (permitiendo que ambas transacciones puedan leer concurrentemente Q) y, cuando vaya a escribir, suba el bloqueo al modo exclusivo.

Para respetar el protocolo en dos fases:

- La operación de **subir** solo está disponible en la **fase de crecimiento**.
 
- Su opuesta, **bajar**, solo está disponible en la **fase de decrecimiento**.


Todas las planificaciones que cumplan el protocolo en dos fases son **secuenciales en cuanto a conflictos**, pero existen planificaciones secuenciales en cuanto a conflictos que no se obtienen por medio del protocolo en dos fases.

Sin embargo, para obtener estas mediante otros protocolos de bloqueo que **no sean el de dos fases**, es necesario:

- Tener información adicional sobre las transacciones.

- Imponer un orden sobre el conjunto de elementos de datos de la base de datos.

### **Generación automática de bloqueos y desbloqueos**

Un esquema simple, pero de uso extendido, **genera automáticamente las peticiones de bloqueo y desbloqueo** para una transacción, basándose en sus solicitudes de lectura y escritura.

El funcionamiento es el siguiente:

- **Lectura:** Cuando una transacción solicita leer un elemento de datos, el sistema genera un **bloqueo compartido** sobre el elemento de datos y posteriormente ejecuta la instrucción de lectura.

- **Escritura:** Si ya existía un bloqueo en **modo compartido**, el sistema genera la instrucción para **subir** a dicho bloqueo. Si no existía un bloqueo, genera directamente un **bloqueo exclusivo** y posteriormente la instrucción de escritura.

- **Desbloqueo:** Para desbloquear los bloqueos, el sistema espera a que la transacción **se haya comprometido** o **haya sido abortada**.

# 4.4 Tratamiento de Interbloqueos
Una forma simple de **prevenir interbloqueos** es que cada transacción **realice bloqueos sobre todos los elementos de datos que va a tratar** antes de comenzar su ejecución, asegurándose además que o se bloquean todos o no se bloquea ninguno (bloqueo de forma atómica).

Sin embargo, esta estrategia tiene grandes desventajas ya que muchas veces **no se conocen de antemano todos los elementos que va a necesitar bloquear una transacción y la utilización de los elementos de datos puede ser baja**, teniendo elementos bloqueados mucho tiempo sin ser usados y disminuyendo claramente la concurrencia.

Otro esquema para prevenir los interbloqueos es ordenar las peticiones de bloqueo en función de los elementos de datos que vayan a bloquear, al **imponer un orden parcial sobre los elementos de datos de la base de datos**. No obstante, esto supone un gran coste al tener que ordenar todos los elementos de la base de datos.

Por último, otra aproximación para evitar interbloqueos consiste en u**tilizar expropiación y retroceso de transacciones**. Cuando una transacción solicita un bloqueo incompatible con otro vigente en otra transacción, se puede expropiar este bloqueo vigente retrocediendo dicha transacción y asignando el bloqueo a la transacción que lo solicitó. Para controlar esta expropiación se usan marcas temporales asignadas a cada transacción, que indican si la transacción debe esperar o retroceder.

Existen dos esquemas en los que se usan estas marcas temporales:

- **Esperar-Morir**: Evita la expropiación. Si la transacción que solicita el bloqueo (habiendo ya uno conflictivo activo) tiene una marca de tiempo menor (es decir, es anterior) que la de la transacción que posee el bloqueo, entonces espera. Por contra, si tiene una marca temporal mayor (y por tanto es más reciente), entonces retrocede (muere).
 
- **Herir-Esperar:** Utiliza la expropiación. Cuando una transacción solicita un bloqueo conflictivo con el de otra transacción, si la que lo solicita tiene una marca temporal mayor (es más reciente), entonces espera. En caso contrario, si tiene una marca temporal menor (es más antigua), hace retroceder a la transacción que posee el bloqueo.


Cuando el sistema no es capaz de garantizar la ausencia de interbloqueos, es necesario contar con un esquema de detención y recuperación de bloqueos que permita averiguar cuándo se producen y pueda actuar para recuperarse del mismo. Para ello, el sistema básicamente tiene que cumplir 3 pasos:

- **Mantener información** sobre la asignación de elementos de datos a las transacciones (bloqueos activos) y también sobre las peticiones pendientes (solicitudes de bloqueo).

- **Disponer de un algoritmo**, que se ejecute reiteradamente, capaz de **determinar si se ha producido un interbloqueo**.

- Ser capaz de **recuperarse del interbloqueo** cuando el algoritmo anterior lo determine.
 

Para resolver los dos primeros puntos, que se engloban dentro de la **detención de interbloqueos**, es muy común describir un **grafo dirigido** donde los nodos representan las transacciones y los arcos entre ellos simbolizan las esperas de una transacción (de la que sale el arco) debido a que está solicitando un elemento de datos reservado por otra (a la que se dirige el arco).

Por tanto, detectar un interbloqueo es tan simple como **buscar ciclos en el grafo**. Así pues, el sistema deberá implementar alguno de los múltiples algoritmos que existen para detectar ciclos en un grafo y **ejecutarlo reiteradamente**.

Sin embargo, ejecutar el algoritmo de detección de ciclos continuamente sobre un grafo cada vez mayor puede suponer un **coste bastante grande**. Por ello, hay que prever con qué probabilidad se puede dar un interbloqueo y sobre qué conjunto de elementos de datos se puede dar para ajustar la regularidad con la que se invoca al algoritmo.

# 3.5 Protocolos Basados en Validación
Cuando tenemos un conjunto de transacciones donde la mayoría son de solo lectura, la probabilidad de conflictos es baja. El sistema de concurrencia impone una sobrecarga en la ejecución del código que para estos casos puede parecer inútil, ya que en la mayor parte de los casos, incluso sin él, se llegará a un estado consistente.

En el intento de reducir esta sobrecarga, necesitamos saber de antemano qué transacciones estarán involucradas en conflictos, por lo que necesitamos supervisar el sistema. De ello se encargan los protocolos basados en validación, pensados para este tipo de conjuntos de transacciones, que asumen que cada transacción se ejecutará en dos o tres fases dependiendo de si es de solo lectura o solo escritura. Las fases son:

- **Fase de lectura**: La transacción lee los valores de la base de datos y los almacena en una variable local. Todas las operaciones de escritura se hacen sobre estas variables locales, no sobre la base de datos.
    
- **Fase de validación**: Se realiza una prueba de validación para comprobar si se pueden escribir los valores de las variables locales actualizadas en la base de datos sin causar una violación de la secuencialidad.
    
- **Fase de escritura**: Si la validación fue positiva, se escriben los valores en la base de datos. Evidentemente, las transacciones de solo lectura no ejecutan esta fase.



**Para cada una de estas fases se impone un marca temporal.**  
Por tanto tenemos la **marca de inicio**, cuando se empieza a ejecutar la transacción, la **marca de validación**, al terminar la fase de lectura y antes de realizar la prueba de validación, y la **marca de fin**, cuando la transacción finaliza la fase de escritura.

**Para fijar el orden de secuencialidad** se escoge como marca global de la transacción la marca de validación. Para la prueba de validación de la segunda fase se comprueba que, para toda transacción Ti cuya marca temporal es menor que Tj (y por tanto irá antes en un orden secuencial, o la marca Fin de Ti es menor que la marca Inicio de Tj (y por tanto se cumple el orden secuencial y no hay ningún problema), o que los datos escritos por Ti no intersecan con los leídos por Tj y además se cumple que Fin de Ti es menor que Validación de Tj (y por tanto la primera acaba antes de que empiece la validación de la segunda).

Este esquema de validación asegura que no habrá retrocesos en cascada ya que las escrituras en la base de datos tienen lugar después de que se comprometa la transacción que la ejecuta.

**Sin embargo, si puede haber inanición** ya que transacciones cortas pueden causar el continuo fallo de validación de una transacción larga, haciendo que esta no prosiguiese nunca. Una forma de superarlo sería bloquear temporalmente las transacciones cortas hasta hacer avanzar a la larga.

A los **protocolos basados en validación** se les denomina protocolos optimistas ya que supone que las transacciones son capaces de finalizar y se realiza la validación al final. Por contra estarían los **protocolos pesimistas**, como los bloqueos o la ordenación por marcas temporales, que suponen que las transacciones no van a ser capaces de finalizar y toman medidas preventivas que fuerzan esperas y retrocesos.

# 3.6 Aislamiento de Instantáneas
Una forma de **mejorar la concurrencia** es realizar diversas copias (**instantáneas**) de la base de datos y hacer que las transacciones trabajen con ellas en lugar de provocar esperas. Esto es básicamente lo que hace el a**islamiento de instantáneas**, el cual proporciona una instantánea de la base de datos a cada transacción en el momento en el que esta comienza su ejecución. La transacción trabajará sobre esta copia, y solo se escribirán los cambios realizados de vuelta a la base de datos cuando la transacción se haya comprometido.

Por tanto, parece evidente que esta es una solución muy buena para las transacciones de **solo lectura**, ya que de esta forma nunca tendrán que esperar ni serán retrocedidas. 

Sin embargo, para transacciones de **actualización** puede ocurrir un problema si varias actúan sobre el mismo elemento de datos, cada una en su copia. La primera transacción se comprometerá y escribirá los cambios realizados en su copia en la base de datos pero, posteriormente, la segunda también se comprometerá y escribirá su modificación sobre los datos originales en la base de datos, haciendo que se pierda la actualización de la primera transacción. A este **problema se le conoce como problema de la actualización perdida**. 

Para solucionar este problema de la actualización perdida existen dos variantes del protocolo de aislamiento de instantáneas: 

- **Primer compromiso gana**: Solo se escriben los datos de la primera transacción que se comprometa dentro del conjunto de transacciones que realicen actualizaciones sobre un elemento de datos común. Por tanto, todas las demás transacciones abortan. Para controlar quién se compromete primero se usan marcas temporales.  

- **Primera actualización gana**: Cada transacción solicita un bloqueo sobre el elemento de datos que quiere escribir y espera hasta que se le conceda. Si al serle concedido ve que los datos ya han sido actualizados por otra transacción, aborta. En caso contrario, realiza su actualización y posteriormente lo escribe en la base de datos.

El **protocolo de aislamiento de instantáneas** no asegura la secuencialidad ya que puede darse el caso en el que una transacción lea un elemento de datos antes de que otra lo escriba, y a su vez esta otra lea un elemento de datos distinto antes de que la primera lo actualice. Como podemos ver, el resultado obtenido no será el mismo que si las transacciones se ejecutasen de forma secuencial.

Otro problema surge cuando cada transacción lee un dato de la otra pero no escriben nada en común. De hecho, podemos comprobar que no existe ningún conflicto entre ambas transacciones y, sin embargo, aunque pueden ser comprometidas debido a esto, puede que su ejecución concurrente viole alguna restricción. A este problema se le denomina **atasco de escritura**.

Un ejemplo lo tenemos en el caso de un banco. Imaginemos que una restricción nos indica que la suma de los valores de las cuentas de una persona no puede ser negativo. Supongamos una persona con una cuenta **A** con 100 euros y una cuenta **B** con 200 euros.

- **Primera transacción:** Retira 200 euros de **A** y tras comprobar que la suma de A + B sigue siendo positiva, escribe el resultado.
 
- **Segunda transacción:** Concurrentemente, retira 200 euros de **B**, y tras comprobar que en esa instantánea A + B sigue siendo positivo, escribe el valor actualizado en la base de datos.
 
Ambas se comprometen sin problema al haber escrito elementos de datos distintos. Sin embargo, en la base de datos tenemos ahora los valores **A = -100 euros** y **B = 0 euros**, lo que da una suma negativa, que viola la restricción inicial.

Una forma de evitar este problema es el uso de **cláusulas "for update"**. Con estas cláusulas, el sistema trata a los datos leídos como si hubieran sido actualizados, de forma que con dos transacciones concurrentes que leen un elemento de datos común pero no lo escriben, una de ellas tendría que retroceder, evitando así violar restricciones como en el caso anterior. Sin embargo, el principal problema de esta solución es que al tratar las lecturas como escrituras se pierde concurrencia.

Ejemplos de sistemas que implementan el aislamiento de instantáneas para algún nivel de aislamiento concreto son:

- **SQLServer:** Implementa un nivel específico para este protocolo de aislamiento de instantáneas.

- **PostgreSQL:** En el nivel de aislamiento secuenciable solo ofrece aislamiento de instantáneas.
 
- **Oracle:** Igual que PostgreSQL, el nivel de aislamiento secuenciable solo ofrece aislamiento de instantánea.
 
# 3.7 Operaciones de insertado y borrado, y lectura de predicados.
Teniendo las operaciones **insertar**, **borrar**, **leer** y **escribir** aplicadas sobre un mismo elemento de datos, parece obvio que no vamos a obtener el mismo resultado si movemos el orden de ejecución de las mismas.

Por un lado, tendremos **errores lógicos** si primero leemos un segmento de datos y posteriormente lo insertamos, o si primero lo borramos y a continuación lo intentamos leer. Podemos sustituir la operación de lectura por la de escritura y seguiremos teniendo los mismos errores, pues el segmento de datos al que queremos acceder no existe en la base de datos en ese momento.

Por tanto, podemos concluir que **borrar está en conflicto con leer y escribir**, pero también con insertar (por exactamente el mismo problema que el descrito para el caso borrar-escribir, pues si no existe el elemento de datos, porque no se ha insertado todavía, no se puede borrar).

A su vez, **insertar está en conflicto con leer, escribir y borrar** por lo visto arriba, pero no está en conflicto con otra instrucción de insertar, pues esta puede considerarse como un caso de insertar-escribir, la cual no da ningún problema en ese orden.

# 3.8 Fenómeno Fantasma
Supongamos que tenemos una instrucción de **lectura** sobre un elemento de datos y otra de **inserción** de una tupla adicional sobre el mismo elemento de datos. Si se ejecuta primero la de lectura y posteriormente la de inserción obtendremos un resultado distinto a si se ejecutan en orden inverso.

Sin embargo, a pesar de que es evidente que por lo tanto esta planificación no es secuenciable, en el primero de los casos, **no comparten ningún dato entre ellas**. Por lo tanto, el conflicto se genera debido a una tupla que todavía no existe en la base de datos. A este fenómeno se le conoce como el **fenómeno fantasma**.

Existen **3 posibles soluciones**:
- **Bloqueo de relación**: Se asocia el elemento de datos con la relación. Por tanto, las transacciones que leen solicitan un bloqueo compartido sobre el elemento de datos, mientras que las que actualicen la información acerca de qué tuplas pertenecen a la relación solicitan uno exclusivo. De esta forma la actualización y la lectura entran en conflicto en un elemento de datos real (la relación) en vez de en uno fantasma (la tupla). Sin embargo, el bloqueo de este elemento de datos no impide poder acceder a una tupla específica de forma concreta, sino que solo evita transacciones acerca de qué tuplas pertenecen a la relación. Por ello, es posible que se generen inconsistencias igualmente. Además, baja considerablemente la concurrencia al producir bloqueos sobre elementos de datos tan grandes.

- **Bloqueo de índice**: Cada relación mantiene al menos un índice. Estos índices, que se representan en un árbol B+, son los que se usan para acceder a un elemento de datos. Cuando se necesita solicitar un bloqueo, se hace sobre el índice en el árbol. De esta forma, se evita el fenómeno fantasma (ahora el conflicto es sobre los elementos asociados a ese índice), y también el problema al acceso de los elementos que deberían estar bloqueados que suponía el bloqueo de relación.

- **Bloqueo de predicado**: Es el empleado por **SQL** desde su versión 9.1. Se realizan bloqueos compartidos sobre los predicados en una consulta. En el caso del borrado o la inserción, se comprueba si entra en conflicto con el predicado bloqueado. Si es así, espera; en caso contrario, se realiza.

# 3.9 Control de Concurrencia en interacciones de usuario
Cuando existe **iteración con el usuario**, los problemas de la **concurrencia** se hacen más notorios. Pongamos por ejemplo el caso de la **reserva de asiento en un avión**. Al usuario se le muestra una **imagen estática** con los asientos libres que representa el estado de la base de datos al momento en el que accedió a la página. Sin embargo, otro usuario que acceda justo después puede encontrarse con exactamente la misma imagen.

Por tanto, estos dos usuarios pueden querer **reservar el mismo asiento**, generando un estado de inconsistencia. Una solución sencilla sería **bloquear todos los asientos** mientras un usuario está en la página de reserva. De esta forma, se asegura que no se producirá ningún tipo de inconsistencia. Sin embargo, el usuario puede hacer que otros **esperen indefinidamente** antes de poder realizar su reserva, perdiendo completamente la concurrencia, lo cual es **muy ineficiente**.

Otra solución puede ser aplicar **aislamiento de instantáneas**, en la que nuevamente volvemos a permitir que los usuarios accedan a la página de la reserva y vean una imagen de los asientos libres (instantánea de la base de datos) que había en el momento en el que entraron. Cuando dos usuarios seleccionen el mismo asiento, a la transacción iniciada por uno de los dos se le hará **retroceder**.

Por el hecho de aplicar el protocolo de aislamiento de instantáneas, tendremos que guardar una copia de los **datos modificados** mientras haya transacciones concurrentes activas, y puede ser que un usuario tarde mucho en finalizar su transacción, lo que obliga a alargar el tiempo que se mantiene la copia, incluso aunque la transacción que trabajó con ella se haya **comprometido** ya.

En la práctica se opta por dividir la transacción en **2 partes**. En la primera se leen los asientos disponibles y se le muestran al usuario, dejando que este pase todo el tiempo que quiera escogiendo su asiento favorito. Posteriormente, una vez lo haya seleccionado, se ejecuta la **segunda parte**, en la cual se comprueba si el asiento sigue estando disponible.

# 3.10 Control de concurrencia optimista
El **protocolo de control de concurrencia optimista sin validación de lectura** supone un esquema de control de concurrencia similar al de **aislamiento de instantáneas**, sin embargo, la **lectura** que realiza la transacción puede no corresponderse con la de la instantánea de la base de datos y, al contrario que el protocolo basado en validación, las **lecturas** realizadas por la transacción no se validan.

Este esquema de control de concurrencia emplea **números de versión** que se almacenan en las propias tuplas y evitan el **problema de la actualización perdida**. Al insertar la tupla, este número de versión toma el valor **0**. Cuando una transacción lee por primera vez la tupla para actualizarla, guarda su número de versión.

De forma local, la transacción actualiza la tupla y, al momento de **escribirla**, comprueba que el número de versión de la tupla es el mismo que cuando lo leyó anteriormente. Si coincide, **actualiza la tupla en la base de datos** e **incrementa en 1 el valor del número de versión**. En caso contrario, **abortará y retrocederá las actualizaciones**. Si la comprobación es correcta para todas las tuplas, la transacción es **comprometida**.