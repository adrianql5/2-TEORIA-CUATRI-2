# 1.1 Frames por Segundo (FPS)
El **FPS** (Frames per Second) es una medida de cuántas imágenes se generan en un segundo. En computación gráfica, esto indica la fluidez con la que se actualiza una escena en una pantalla.

- **24 FPS**: Es la tasa estándar en el cine, lo que se considera suficiente para simular movimiento sin ser demasiado notorio que son imágenes estáticas.
- **50 y 60 FPS**: En televisores antiguos, las frecuencias de refresco eran de **50 Hz** en Europa y **60 Hz** en América debido a la frecuencia de la electricidad (50 Hz y 60 Hz son comunes en las redes eléctricas).
- **30-60 FPS en videojuegos**: Se busca que los juegos mantengan entre **30 y 60 FPS** para asegurar una experiencia fluida. Si el FPS es más bajo, el juego se vuelve menos fluido, mientras que un FPS más alto mejora la experiencia visual.

**Optimización**: Si un juego no alcanza el rendimiento deseado, reducir la calidad gráfica (por ejemplo, de las texturas) puede aumentar el FPS, mejorando la fluidez de la experiencia.

# 1.2 Tuberías de Rayos Catódicos (TRC)
Los **monitores CRT** (o tubos de rayos catódicos) fueron los primeros tipos de pantallas utilizadas en televisores y computadoras. Funcionaban proyectando un **haz de electrones** sobre una pantalla cubierta de **fósforo fluorescente**, lo que provocaba que la pantalla se iluminara.

- La **persistencia del fósforo** influía en la frecuencia mínima de refresco que podía alcanzar el monitor, típicamente de **50 Hz** en Europa.
- Los monitores **monocromáticos** usaban un solo haz de electrones, mientras que los monitores en color usaban tres haces (uno para cada color primario: **rojo, verde, azul**).

Estos monitores fueron reemplazados gradualmente por tecnologías como **LCD** y **LED** en la década de 2000.


# 1.3 Terminales Vectoriales
Los **terminales vectoriales** fueron una de las primeras tecnologías gráficas para computadoras, a diferencia de las pantallas modernas, que están basadas en píxeles. Los terminales vectoriales representaban imágenes **directamente como líneas**, no como una cuadrícula de píxeles.

- Estos terminales usaban memoria para almacenar instrucciones de dibujo, lo que permitía controlar el trazado de líneas en lugar de dibujar cada píxel individualmente.


# 1.4 Terminales Raster
Los **terminales raster** aparecieron en los años 70 y reemplazaron a los terminales vectoriales. En lugar de trabajar con líneas, los terminales raster utilizaban una **matriz de píxeles** (rasterización).

1. **Matriz de píxeles**: Las imágenes se guardan como una cuadrícula de pequeños puntos (píxeles), donde cada píxel tiene información de color.
2. **Escaneo secuencial**: Un haz de electrones recorre la pantalla de **izquierda a derecha y de arriba a abajo** para iluminar los píxeles según la información almacenada.
3. **Frame Buffer**: Es la memoria donde se almacenan los valores de cada píxel (información sobre si está encendido o apagado, o su color).

Un **ejemplo práctico** de esta tecnología es la televisión en blanco y negro, donde cada píxel solo podía estar encendido (blanco) o apagado (negro).


# 1.5 Frame Buffer y Color Buffer
**Frame Buffer** es la memoria donde se almacena temporalmente la imagen antes de enviarla al monitor.

- **Cálculo del tamaño del Frame Buffer**: Si tienes una pantalla de **640x480 píxeles** y estás trabajando en **blanco y negro**, necesitas **640×480 bits** de memoria.
    
    Para una pantalla a color con **24 bits por píxel** (8 bits para cada componente de color: rojo, verde y azul), el cálculo sería:
    
    $$640 \times 480 \times 24 \div 8 = 0.92 \text{ MB}$$
    
    El uso de más **bits por píxel** (como en 24 bits para color real) aumenta el espacio necesario en la memoria.
    

**Color Buffer** es donde se guarda la imagen final lista para ser mostrada. En OpenGL, se usan ambos: **frame buffer** para almacenamiento temporal y **color buffer** para la imagen que finalmente se presenta en la pantalla.


# 1.6 Proceso de Rasterización
> [!Aclaración]
> **Renderizar** es el proceso de generar una imagen a partir de datos en bruto, generalmente en gráficos 3D. En otras palabras, es convertir un modelo digital en una imagen visible en la pantalla.

La **rasterización** es una de las etapas clave dentro del proceso de **renderizado**. Su objetivo es convertir una escena 3D en una imagen 2D que pueda ser mostrada en la pantalla. Este proceso implica varios pasos importantes:

1. **Conversión de coordenadas**: Los objetos 3D en la escena se transforman de sus coordenadas locales a coordenadas globales (espacio de la escena), y luego se proyectan a coordenadas 2D (pantalla).
    
2. **Ensamblaje de vértices**: Los vértices de los objetos 3D se conectan para formar las caras de los modelos. Esto puede incluir triángulos u otras formas poligonales que representen la geometría de los objetos.
    
3. **Proyección sobre la pantalla**: Se proyectan estas caras 3D en el plano 2D de la pantalla. Este paso tiene en cuenta la perspectiva, lo que permite simular cómo los objetos lejanos se ven más pequeños y los cercanos más grandes, según la distancia al espectador.
    
4. **Rasterización**: Aquí es donde los polígonos proyectados sobre la pantalla se convierten en **píxeles**. Cada triángulo o polígono se divide en una cuadrícula de píxeles y se les asigna un color basado en los vértices, las texturas, y las luces de la escena.
    
5. **Interpolación de colores**: Una vez rasterizados los píxeles, se interpolan los colores entre los vértices del objeto, tomando en cuenta las texturas y los efectos de iluminación, para que la imagen final tenga el aspecto visual adecuado.
    

A partir de **OpenGL 3.3**, se introdujeron los **vertex shaders** y **fragment shaders** como parte de este proceso de renderizado, permitiendo un control más preciso y flexible sobre cómo se manejan los vértices y los píxeles:

- **Vertex Shaders**: Permiten manipular la geometría de los objetos antes de la rasterización, por ejemplo, para aplicar animaciones o transformaciones.
    
- **Fragment Shaders**: Controlan el color de cada píxel tras la rasterización, permitiendo efectos como iluminación dinámica, sombras, y otros detalles visuales.
    

![[Pasted image 20250228205458.png]]
>[!Nota]
>Los **shaders** proporcionan un control fino sobre los aspectos visuales de una escena, permiten una **gran optimización del rendimiento** gracias al uso de la **GPU**, y facilitan la implementación de efectos visuales complejos y dinámicos, lo que los hace esenciales para cualquier aplicación gráfica moderna, desde videojuegos hasta simulaciones realistas en tiempo real.

# 1.7 Conceptos Generales de COGA
- **Double Buffering (Doble Búfer)**: Esta técnica utiliza dos búferes de imágenes (primario y secundario) para evitar el parpadeo de la imagen. Mientras el sistema renderiza una imagen en el **búfer secundario**, el **búfer primario** muestra la imagen ya renderizada. Una vez que la imagen en el búfer secundario está lista, los búferes se intercambian rápidamente, proporcionando una transición suave y sin parpadeos.
    
- **Depth Buffer (Z-Buffer)**: El **Z-buffer** resuelve el problema de la visibilidad de los objetos cuando se superponen en la escena. Cada píxel en la pantalla tiene una coordenada de **profundidad (z)**, que indica qué tan lejos está del espectador. El Z-buffer guarda estos valores de profundidad y, al renderizar, asegura que solo se muestren los píxeles más cercanos al espectador (los de menor valor **z**), lo que elimina problemas como el de los objetos que se "enciman" de manera incorrecta.
    


