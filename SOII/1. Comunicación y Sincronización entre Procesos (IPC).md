C√≥mo un proceso puede pasar informaci√≥n a otro, c√≥mo hacer que dos o m√°s procesos no se interpongan entre s√≠, c√≥mo obtener la secuencia apropiada cuando hay dependencias presentes.

# 1.1 Condiciones de Carrera
Los procesos que trabajan en conjunto pueden **compartir cierto espacio de almacenamiento** en el que pueden leer y escribir datos. Este almacenamiento compartido puede estar tanto en la **RAM** (*en una estructura de datos*) o en un **archivo compartido**. 

Como ejemplo tenemos un **directorio de spooler** que se usa para imprimir archivos mediante el **demonio de impresi√≥n**. Cada ranura del spooler contiene el nombre de un archivo. Si hay dos variables compartidas `sal` que apunta al siguiente archivo a imprimir y `ent` que apunta a la siguiente ranura libre. Estas variables se pueden guardar en una archivo compartido para los procesos.

Pongamos que tenemos las ranuras 0-3 est√°n vac√≠as y las 4-6 llenas, y dos procesos desean poner en cola a un proceso para imprimirlo.

![[Pasted image 20250215133706.png]]
El proceso **A** lee `ent` y guarda el valor 7 en una variable local llamada `siguiente_ranura_libre`. Despu√©s pasa el proceso **B** que lee `ent` y recibe un 7 y lo guarda en su variable local. **B** almacena el nombre de su archivo en la ranura 7 y actualiza `ent` para que valga 8.

En cierto momento **A** sabe que para el su ranura libre es la 7 y sobreescribe el nombre del archivo escrito por **B**, por lo que el archivo de **B** nunca se imprime.

Situaciones como estas en donde dos o m√°s procesos est√°n leyendo o escribiendo algunos datos compartidos y el resultado final depende de qui√©n se ejecuta y exactamente cu√°ndo lo hace, se conocen como **condiciones de carrera**. **Muy complejo depurar el codigo**.

# 1.2 Regiones Criticas
Para evitar condiciones de carrera debemos prohibir que varios procesos elan y escriban los datos compartidos (*archivos, memoria compartida, etc.*) al mismo tiempo. Necesitamos **exclusi√≥n mutua**. En el ejemplo del Spooler el proceso **B** empez√≥ a utilizar las variables compartidas antes de que **A** hubiese acabado con ellas.

**Regi√≥n Cr√≠tica:** parte del programa en la que se accede a la memoria compartida. 

Si pudi√©ramos ordenar las cosas de manera que dos procesos nunca estuvieran en sus regiones cr√≠ticas al mismo tiempo, evitar√≠amos las carreras. Aunque esto evita las condiciones de carrera, **no es suficiente para que los procesos en paralelo cooperen** de forma correcta y eficiente.

- No puede haber dos procesos de manera simult√°nea dentro de sus regiones cr√≠ticas
- No pueden hacerse suposiciones acerca de las velocidades o el n√∫mero de CPUs.
- Ning√∫n proceso que se ejecute fuera de sus regi√≥n cr√≠tica puede bloquear otros procesos.
- Ning√∫n proceso tiene que esperar para siempre a entrar a su regi√≥n cr√≠tica.

![[Pasted image 20250322112620.png]]

# 1.3 Exclusi√≥n mutua con espera ocupada
El objetivo es lograr la **exclusi√≥n mutua** de manera que mientras un proceso est√© ocupada utilizando la memoria compartida en su regi√≥n cr√≠tica, ning√∫n otro proceso puede entrar a su regi√≥n cr√≠tica y ocasionar problemas.

## 1.3.1 Deshabilitando interrupciones
En un sistema con un solo procesador, la soluci√≥n m√°s simple es hacer que cada proceso deshabilite todas las interrupciones justo despu√©s de entrar a su regi√≥n cr√≠tica y las rehabilite justo despu√©s de salir. As√≠ **evitamos las interrupciones de reloj** que marcan cuando la **CPU conmuta de un proceso a otro**. Esto evita que otro proceso intervenga

Sin embargo no es conveniente dar a los procesos de usuario el poder de desactivar las interrupciones. Y si tenemos m√°s de una CPU, solo se ve afectada la CPU que ejecut√≥ la instrucci√≥n disable, las dem√°s se ejecutan correctamente y accediendo a la memoria compartida.

## 1.3.2 Variables de candado
**Soluci√≥n software**. Si tenemos una variable compartida que es 0 inicialmente. Cuando un proceso desea entrar a su regi√≥n cr√≠tica primero eval√∫a el candado. Si es 0, el proceso lo fija en 1 y entra a la regi√≥n cr√≠tica. Si el candado ya es 1 s√≥lo espera hasta que el candado sea 0. 

**Un 0 significa que ning√∫n proceso est√° en la regi√≥n cr√≠tica y un 1 significa que alg√∫n proceso est√° en su regi√≥n cr√≠tica**. 

Sin embargo puede suceder lo mimo que en el Spooler. Si un proceso lee el candado y ve que es 0. Antes de que pueda fijar el candado a 1, otro procesos se planifica para ejecutarse y fija el candado a 1. Cuando el primer proceso se ejecuta de nuevo, tambi√©n fija el candado a 1 y por lo tanto dos procesos se encontraran en sus regiones cr√≠ticas al mismo tiempo.

## 1.3.3 Alternancia estricta
![[Pasted image 20250322114243.png]]
La variable **turno** lleva la cuenta acerca de que proceso le toca entrar a su regi√≥n cr√≠tica y examinar o actualizar la memoria compartida. El **proceso 0** inspeccionar turno, descubre que es 0 y **entra a su region cr√≠tica**. El **proceso 1** ve que es 0 por lo que se queda evaluando turno de forma continua. **La acci√≥n a evaluar en forma continua de una variable hasta que aparezca cierto valor se conoce como espera ocupada.**

Esta espera ocupada se debe intentar evitar ya que desperdicia tiempo de cpu, solo se usa cuando se cree que la espera ser√° corta. 

Cuando el proceso 0 sale de la regi√≥n cr√≠tica establece turno a 1, para permitir que el proceso 1 entre a su regi√≥n cr√≠tica. Suponga que el proceso 1 sale r√°pidamente de su regi√≥n cr√≠tica, de manera que ambos procesos se encuentran en sus regiones no cr√≠ticas, con turno establecido en 0. Ahora el proceso 0 ejecuta todo su ciclo r√°pidamente, saliendo de su regi√≥n cr√≠tica y estableciendo turno a 1. En este punto, turno es 1 y ambos procesos se est√°n **ejecutando en sus regiones no cr√≠ticas**.

De repente, el proceso 0 termina en su regi√≥n no cr√≠tica y regresa a la parte superior de su ciclo. Por desgracia no puede entrar a su regi√≥n cr√≠tica ahora, debido a que turno es 1 y el proceso 1 est√° ocupado con su regi√≥n no cr√≠tica. El proceso 0 espera en su ciclo while hasta que el pro- ceso 1 establezca turno a 0. Dicho en forma distinta, tomar turnos no es una buena idea cuando uno de los procesos es mucho m√°s lento que el otro. Esta situaci√≥n viola la condici√≥n 3 antes establecida:

- Ning√∫n proceso que se ejecute fuera de sus regi√≥n cr√≠tica puede bloquear otros procesos.

## 1.3.4 Soluci√≥n de Peterson
![[Pasted image 20250322121723.png]]
Antes de utilizar las variables compartidas (es decir, antes de entrar a su regi√≥n cr√≠tica), cada proceso llama a `entrar_region` con su propio n√∫mero de proceso como par√°metro. Esta llamada har√° que espera, si es necesario, hasta que sea seguro entrar. 

Cuando termina de usar las **variables compartidas** llama a `salir_region` para indicar que ha terminado y permitir que los dem√°s procesos entren, si as√≠ lo desean.

El **proceso 0** llama a `entrar_region`. Indica su inter√©s estableciendo su elemento del arreglo y fija **turno a 0**. Como el proceso 1 no est√° interesado, `entrar_region` regresa de inmediato. Si ahora el **proceso 1** hace una llamada a `entrar_region`, se quedar√° ah√≠ hasta que interesado[0] sea **FALSE**, un evento que s√≥lo ocurre cuando el **proceso 0** llama a `salir_region` para salir de la regi√≥n cr√≠tica.

Ahora considere el caso en el que ambos procesos llaman a `entrar_region` casi en forma simult√°nea. Ambos almacenar√°n su n√∫mero de proceso en **turno**. Cualquier almacenamiento que se haya realizado al √∫ltimo es el que cuenta; **el primero se sobrescribe y se pierde**. Suponga que el **proceso 1** almacena al √∫ltimo, por lo que **turno es 1**. Cuando ambos procesos llegan a la instrucci√≥n `while`, el **proceso 0 la ejecuta 0** **veces** **y entra a su regi√≥n cr√≠tica**. El **proceso 1 itera y no entra a su regi√≥n cr√≠tica sino hasta que el proceso 0 sale de su regi√≥n cr√≠tica**.

## 1.3.5 Instrucci√≥n TSL
La instrucci√≥n **TSL (Test and Set Lock)** es una instrucci√≥n especial de bajo nivel que se usa en sistemas multiprocesador para garantizar la exclusi√≥n mutua en regiones cr√≠ticas. Se trata de una operaci√≥n at√≥mica que ayuda a evitar **condiciones de carrera** cuando varios procesos intentan acceder a una variable compartida.

- **Lee el valor** de una variable de memoria compartida (llamada **candado**) y lo guarda en un registro.
- **Fija la variable** candado a un valor distinto de 0 (por ejemplo, 1) en memoria, asegurando que otros procesos no puedan modificarla.
- **Bloquea el bus de memoria** temporalmente mientras ejecuta estas dos operaciones, asegurando que ning√∫n otro procesador pueda acceder a la variable hasta que la instrucci√≥n termine.

Es una alternativa para evitar condiciones de carrera es **deshabilitar interrupciones** antes de acceder a la regi√≥n cr√≠tica. Sin embargo, esto **no funciona en sistemas multiprocesador** porque:
- Deshabilitar interrupciones en un procesador **no afecta a los dem√°s**.
- Otro procesador puede leer la variable compartida y modificarla mientras el primero a√∫n est√° ejecutando su c√≥digo.

![[Pasted image 20250322123107.png]]


# 1.4 Dormir y Despertar
Para evitar la espera ocupada, se introduce el mecanismo de **Dormir y Despertar** con dos primitivas de comunicaci√≥n entre procesos:

1. **`sleep()`** ‚Üí Suspende el proceso actual **hasta que otro proceso lo despierte**.
2. **`wakeup(proceso)`** ‚Üí Despierta un proceso suspendido, permiti√©ndole continuar su ejecuci√≥n.

Esto significa que **si un proceso no puede entrar a la regi√≥n cr√≠tica, en lugar de quedarse en un bucle gastando CPU, simplemente se suspende hasta que otro proceso lo despierte**.

## 1.4.1 El problema del productor-consumidor
Dos procesos comparten un **buffer compartido de tama√±o fijo**. El productor coloca informaci√≥n en el buffer y el consumidor la saca. 

El problema surge cuando el productor desea colocar un nuevo elemento en el buffer, pero este ya est√° lleno. La soluci√≥n es que se vaya a dormir y se despierte cuando el consumidor haya quitado uno o mas elementos. Lo mismo cuando el buffer esta vac√≠o y el consumidor quiere retirar elementos.

Parece simple, pero genera los mismos **tipos de condiciones de carrera** del directorio de Spooler. Necesitamos la variable cuenta para saber llevar la cuenta de elementos en el buffer. 

![[Pasted image 20250322124847.png]]

Los procedimientos `insertar_elemento` y `quitar_elemento`, que no se muestran aqu√≠ se encargan de colocar elementos en el buffer y sacarlos del mismo. 

Debido a que el acceso a cuenta no est√° restringido. Es posible que ocurra la condici√≥n de carrera en la siguiente situaci√≥n: **el buffer est√° vac√≠o y el consumidor acaba de leer cuenta para ver si es 0**. En ese instante, el planificador decide detener al consumidor en forma temporal y empieza a ejecutar el productor.

El productor inserta un elemento en el buffer, incrementa cuenta y observa que ahora es 1. Razonando que cuenta era antes 0, y que por ende el consumidor debe estar dormido, el productor llama a wakeup. Sin embargo, el consumidor no est√° l√≥gicamente dormido, por lo que la se√±al para despertarlo se pierde. Cuando es turno de que se ejecute el consumidor, eval√∫a el valor de cuenta en que ley√≥ antes, encuentra que es 0 y pasa a dormirse. Tarde o temprano el **productor llenar√° el buffer y tambi√©n pasar√° a dormirse**, quedando ambos dormidos para siempre.

La esencia del problema aqu√≠ es que una se√±al que se env√≠a para despertar a un proceso que no est√° dormido (todav√≠a) se pierde. Si no se perdiera, todo funcionar√≠a. 

# 1.5 Sem√°foros
**Sem√°foro**, variable entera para contar el n√∫mero de se√±ales de **wakeup**, guardadas para un uso futuro. Almacena el valor 0, indicando que no se guardaron se√±ales de despertar o alg√∫n valor positivo si estuvieran pendientes una o m√°s se√±ales de **wakeup**.

Tenemos dos operaciones, `down` y `up` (generalizaciones de `sleep` y `wakeup`). La operaci√≥n `down` comprueba si el valor es mayor que 0. De ser as√≠, disminuye el valor(utiliza una se√±al de despertar almacenada) y s√≥lo contin√∫a.

Si el valor es 0, el proceso se pone a dormir sin completar la operaci√≥n `down` por el momento. Las acciones de comprobar el valor, modificarlo y posiblemente dormir, se realizan en conjunto como una sola **acci√≥n at√≥mica** indivisible. 

Una vez que empieza la operaci√≥n de sem√°foro, ning√∫n otro proceso podr√° accede al sem√°foro sino hasta que la operaci√≥n se haya completado o bloqueado. Esto resuelve problemas de sincronizaci√≥n y evita condiciones de carrera.

La operaci√≥n `up` incrementa el valor del sem√°foro direccionado. Si uno o m√°s procesos estaban inactivos en ese sem√°foro, sin poder completar una operaci√≥n `down` anterior, el sistema selecciona uno de ellos (al azar) y permite que complete su operaci√≥n `down`.

## 1.5.1 Resolver el problema del productor-consumidor mediante el uso de sem√°foros

En este caso, se utilizan tres sem√°foros para coordinar el acceso al b√∫fer compartido:

- **Sem√°foro `llenas`**: Cuenta cu√°ntas ranuras del b√∫fer est√°n ocupadas:    
    - Inicialmente es 0 porque el b√∫fer comienza vac√≠o.
    - Se incrementa (`up`) cuando el productor coloca un elemento.
    - Se decrementa (`down`) cuando el consumidor retira un elemento.
    
- **Sem√°foro `vac√≠as`**: Cuenta cu√°ntas ranuras del b√∫fer est√°n disponibles. 
    - Se inicializa con el tama√±o total del b√∫fer (porque al inicio est√° completamente vac√≠o).
    - Se decrementa (`down`) cuando el productor coloca un elemento.
    - Se incrementa (`up`) cuando el consumidor extrae un elemento.
    
- **Sem√°foro `mutex`**: Asegura que solo un proceso (productor o consumidor) acceda al b√∫fer a la vez.
    - Se inicializa en 1 (se trata de un sem√°foro binario).
    - Se usa para garantizar **exclusi√≥n mutua**:
        - El productor lo adquiere (`down`) antes de escribir y lo libera (`up`) despu√©s.
        - El consumidor lo adquiere (`down`) antes de leer y lo libera (`up`) despu√©s.


## **Implementaci√≥n de `up` y `down`**
Las operaciones `up` y `down` deben ser **at√≥micas** (indivisibles). Para garantizar esto, el sistema operativo suele deshabilitar las interrupciones brevemente mientras se realiza la operaci√≥n. En sistemas con m√∫ltiples CPUs, se protege el sem√°foro con una variable de candado y **operaciones at√≥micas** como `TSL` (Test and Set Lock) o `XCHG` para evitar que varias CPUs lo modifiquen al mismo tiempo.



## **Flujo de ejecuci√≥n**
![[Pasted image 20250324164420.png]]

## **Uso de sem√°foros en manejo de interrupciones**

Los sem√°foros tambi√©n pueden sincronizar procesos con dispositivos de E/S. Cada dispositivo de E/S puede tener un sem√°foro inicializado en 0.

- Cuando un proceso inicia una operaci√≥n de E/S, hace `down` en el sem√°foro y se bloquea.
    
- Cuando la interrupci√≥n de E/S ocurre, el manejador hace `up` en el sem√°foro, despertando al proceso.
    

Esto evita que los procesos hagan espera ocupada y permite que el planificador de CPU ejecute otras tareas mientras espera la E/S.

### Funciones clave

|Funci√≥n|Descripci√≥n|
|---|---|
|`sem_init()`|Inicializa un sem√°foro.|
|`sem_wait()`|Decrementa el sem√°foro (espera si es 0).|
|`sem_post()`|Incrementa el sem√°foro (libera un recurso).|
|`sem_destroy()`|Libera recursos del sem√°foro.|
# 1.6 Mutexes
Los **mutexes** son buenos para administrar la exclusi√≥n mutua para cierto recurso compartido o pieza de c√≥digo. 

Un **mutex** es una variable que puede estar en uno de dos estados: **abierto** (*desbloqueado*) o **cerrado** (*bloqueado*). En consecuencia, se requiere s√≥lo 1 bit para representarla, pero en la pr√°ctica se utiliza con frecuencia un entero, en donde **0 indica que est√° abierto** y todos los dem√°s valores indican que est√° **cerrado**.

Cuando un hilo necesita acceso a una **regi√≥n cr√≠tica**, llama a `mutex_lock`. Si el mutex est√° actualmente abierto, la llamada tiene √©xito y el **hilo llamador puede entrara la regi√≥n cr√≠tica**.

Si el mutex ya **se encuentra cerrado**, el hilo que hizo la llamada se **bloquea** hasta que el hilo que est√° en la regi√≥n cr√≠tica termine y llame a `mutex_unlock`. Si se bloquean varios hilos por el mutex, se selecciona uno de ellos al azar y se permite que adquiera el mutex.

`mutex_lock` es similar al c√≥digo de `entrar_region`pero la diferencia es que en `entrar_region`, cuando no puede entrar, contin√∫a evaluando el mutex en forma repetida (*espera ocupada*). Cuando el reloj expire alg√∫n otro proceso se programar√° para ejecutarlo. Cuando tenemos **hilos** no hay reloj, por lo que si empleamos la **espera ocupada** lo intentar√° adquirir de forma indefinida y nunca adquirira un mutex debido a que nunca permitir√° que alg√∫n otro hilo se ejecute y libere el mutex. Entonces por eso `mutex_lock` llama a `thread_yield` para darle CPU a otro hilo.

Como se llama al `thread_yield` en el espacio de usuario es muy r√°pido y ni `mutex_lock` ni `mutex_unlock` requieren de llamadas al kernel.


## Mutexes (Mutual Exclusion Locks)
Los **mutexes** sirven para proteger **regiones cr√≠ticas** en las que solo un hilo debe acceder a la vez, evitando que m√∫ltiples hilos modifiquen datos compartidos simult√°neamente y generen condiciones de carrera.


|**Funci√≥n**|**Descripci√≥n**|
|---|---|
|`pthread_mutex_init`|Crea un mutex antes de usarlo|
|`pthread_mutex_destroy`|Destruye un mutex cuando ya no se necesita|
|`pthread_mutex_lock`|Bloquea un mutex (si ya est√° bloqueado, el hilo se bloquea hasta que se libere)|
|`pthread_mutex_trylock`|Intenta bloquear un mutex, pero si est√° ocupado, **no bloquea el hilo** (retorna error en su lugar)|
|`pthread_mutex_unlock`|Libera un mutex, permitiendo que otro hilo lo adquiera|

**Ejemplo:**
```c
pthread_mutex_t lock;  // Declaraci√≥n del mutex

// Inicializaci√≥n antes de usar
pthread_mutex_init(&lock, NULL);

// Bloquear el mutex antes de entrar a la regi√≥n cr√≠tica
pthread_mutex_lock(&lock);
    // üîπ Secci√≥n cr√≠tica (modificaci√≥n de recursos compartidos)
pthread_mutex_unlock(&lock);  // Liberar el mutex

// Al finalizar, destruir el mutex
pthread_mutex_destroy(&lock);
```

**Regla de oro:** Cada `pthread_mutex_lock` **debe** tener un `pthread_mutex_unlock` para evitar bloqueos permanentes.


## Variables de Condici√≥n
Los **mutexes** protegen el acceso a una regi√≥n cr√≠tica, pero no son suficientes si un hilo debe **esperar a que ocurra una condici√≥n espec√≠fica**. Para eso, se usan **variables de condici√≥n** junto con los mutexes.

| **Funci√≥n**              | **Descripci√≥n**                                                                  |
| ------------------------ | -------------------------------------------------------------------------------- |
| `pthread_cond_init`      | Crea una variable de condici√≥n                                                   |
| `pthread_cond_destroy`   | Destruye una variable de condici√≥n                                               |
| `pthread_cond_wait`      | Bloquea el hilo hasta que otra se√±al lo despierte (**debe usarse con un mutex**) |
| `pthread_cond_signal`    | Despierta **un solo** hilo bloqueado en la variable de condici√≥n                 |
| `pthread_cond_broadcast` | Despierta **todos** los hilos bloqueados en la variable de condici√≥n             |
| 2                        |                                                                                  |
**Ejemplo:**
```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
int buffer_disponible = 0;  // 0 = vac√≠o, 1 = lleno

void *productor(void *arg) {
    pthread_mutex_lock(&lock);
    while (buffer_disponible == 1) {
        pthread_cond_wait(&cond, &lock);  // Espera hasta que el buffer est√© vac√≠o
    }
    // üîπ Producir algo
    buffer_disponible = 1;
    pthread_cond_signal(&cond);  // Despertar al consumidor
    pthread_mutex_unlock(&lock);
    return NULL;
}

void *consumidor(void *arg) {
    pthread_mutex_lock(&lock);
    while (buffer_disponible == 0) {
        pthread_cond_wait(&cond, &lock);  // Espera hasta que haya algo en el buffer
    }
    // üîπ Consumir algo
    buffer_disponible = 0;
    pthread_cond_signal(&cond);  // Despertar al productor
    pthread_mutex_unlock(&lock);
    return NULL;
}
```

# 1.7 Monitores
Imagina que en el c√≥digo de los sem√°foros llamamos antes al `down` de la variable `mutex` que al de la variable `vac√≠as` en el c√≥digo del `productor`. Si el buffer estuviera completamente lleno el productor se bloquear√≠a, con `mutex = 0`. En consecuencia, la pr√≥xima vez que el consumidor tratara de acceder al buffer, realizar√≠a una operaci√≥n `down` en `mutex` y se bloquear√≠a. Ambos procesos permanecer√≠an bloqueados de manera indefinida y no se realizar√≠a trabajo. Esto es un **interbloqueo**.



## 1.7.1 ¬øQu√© es un Monitor?
Un **monitor** es una **abstracci√≥n de alto nivel** para la **sincronizaci√≥n de procesos o hilos**, que **combina exclusi√≥n mutua autom√°tica con estructuras de datos y procedimientos protegidos**.

> Esencialmente, es un **m√≥dulo o paquete** que agrupa:

- Variables compartidas
- Procedimientos para acceder a esas variables
- Reglas que garantizan que **s√≥lo un proceso/hilo** est√© activo dentro del monitor a la vez

### **Objetivo**

- **Evitar condiciones de carrera** al controlar el acceso concurrente a datos compartidos.
- **Simplificar el dise√±o y la implementaci√≥n** de programas concurrentes al automatizar la exclusi√≥n mutua.


## 1.7.2. ¬øC√≥mo funciona un Monitor?
S√≥lo **un proceso o hilo** puede estar ejecutando dentro del monitor en un momento dado. 

Si otro proceso intenta entrar mientras hay uno activo, **se bloquea autom√°ticamente** hasta que el monitor est√© libre.    

_Analog√≠a_: Piensa en un ba√±o de una sola cabina. Si alguien est√° adentro, el siguiente tiene que esperar fuera. La cerradura (mutex) est√° gestionada autom√°ticamente.


Los monitores son una **construcci√≥n del lenguaje**. El compilador reconoce cu√°ndo se est√° accediendo a un monitor y **genera autom√°ticamente** el c√≥digo necesario para bloquear y desbloquear.
 
A diferencia de los sem√°foros (que son una herramienta de bajo nivel), los monitores son m√°s **seguros y f√°ciles de usar**, porque el programador no necesita preocuparse por errores como olvidar un `unlock`.
  

Lenguajes como **Java** tienen soporte para monitores (a trav√©s de `synchronized`, `wait()`, y `notify()`).


## 1.7.3 Variables de condici√≥n
La exclusi√≥n mutua no es suficiente. A veces un proceso necesita **esperar hasta que se cumpla una condici√≥n** para poder continuar.

**Productor-Consumidor**
- El productor no puede insertar en el b√∫fer si est√° lleno.
- El consumidor no puede eliminar si el b√∫fer est√° vac√≠o.

**Soluci√≥n: variables de condici√≥n**
- Son mecanismos dentro de los monitores que permiten a un proceso **bloquearse activamente** cuando no puede continuar.
- Usan dos operaciones clave:
    - `wait(cond)`: bloquea el proceso hasta que otro haga `signal(cond)`
    - `signal(cond)`: despierta a **uno** de los procesos bloqueados en `cond`


_Importante_: Las variables de condici√≥n **no almacenan se√±ales**. Si haces un `signal` y no hay nadie esperando, la se√±al **se pierde**.


## 1.7.4 Estrategias de Desbloqueo: ¬øqui√©n sigue?
Cuando un proceso hace `signal(cond)`, ¬øqui√©n debe ejecutarse?

1. **Hoare**: El proceso que fue despertado **entra inmediatamente al monitor**, suspendiendo al se√±alizador.  
2. **Brinch Hansen** (preferida): El se√±alizador **sale del monitor inmediatamente** despu√©s del `signal`, y entonces entra el otro proceso.
3. **Tercera opci√≥n (intermedia)**: El se√±alizador termina completamente y luego entra el otro.

üìå En la pr√°ctica, se suele usar la segunda (Brinch Hansen) por su **simplicidad de implementaci√≥n**.


## 1.7.5 Ejemplo: Productor-Consumidor con Monitores

```pascal
monitor ProductorConsumidor
    condition llenas, vacias;
    integer cuenta;

    procedure insertar(elemento: integer);
    begin
        if cuenta = N then wait(llenas);
        insertar_elemento(elemento);
        cuenta := cuenta + 1;
        if cuenta = 1 then signal(vacias);
    end;

    function eliminar: integer;
    begin
        if cuenta = 0 then wait(vacias);
        eliminar := eliminar_elemento;
        cuenta := cuenta - 1;
        if cuenta = N - 1 then signal(llenas);
    end;

    cuenta := 0;
end monitor;
```

- `cuenta` lleva el n√∫mero de elementos en el b√∫fer. 
- Las variables de condici√≥n `llenas` y `vacias` ayudan a coordinar.
- Solo **un proceso a la vez** puede ejecutar `insertar` o `eliminar`.


## 1.7.6 Comparaci√≥n con Sem√°foros y Sleep/Wakeup

**Problemas de `sleep()` y `wakeup()`**
- Son vulnerables a **condiciones de carrera**.
- Si `wakeup` ocurre **antes** de `sleep`, el proceso **se duerme para siempre**.

Los monitores **evitan estos errores** porque:
- Garantizan que `wait()` se ejecute **dentro** de una secci√≥n cr√≠tica. 
- Solo un proceso entra al monitor, por lo que no puede haber interferencia al hacer `wait`.

## 1.7.7 Limitaciones de los Monitores
- **Dependencia del lenguaje**: requieren soporte a nivel de compilador. Lenguajes como C no los soportan directamente.
- **Inutilizables en sistemas distribuidos**: est√°n dise√±ados para **memoria compartida**, no para CPUs conectadas por red.
- **No permiten compartir datos entre m√°quinas**.

# 1.8 Paso de Mensajes
El **pasaje de mensajes** es un **m√©todo de comunicaci√≥n entre procesos** (ya sea en el mismo sistema o en sistemas distribuidos), que **no depende de memoria compartida**. Es especialmente √∫til cuando:

- Los procesos est√°n en **m√°quinas diferentes**.
- **No existe memoria com√∫n** entre procesos.
- Se busca una soluci√≥n m√°s **estructurada y segura** para la comunicaci√≥n.


Funciona con dos operaciones b√°sicas (*llamadas al sistema*):

- `send(destino, &mensaje);` ‚Üí Env√≠a un mensaje al proceso destino. (kill) 
- `receive(origen, &mensaje);` ‚Üí Recibe un mensaje del proceso origen. (pause o manejadores)


Estas llamadas permiten a los procesos **enviar y recibir datos sin compartir memoria**, y **el sistema operativo gestiona** los detalles como la sincronizaci√≥n o el bloqueo si no hay mensajes disponibles.

|Mecanismo|Requiere Memoria Compartida|¬øA qu√© nivel opera?|Soporte en Lenguaje|Comunicaci√≥n de datos|
|---|---|---|---|---|
|**Sem√°foro**|S√≠|Bajo nivel (llamada al sistema)|No, se implementan con librer√≠as o ensamblador|No (s√≥lo sincronizaci√≥n)|
|**Monitor**|S√≠|Nivel del lenguaje (estructuras)|S√≠, integrado en lenguajes como Java|No (principalmente sincronizaci√≥n)|
|**Pasaje de mensajes**|No|Llamada al sistema|No requiere integraci√≥n en el lenguaje|**S√≠, permite transferencia de datos**|

**Sem√°foros y monitores** se usan principalmente para **exclusi√≥n mutua** (sincronizaci√≥n).

**El pasaje de mensajes**, adem√°s de sincronizar, permite **transferir datos directamente** entre procesos.


### Problema del Productor-Consumidor
Con monitores (como en Java), el productor y el consumidor **acceden a un b√∫fer compartido** y sincronizan su acceso usando `wait()` y `notify()` dentro de un objeto monitor.

Con el pasaje de mensajes **no hay b√∫fer compartido**. El productor y el consumidor **se env√≠an mensajes entre s√≠**, como en este flujo:

1. El **consumidor** env√≠a `N` mensajes vac√≠os al **productor**.
2. Cada vez que el **productor** tiene un elemento:
    - Espera un mensaje vac√≠o (`receive`).
    - Lo llena y lo env√≠a al consumidor (`send`).
3. El **consumidor**:
    - Recibe un mensaje lleno.
    - Extrae el elemento.
    - Env√≠a de vuelta un mensaje vac√≠o.

Este ciclo permite **sincronizaci√≥n y transmisi√≥n de datos**, sin necesidad de memoria compartida.

En sistemas con **m√∫ltiples CPUs con memoria separada**, **no se puede usar memoria compartida**, por lo tanto ni sem√°foros ni monitores sirven. 

El pasaje de mensajes **s√≠ puede funcionar**, ya que:  
- No requiere acceso a una misma memoria.
- Es naturalmente compatible con redes. 
- Permite manejar **perdidas, duplicados y errores** en la comunicaci√≥n (por ejemplo, usando ACKs y n√∫meros de secuencia).

### Cuestiones de dise√±o

1. **Mensajes perdidos:** se puede usar un sistema de  acuses de recibo (ACK).
2. **Duplicados:** se usan **n√∫meros de secuencia** para detectarlos.
3. **Autenticaci√≥n:** ¬øc√≥mo saber que el servidor con el que se habla es leg√≠timo?
4. **Rendimiento:** es m√°s lento que acceso a memoria compartida, pero se puede optimizar (p. ej., usando registros en lugar de copiar bloques grandes de memoria).
5. **Direccionamiento:** se pueden enviar mensajes a:
- Procesos espec√≠ficos.  
- **Buzones**: estructura intermediaria para mensajes.

### Tipos de implementaci√≥n
- **Con b√∫feres (buzones):** los mensajes se almacenan hasta que se reciben.
- **Sin b√∫fer (encuentro):** el env√≠o y recepci√≥n ocurren al mismo tiempo. Si uno ocurre primero, se bloquea hasta que el otro proceso est√© listo.

# 1.9 Barreras
Una **barrera** es una forma de sincronizaci√≥n colectiva. Es decir:

> ‚ÄúNing√∫n proceso (o hilo) puede avanzar m√°s all√° de cierto punto, hasta que **todos** los dem√°s procesos tambi√©n hayan llegado a ese mismo punto‚Äù.

Ideal para algoritmos que se ejecutan por fases, como los de simulaci√≥n f√≠sica o c√°lculos sobre matrices grandes.

Imagina 4 hilos (`A`, `B`, `C`, `D`). Cada uno trabaja de forma independiente en su pedazo de tarea. Al final de cada fase, todos hacen una llamada como `barrier()`.

- El primero que llega se queda esperando.
- Lo mismo el segundo y el tercero.
- El √∫ltimo que llega libera a todos.

As√≠ todos comienzan la siguiente fase sincronizados.


## 1.9.1 ¬øC√≥mo se implementan las barreras en C?
En C, podemos hacer esto manualmente con **sem√°foros y contadores**, pero la forma m√°s sencilla y moderna es usando la **API de hilos de POSIX (pthreads)**, que incluye **barreras nativas** (`pthread_barrier_t`).


```c
#include <stdio.h>
#include <pthread.h>

#define NUM_THREADS 4
#define NUM_ITERATIONS 3

pthread_barrier_t barrier;

void* trabajar(void* arg) {
    int id = *(int*)arg;
    for (int fase = 0; fase < NUM_ITERATIONS; fase++) {
        // Simula trabajo
        printf("Hilo %d: Fase %d comenzada\n", id, fase);
        // Aqu√≠ podr√≠as poner c√°lculos reales

        // Barrera: todos deben terminar esta fase antes de continuar
        pthread_barrier_wait(&barrier);

        // Simula el inicio de una nueva fase
        printf("Hilo %d: Fase %d completada\n", id, fase);
    }
    return NULL;
}

int main() {
    pthread_t hilos[NUM_THREADS];
    int ids[NUM_THREADS];

    // Inicializa la barrera para NUM_THREADS
    pthread_barrier_init(&barrier, NULL, NUM_THREADS);

    // Crea los hilos
    for (int i = 0; i < NUM_THREADS; i++) {
        ids[i] = i;
        pthread_create(&hilos[i], NULL, trabajar, &ids[i]);
    }

    // Espera a que terminen
    for (int i = 0; i < NUM_THREADS; i++) {
        pthread_join(hilos[i], NULL);
    }

    // Destruye la barrera
    pthread_barrier_destroy(&barrier);

    return 0;
}
```


Detalles importantes:
- `pthread_barrier_init(&barrier, NULL, NUM_THREADS)`  
    ‚Üí Inicializa la barrera para que se desbloquee cuando hayan llegado los `NUM_THREADS` hilos.
- `pthread_barrier_wait(&barrier)`  
    ‚Üí El hilo que llama aqu√≠ se bloquea hasta que todos los dem√°s tambi√©n lo llamen.    
- `pthread_barrier_destroy(&barrier)`  
    ‚Üí Limpieza de recursos.

