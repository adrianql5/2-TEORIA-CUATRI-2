Cómo un proceso puede pasar información a otro, cómo hacer que dos o más procesos no se interpongan entre sí, cómo obtener la secuencia apropiada cuando hay dependencias presentes.

# 1.1 Condiciones de Carrera
Los procesos que trabajan en conjunto pueden **compartir cierto espacio de almacenamiento** en el que pueden leer y escribir datos. Este almacenamiento compartido puede estar tanto en la **RAM** (*en una estructura de datos*) o en un **archivo compartido**. 

Como ejemplo tenemos un **directorio de spooler** que se usa para imprimir archivos mediante el **demonio de impresión**. Cada ranura del spooler contiene el nombre de un archivo. Si hay dos variables compartidas `sal` que apunta al siguiente archivo a imprimir y `ent` que apunta a la siguiente ranura libre. Estas variables se pueden guardar en una archivo compartido para los procesos.

Pongamos que tenemos las ranuras 0-3 están vacías y las 4-6 llenas, y dos procesos desean poner en cola a un proceso para imprimirlo.

![[Pasted image 20250215133706.png]]
El proceso **A** lee `ent` y guarda el valor 7 en una variable local llamada `siguiente_ranura_libre`. Después pasa el proceso **B** que lee `ent` y recibe un 7 y lo guarda en su variable local. **B** almacena el nombre de su archivo en la ranura 7 y actualiza `ent` para que valga 8.

En cierto momento **A** sabe que para el su ranura libre es la 7 y sobreescribe el nombre del archivo escrito por **B**, por lo que el archivo de **B** nunca se imprime.

Situaciones como estas en donde dos o más procesos están leyendo o escribiendo algunos datos compartidos y el resultado final depende de quién se ejecuta y exactamente cuándo lo hace, se conocen como **condiciones de carrera**. **Muy complejo depurar el codigo**.

# 1.2 Regiones Criticas
Para evitar condiciones de carrera debemos prohibir que varios procesos elan y escriban los datos compartidos (*archivos, memoria compartida, etc.*) al mismo tiempo. Necesitamos **exclusión mutua**. En el ejemplo del Spooler el proceso **B** empezó a utilizar las variables compartidas antes de que **A** hubiese acabado con ellas.

**Región Crítica:** parte del programa en la que se accede a la memoria compartida. 

Si pudiéramos ordenar las cosas de manera que dos procesos nunca estuvieran en sus regiones críticas al mismo tiempo, evitaríamos las carreras. Aunque esto evita las condiciones de carrera, **no es suficiente para que los procesos en paralelo cooperen** de forma correcta y eficiente.

- No puede haber dos procesos de manera simultánea dentro de sus regiones críticas
- No pueden hacerse suposiciones acerca de las velocidades o el número de CPUs.
- Ningún proceso que se ejecute fuera de sus región crítica puede bloquear otros procesos.
- Ningún proceso tiene que esperar para siempre a entrar a su región crítica.

![[Pasted image 20250322112620.png]]

# 1.3 Exclusión mutua con espera ocupada
El objetivo es lograr la **exclusión mutua** de manera que mientras un proceso esté ocupada utilizando la memoria compartida en su región crítica, ningún otro proceso puede entrar a su región crítica y ocasionar problemas.

## 1.3.1 Deshabilitando interrupciones
En un sistema con un solo procesador, la solución más simple es hacer que cada proceso deshabilite todas las interrupciones justo después de entrar a su región crítica y las rehabilite justo después de salir. Así **evitamos las interrupciones de reloj** que marcan cuando la **CPU conmuta de un proceso a otro**. Esto evita que otro proceso intervenga

Sin embargo no es conveniente dar a los procesos de usuario el poder de desactivar las interrupciones. Y si tenemos más de una CPU, solo se ve afectada la CPU que ejecutó la instrucción disable, las demás se ejecutan correctamente y accediendo a la memoria compartida.

## 1.3.2 Variables de candado
**Solución software**. Si tenemos una variable compartida que es 0 inicialmente. Cuando un proceso desea entrar a su región crítica primero evalúa el candado. Si es 0, el proceso lo fija en 1 y entra a la región crítica. Si el candado ya es 1 sólo espera hasta que el candado sea 0. 

**Un 0 significa que ningún proceso está en la región crítica y un 1 significa que algún proceso está en su región crítica**. 

Sin embargo puede suceder lo mimo que en el Spooler. Si un proceso lee el candado y ve que es 0. Antes de que pueda fijar el candado a 1, otro procesos se planifica para ejecutarse y fija el candado a 1. Cuando el primer proceso se ejecuta de nuevo, también fija el candado a 1 y por lo tanto dos procesos se encontraran en sus regiones críticas al mismo tiempo.

## 1.3.3 Alternancia estricta
![[Pasted image 20250322114243.png]]
La variable **turno** lleva la cuenta acerca de que proceso le toca entrar a su región crítica y examinar o actualizar la memoria compartida. El **proceso 0** inspeccionar turno, descubre que es 0 y **entra a su region crítica**. El **proceso 1** ve que es 0 por lo que se queda evaluando turno de forma continua. **La acción a evaluar en forma continua de una variable hasta que aparezca cierto valor se conoce como espera ocupada.**

Esta espera ocupada se debe intentar evitar ya que desperdicia tiempo de cpu, solo se usa cuando se cree que la espera será corta. 

Cuando el proceso 0 sale de la región crítica establece turno a 1, para permitir que el proceso 1 entre a su región crítica. Suponga que el proceso 1 sale rápidamente de su región crítica, de manera que ambos procesos se encuentran en sus regiones no críticas, con turno establecido en 0. Ahora el proceso 0 ejecuta todo su ciclo rápidamente, saliendo de su región crítica y estableciendo turno a 1. En este punto, turno es 1 y ambos procesos se están **ejecutando en sus regiones no críticas**.

De repente, el proceso 0 termina en su región no crítica y regresa a la parte superior de su ciclo. Por desgracia no puede entrar a su región crítica ahora, debido a que turno es 1 y el proceso 1 está ocupado con su región no crítica. El proceso 0 espera en su ciclo while hasta que el pro- ceso 1 establezca turno a 0. Dicho en forma distinta, tomar turnos no es una buena idea cuando uno de los procesos es mucho más lento que el otro. Esta situación viola la condición 3 antes establecida:

- Ningún proceso que se ejecute fuera de sus región crítica puede bloquear otros procesos.

## 1.3.4 Solución de Peterson
![[Pasted image 20250322121723.png]]
Antes de utilizar las variables compartidas (es decir, antes de entrar a su región crítica), cada proceso llama a `entrar_region` con su propio número de proceso como parámetro. Esta llamada hará que espera, si es necesario, hasta que sea seguro entrar. 

Cuando termina de usar las **variables compartidas** llama a `salir_region` para indicar que ha terminado y permitir que los demás procesos entren, si así lo desean.

El **proceso 0** llama a `entrar_region`. Indica su interés estableciendo su elemento del arreglo y fija **turno a 0**. Como el proceso 1 no está interesado, `entrar_region` regresa de inmediato. Si ahora el **proceso 1** hace una llamada a `entrar_region`, se quedará ahí hasta que interesado[0] sea **FALSE**, un evento que sólo ocurre cuando el **proceso 0** llama a `salir_region` para salir de la región crítica.

Ahora considere el caso en el que ambos procesos llaman a `entrar_region` casi en forma simultánea. Ambos almacenarán su número de proceso en **turno**. Cualquier almacenamiento que se haya realizado al último es el que cuenta; **el primero se sobrescribe y se pierde**. Suponga que el **proceso 1** almacena al último, por lo que **turno es 1**. Cuando ambos procesos llegan a la instrucción `while`, el **proceso 0 la ejecuta 0** **veces** **y entra a su región crítica**. El **proceso 1 itera y no entra a su región crítica sino hasta que el proceso 0 sale de su región crítica**.

## 1.3.5 Instrucción TSL
La instrucción **TSL (Test and Set Lock)** es una instrucción especial de bajo nivel que se usa en sistemas multiprocesador para garantizar la exclusión mutua en regiones críticas. Se trata de una operación atómica que ayuda a evitar **condiciones de carrera** cuando varios procesos intentan acceder a una variable compartida.

- **Lee el valor** de una variable de memoria compartida (llamada **candado**) y lo guarda en un registro.
- **Fija la variable** candado a un valor distinto de 0 (por ejemplo, 1) en memoria, asegurando que otros procesos no puedan modificarla.
- **Bloquea el bus de memoria** temporalmente mientras ejecuta estas dos operaciones, asegurando que ningún otro procesador pueda acceder a la variable hasta que la instrucción termine.

Es una alternativa para evitar condiciones de carrera es **deshabilitar interrupciones** antes de acceder a la región crítica. Sin embargo, esto **no funciona en sistemas multiprocesador** porque:
- Deshabilitar interrupciones en un procesador **no afecta a los demás**.
- Otro procesador puede leer la variable compartida y modificarla mientras el primero aún está ejecutando su código.

![[Pasted image 20250322123107.png]]


# 1.4 Dormir y Despertar
Para evitar la espera ocupada, se introduce el mecanismo de **Dormir y Despertar** con dos primitivas de comunicación entre procesos:

1. **`sleep()`** → Suspende el proceso actual **hasta que otro proceso lo despierte**.
2. **`wakeup(proceso)`** → Despierta un proceso suspendido, permitiéndole continuar su ejecución.

Esto significa que **si un proceso no puede entrar a la región crítica, en lugar de quedarse en un bucle gastando CPU, simplemente se suspende hasta que otro proceso lo despierte**.

## 1.4.1 El problema del productor-consumidor
Dos procesos comparten un **buffer compartido de tamaño fijo**. El productor coloca información en el buffer y el consumidor la saca. 

El problema surge cuando el productor desea colocar un nuevo elemento en el buffer, pero este ya está lleno. La solución es que se vaya a dormir y se despierte cuando el consumidor haya quitado uno o mas elementos. Lo mismo cuando el buffer esta vacío y el consumidor quiere retirar elementos.

Parece simple, pero genera los mismos **tipos de condiciones de carrera** del directorio de Spooler. Necesitamos la variable cuenta para saber llevar la cuenta de elementos en el buffer. 

![[Pasted image 20250322124847.png]]

Los procedimientos `insertar_elemento` y `quitar_elemento`, que no se muestran aquí se encargan de colocar elementos en el buffer y sacarlos del mismo. 

Debido a que el acceso a cuenta no está restringido. Es posible que ocurra la condición de carrera en la siguiente situación: **el buffer está vacío y el consumidor acaba de leer cuenta para ver si es 0**. En ese instante, el planificador decide detener al consumidor en forma temporal y empieza a ejecutar el productor.

El productor inserta un elemento en el buffer, incrementa cuenta y observa que ahora es 1. Razonando que cuenta era antes 0, y que por ende el consumidor debe estar dormido, el productor llama a wakeup. Sin embargo, el consumidor no está lógicamente dormido, por lo que la señal para despertarlo se pierde. Cuando es turno de que se ejecute el consumidor, evalúa el valor de cuenta en que leyó antes, encuentra que es 0 y pasa a dormirse. Tarde o temprano el **productor llenará el buffer y también pasará a dormirse**, quedando ambos dormidos para siempre.

La esencia del problema aquí es que una señal que se envía para despertar a un proceso que no está dormido (todavía) se pierde. Si no se perdiera, todo funcionaría. 

# 1.5 Semáforos
**Semáforo**, variable entera para contar el número de señales de **wakeup**, guardadas para un uso futuro. Almacena el valor 0, indicando que no se guardaron señales de despertar o algún valor positivo si estuvieran pendientes una o más señales de **wakeup**.

Tenemos dos operaciones, `down` y `up` (generalizaciones de `sleep` y `wakeup`). La operación `down` comprueba si el valor es mayor que 0. De ser así, disminuye el valor(utiliza una señal de despertar almacenada) y sólo continúa.

Si el valor es 0, el proceso se pone a dormir sin completar la operación `down` por el momento. Las acciones de comprobar el valor, modificarlo y posiblemente dormir, se realizan en conjunto como una sola **acción atómica** indivisible. 

Una vez que empieza la operación de semáforo, ningún otro proceso podrá accede al semáforo sino hasta que la operación se haya completado o bloqueado. Esto resuelve problemas de sincronización y evita condiciones de carrera.

La operación `up` incrementa el valor del semáforo direccionado. Si uno o más procesos estaban inactivos en ese semáforo, sin poder completar una operación `down` anterior, el sistema selecciona uno de ellos (al azar) y permite que complete su operación `down`.

## 1.5.1 Resolver el problema del productor-consumidor mediante el uso de semáforos

En este caso, se utilizan tres semáforos para coordinar el acceso al búfer compartido:

- **Semáforo `llenas`**: Cuenta cuántas ranuras del búfer están ocupadas:    
    - Inicialmente es 0 porque el búfer comienza vacío.
    - Se incrementa (`up`) cuando el productor coloca un elemento.
    - Se decrementa (`down`) cuando el consumidor retira un elemento.
    
- **Semáforo `vacías`**: Cuenta cuántas ranuras del búfer están disponibles. 
    - Se inicializa con el tamaño total del búfer (porque al inicio está completamente vacío).
    - Se decrementa (`down`) cuando el productor coloca un elemento.
    - Se incrementa (`up`) cuando el consumidor extrae un elemento.
    
- **Semáforo `mutex`**: Asegura que solo un proceso (productor o consumidor) acceda al búfer a la vez.
    - Se inicializa en 1 (se trata de un semáforo binario).
    - Se usa para garantizar **exclusión mutua**:
        - El productor lo adquiere (`down`) antes de escribir y lo libera (`up`) después.
        - El consumidor lo adquiere (`down`) antes de leer y lo libera (`up`) después.


## **Implementación de `up` y `down`**
Las operaciones `up` y `down` deben ser **atómicas** (indivisibles). Para garantizar esto, el sistema operativo suele deshabilitar las interrupciones brevemente mientras se realiza la operación. En sistemas con múltiples CPUs, se protege el semáforo con una variable de candado y **operaciones atómicas** como `TSL` (Test and Set Lock) o `XCHG` para evitar que varias CPUs lo modifiquen al mismo tiempo.



## **Flujo de ejecución**
![[Pasted image 20250324164420.png]]

## **Uso de semáforos en manejo de interrupciones**

Los semáforos también pueden sincronizar procesos con dispositivos de E/S. Cada dispositivo de E/S puede tener un semáforo inicializado en 0.

- Cuando un proceso inicia una operación de E/S, hace `down` en el semáforo y se bloquea.
    
- Cuando la interrupción de E/S ocurre, el manejador hace `up` en el semáforo, despertando al proceso.
    

Esto evita que los procesos hagan espera ocupada y permite que el planificador de CPU ejecute otras tareas mientras espera la E/S.

# 1.6 Mutexes
Los **mutexes** son buenos para administrar la exclusión mutua para cierto recurso compartido o pieza de código. 

Un **mutex** es una variable que puede estar en uno de dos estados: **abierto** (*desbloqueado*) o **cerrado** (*bloqueado*). En consecuencia, se requiere sólo 1 bit para representarla, pero en la práctica se utiliza con frecuencia un entero, en donde **0 indica que está abierto** y todos los demás valores indican que está **cerrado**.

Cuando un hilo necesita acceso a una **región crítica**, llama a `mutex_lock`. Si el mutex está actualmente abierto, la llamada tiene éxito y el **hilo llamador puede entrara la región crítica**.

Si el mutex ya **se encuentra cerrado**, el hilo que hizo la llamada se **bloquea** hasta que el hilo que está en la región crítica termine y llame a `mutex_unlock`. Si se bloquean varios hilos por el mutex, se selecciona uno de ellos al azar y se permite que adquiera el mutex.

`mutex_lock` es similar al código de `entrar_region`pero la diferencia es que en `entrar_region`, cuando no puede entrar, continúa evaluando el mutex en forma repetida (*espera ocupada*). Cuando el reloj expire algún otro proceso se programará para ejecutarlo. Cuando tenemos **hilos** no hay reloj, por lo que si empleamos la **espera ocupada** lo intentará adquirir de forma indefinida y nunca adquirira un mutex debido a que nunca permitirá que algún otro hilo se ejecute y libere el mutex. Entonces por eso `mutex_lock` llama a `thread_yield` para darle CPU a otro hilo.

Como se llama al `thread_yield` en el espacio de usuario es muy rápido y ni `mutex_lock` ni `mutex_unlock` requieren de llamadas al kernel.


## Mutexes (Mutual Exclusion Locks)
Los **mutexes** sirven para proteger **regiones críticas** en las que solo un hilo debe acceder a la vez, evitando que múltiples hilos modifiquen datos compartidos simultáneamente y generen condiciones de carrera.


|**Función**|**Descripción**|
|---|---|
|`pthread_mutex_init`|Crea un mutex antes de usarlo|
|`pthread_mutex_destroy`|Destruye un mutex cuando ya no se necesita|
|`pthread_mutex_lock`|Bloquea un mutex (si ya está bloqueado, el hilo se bloquea hasta que se libere)|
|`pthread_mutex_trylock`|Intenta bloquear un mutex, pero si está ocupado, **no bloquea el hilo** (retorna error en su lugar)|
|`pthread_mutex_unlock`|Libera un mutex, permitiendo que otro hilo lo adquiera|

**Ejemplo:**
```c
pthread_mutex_t lock;  // Declaración del mutex

// Inicialización antes de usar
pthread_mutex_init(&lock, NULL);

// Bloquear el mutex antes de entrar a la región crítica
pthread_mutex_lock(&lock);
    // 🔹 Sección crítica (modificación de recursos compartidos)
pthread_mutex_unlock(&lock);  // Liberar el mutex

// Al finalizar, destruir el mutex
pthread_mutex_destroy(&lock);
```

**Regla de oro:** Cada `pthread_mutex_lock` **debe** tener un `pthread_mutex_unlock` para evitar bloqueos permanentes.


## Variables de Condición
Los **mutexes** protegen el acceso a una región crítica, pero no son suficientes si un hilo debe **esperar a que ocurra una condición específica**. Para eso, se usan **variables de condición** junto con los mutexes.

| **Función**              | **Descripción**                                                                  |
| ------------------------ | -------------------------------------------------------------------------------- |
| `pthread_cond_init`      | Crea una variable de condición                                                   |
| `pthread_cond_destroy`   | Destruye una variable de condición                                               |
| `pthread_cond_wait`      | Bloquea el hilo hasta que otra señal lo despierte (**debe usarse con un mutex**) |
| `pthread_cond_signal`    | Despierta **un solo** hilo bloqueado en la variable de condición                 |
| `pthread_cond_broadcast` | Despierta **todos** los hilos bloqueados en la variable de condición             |
**Ejemplo:**
```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
int buffer_disponible = 0;  // 0 = vacío, 1 = lleno

void *productor(void *arg) {
    pthread_mutex_lock(&lock);
    while (buffer_disponible == 1) {
        pthread_cond_wait(&cond, &lock);  // Espera hasta que el buffer esté vacío
    }
    // 🔹 Producir algo
    buffer_disponible = 1;
    pthread_cond_signal(&cond);  // Despertar al consumidor
    pthread_mutex_unlock(&lock);
    return NULL;
}

void *consumidor(void *arg) {
    pthread_mutex_lock(&lock);
    while (buffer_disponible == 0) {
        pthread_cond_wait(&cond, &lock);  // Espera hasta que haya algo en el buffer
    }
    // 🔹 Consumir algo
    buffer_disponible = 0;
    pthread_cond_signal(&cond);  // Despertar al productor
    pthread_mutex_unlock(&lock);
    return NULL;
}
```

