Cómo un proceso puede pasar información a otro, cómo hacer que dos o más procesos no se interpongan entre sí, cómo obtener la secuencia apropiada cuando hay dependencias presentes.

# 1.1 Condiciones de Carrera
Los procesos que trabajan en conjunto pueden **compartir cierto espacio de almacenamiento** en el que pueden leer y escribir datos. Este almacenamiento compartido puede estar tanto en la **RAM** (*en una estructura de datos*) o en un **archivo compartido**. 

Como ejemplo tenemos un **directorio de spooler** que se usa para imprimir archivos mediante el **demonio de impresión**. Cada ranura del spooler contiene el nombre de un archivo. Si hay dos variables compartidas `sal` que apunta al siguiente archivo a imprimir y `ent` que apunta a la siguiente ranura libre. Estas variables se pueden guardar en una archivo compartido para los procesos.

Pongamos que tenemos las ranuras 0-3 están vacías y las 4-6 llenas, y dos procesos desean poner en cola a un proceso para imprimirlo.

![[Pasted image 20250215133706.png]]
El proceso **A** lee `ent` y guarda el valor 7 en una variable local llamada `siguiente_ranura_libre`. Después pasa el proceso **B** que lee `ent` y recibe un 7 y lo guarda en su variable local. **B** almacena el nombre de su archivo en la ranura 7 y actualiza `ent` para que valga 8.

En cierto momento **A** sabe que para el su ranura libre es la 7 y sobreescribe el nombre del archivo escrito por **B**, por lo que el archivo de **B** nunca se imprime.

Situaciones como estas en donde dos o más procesos están leyendo o escribiendo algunos datos compartidos y el resultado final depende de quién se ejecuta y exactamente cuándo lo hace, se conocen como **condiciones de carrera**. **Muy complejo depurar el codigo**.

# 1.2 Regiones Criticas
Para evitar condiciones de carrera debemos prohibir que varios procesos elan y escriban los datos compartidos (*archivos, memoria compartida, etc.*) al mismo tiempo. Necesitamos **exclusión mutua**. En el ejemplo del Spooler el proceso **B** empezó a utilizar las variables compartidas antes de que **A** hubiese acabado con ellas.

**Región Crítica:** parte del programa en la que se accede a la memoria compartida. 

Si pudiéramos ordenar las cosas de manera que dos procesos nunca estuvieran en sus regiones críticas al mismo tiempo, evitaríamos las carreras. Aunque esto evita las condiciones de carrera, **no es suficiente para que los procesos en paralelo cooperen** de forma correcta y eficiente.

- No puede haber dos procesos de manera simultánea dentro de sus regiones críticas
- No pueden hacerse suposiciones acerca de las velocidades o el número de CPUs.
- Ningún proceso que se ejecute fuera de sus región crítica puede bloquear otros procesos.
- Ningún proceso tiene que esperar para siempre a entrar a su región crítica.

![[Pasted image 20250322112620.png]]

# 1.3 Exclusión mutua con espera ocupada
El objetivo es lograr la **exclusión mutua** de manera que mientras un proceso esté ocupada utilizando la memoria compartida en su región crítica, ningún otro proceso puede entrar a su región crítica y ocasionar problemas.

## 1.3.1 Deshabilitando interrupciones
En un sistema con un solo procesador, la solución más simple es hacer que cada proceso deshabilite todas las interrupciones justo después de entrar a su región crítica y las rehabilite justo después de salir. Así **evitamos las interrupciones de reloj** que marcan cuando la **CPU conmuta de un proceso a otro**. Esto evita que otro proceso intervenga

Sin embargo no es conveniente dar a los procesos de usuario el poder de desactivar las interrupciones. Y si tenemos más de una CPU, solo se ve afectada la CPU que ejecutó la instrucción disable, las demás se ejecutan correctamente y accediendo a la memoria compartida.

## 1.3.2 Variables de candado
**Solución software**. Si tenemos una variable compartida que es 0 inicialmente. Cuando un proceso desea entrar a su región crítica primero evalúa el candado. Si es 0, el proceso lo fija en 1 y entra a la región crítica. Si el candado ya es 1 sólo espera hasta que el candado sea 0. 

**Un 0 significa que ningún proceso está en la región crítica y un 1 significa que algún proceso está en su región crítica**. 

Sin embargo puede suceder lo mimo que en el Spooler. Si un proceso lee el candado y ve que es 0. Antes de que pueda fijar el candado a 1, otro procesos se planifica para ejecutarse y fija el candado a 1. Cuando el primer proceso se ejecuta de nuevo, también fija el candado a 1 y por lo tanto dos procesos se encontraran en sus regiones críticas al mismo tiempo.

## 1.3.3 Alternancia estricta
![[Pasted image 20250322114243.png]]
La variable **turno** lleva la cuenta acerca de que proceso le toca entrar a su región crítica y examinar o actualizar la memoria compartida. El **proceso 0** inspeccionar turno, descubre que es 0 y **entra a su region crítica**. El **proceso 1** ve que es 0 por lo que se queda evaluando turno de forma continua. **La acción a evaluar en forma continua de una variable hasta que aparezca cierto valor se conoce como espera ocupada.**

Esta espera ocupada se debe intentar evitar ya que desperdicia tiempo de cpu, solo se usa cuando se cree que la espera será corta. 

Cuando el proceso 0 sale de la región crítica establece turno a 1, para permitir que el proceso 1 entre a su región crítica. Suponga que el proceso 1 sale rápidamente de su región crítica, de manera que ambos procesos se encuentran en sus regiones no críticas, con turno establecido en 0. Ahora el proceso 0 ejecuta todo su ciclo rápidamente, saliendo de su región crítica y estableciendo turno a 1. En este punto, turno es 1 y ambos procesos se están **ejecutando en sus regiones no críticas**.

De repente, el proceso 0 termina en su región no crítica y regresa a la parte superior de su ciclo. Por desgracia no puede entrar a su región crítica ahora, debido a que turno es 1 y el proceso 1 está ocupado con su región no crítica. El proceso 0 espera en su ciclo while hasta que el pro- ceso 1 establezca turno a 0. Dicho en forma distinta, tomar turnos no es una buena idea cuando uno de los procesos es mucho más lento que el otro. Esta situación viola la condición 3 antes establecida:

- Ningún proceso que se ejecute fuera de sus región crítica puede bloquear otros procesos.

## 1.3.4 Solución de Peterson
![[Pasted image 20250322121723.png]]
Antes de utilizar las variables compartidas (es decir, antes de entrar a su región crítica), cada proceso llama a `entrar_region` con su propio número de proceso como parámetro. Esta llamada hará que espera, si es necesario, hasta que sea seguro entrar. 

Cuando termina de usar las **variables compartidas** llama a `salir_region` para indicar que ha terminado y permitir que los demás procesos entren, si así lo desean.

El **proceso 0** llama a `entrar_region`. Indica su interés estableciendo su elemento del arreglo y fija **turno a 0**. Como el proceso 1 no está interesado, `entrar_region` regresa de inmediato. Si ahora el **proceso 1** hace una llamada a `entrar_region`, se quedará ahí hasta que interesado[0] sea **FALSE**, un evento que sólo ocurre cuando el **proceso 0** llama a `salir_region` para salir de la región crítica.

Ahora considere el caso en el que ambos procesos llaman a `entrar_region` casi en forma simultánea. Ambos almacenarán su número de proceso en **turno**. Cualquier almacenamiento que se haya realizado al último es el que cuenta; **el primero se sobrescribe y se pierde**. Suponga que el **proceso 1** almacena al último, por lo que **turno es 1**. Cuando ambos procesos llegan a la instrucción `while`, el **proceso 0 la ejecuta 0** **veces** **y entra a su región crítica**. El **proceso 1 itera y no entra a su región crítica sino hasta que el proceso 0 sale de su región crítica**.

## 1.3.5 Instrucción TSL
La instrucción **TSL (Test and Set Lock)** es una instrucción especial de bajo nivel que se usa en sistemas multiprocesador para garantizar la exclusión mutua en regiones críticas. Se trata de una operación atómica que ayuda a evitar **condiciones de carrera** cuando varios procesos intentan acceder a una variable compartida.

- **Lee el valor** de una variable de memoria compartida (llamada **candado**) y lo guarda en un registro.
- **Fija la variable** candado a un valor distinto de 0 (por ejemplo, 1) en memoria, asegurando que otros procesos no puedan modificarla.
- **Bloquea el bus de memoria** temporalmente mientras ejecuta estas dos operaciones, asegurando que ningún otro procesador pueda acceder a la variable hasta que la instrucción termine.

Es una alternativa para evitar condiciones de carrera es **deshabilitar interrupciones** antes de acceder a la región crítica. Sin embargo, esto **no funciona en sistemas multiprocesador** porque:
- Deshabilitar interrupciones en un procesador **no afecta a los demás**.
- Otro procesador puede leer la variable compartida y modificarla mientras el primero aún está ejecutando su código.

![[Pasted image 20250322123107.png]]


# 1.4 Dormir y Despertar
Para evitar la espera ocupada, se introduce el mecanismo de **Dormir y Despertar** con dos primitivas de comunicación entre procesos:

1. **`sleep()`** → Suspende el proceso actual **hasta que otro proceso lo despierte**.
2. **`wakeup(proceso)`** → Despierta un proceso suspendido, permitiéndole continuar su ejecución.

Esto significa que **si un proceso no puede entrar a la región crítica, en lugar de quedarse en un bucle gastando CPU, simplemente se suspende hasta que otro proceso lo despierte**.

## 1.4.1 El problema del productor-consumidor
Dos procesos comparten un **buffer compartido de tamaño fijo**. El productor coloca información en el buffer y el consumidor la saca. 

El problema surge cuando el productor desea colocar un nuevo elemento en el buffer, pero este ya está lleno. La solución es que se vaya a dormir y se despierte cuando el consumidor haya quitado uno o mas elementos. Lo mismo cuando el buffer esta vacío y el consumidor quiere retirar elementos.

Parece simple, pero genera los mismos **tipos de condiciones de carrera** del directorio de Spooler. Necesitamos la variable cuenta para saber llevar la cuenta de elementos en el buffer. 

![[Pasted image 20250322124847.png]]

Los procedimientos `insertar_elemento` y `quitar_elemento`, que no se muestran aquí se encargan de colocar elementos en el buffer y sacarlos del mismo. 

Debido a que el acceso a cuenta no está restringido. Es posible que ocurra la condición de carrera en la siguiente situación: **el buffer está vacío y el consumidor acaba de leer cuenta para ver si es 0**. En ese instante, el planificador decide detener al consumidor en forma temporal y empieza a ejecutar el productor.

El productor inserta un elemento en el buffer, incrementa cuenta y observa que ahora es 1. Razonando que cuenta era antes 0, y que por ende el consumidor debe estar dormido, el productor llama a wakeup. Sin embargo, el consumidor no está lógicamente dormido, por lo que la señal para despertarlo se pierde. Cuando es turno de que se ejecute el consumidor, evalúa el valor de cuenta en que leyó antes, encuentra que es 0 y pasa a dormirse. Tarde o temprano el **productor llenará el buffer y también pasará a dormirse**, quedando ambos dormidos para siempre.

La esencia del problema aquí es que una señal que se envía para despertar a un proceso que no está dormido (todavía) se pierde. Si no se perdiera, todo funcionaría. 

# 1.5 Semáforos